01/17/2024 13:19:38 - INFO - __main__ - Namespace(use_demonstrations=True, use_soft_prefix=False, use_soft_postfix=False, n_prefix_tokens=10, max_length=1024, prior=['easiest'], difficulty='concept_calibrated', reorder=True, log_dir='logs', out_dir='out\\gpt2', load_dir=None, concept_dir='concept_likelihood\\gpt2\\glue-glue-100\\glue-sst2-channel-prefix=10-lr=1e-5-3000', prefix_embed_file='checkpoints\\gpt2\\glue-glue\\prefix={10}-{channel}-lr={1e-5}-initByVocab\\soft_embeddings-3000.pt', task=None, dataset='glue-sst2', data_dir='data/', k=4, seed='100,13,21,42,87', test_batch_size=8, global_step=None, use_random_english_words=False, use_random_label=False, use_instruction=False, unseen_domain_only=False, split='test', method='channel', gpt='gpt2', api=None, test_size=1000, train_size=100, embedding_dir='embeddings\\', embedding_model='all-mpnet-base-v2', similarity_temperature=0.1, concept_temperature=50.0)
01/17/2024 13:19:38 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:19:39 - INFO - __main__ - batch_size=8	max_length=1024	max_length_per_example=256
01/17/2024 13:19:41 - INFO - __main__ - [Train] glue-sst2	67349
01/17/2024 13:19:41 - INFO - __main__ - [Dev] glue-sst2	872
01/17/2024 13:19:41 - INFO - __main__ - channel on None (1 train, 1 dev)
01/17/2024 13:19:41 - INFO - __main__ - loading saved concept likelihoods
01/17/2024 13:19:41 - INFO - __main__ - start running soft prefix model
01/17/2024 13:19:41 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:19:44 - INFO - __main__ - Checking the first example...
Input:
negative sentence: the stars may be college kids, but the subject matter is as adult as you can get :
Output:
<glue-mnli-0><glue-mnli-1><glue-mnli-2><glue-mnli-3><glue-mnli-4><glue-mnli-5><glue-mnli-6><glue-mnli-7><glue-mnli-8><glue-mnli-9>
01/17/2024 13:19:44 - INFO - __main__ - torch.Size([200, 1024])
01/17/2024 13:19:59 - INFO - __main__ - time use for computing 100 examples: 18.802783250808716
01/17/2024 13:19:59 - INFO - __main__ - start running soft prefix model
01/17/2024 13:19:59 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:20:03 - INFO - __main__ - Checking the first example...
Input:
negative sentence: the stars may be college kids, but the subject matter is as adult as you can get :
Output:
<glue-qqp-0><glue-qqp-1><glue-qqp-2><glue-qqp-3><glue-qqp-4><glue-qqp-5><glue-qqp-6><glue-qqp-7><glue-qqp-8><glue-qqp-9>
01/17/2024 13:20:03 - INFO - __main__ - torch.Size([200, 1024])
01/17/2024 13:20:18 - INFO - __main__ - time use for computing 100 examples: 19.008267641067505
01/17/2024 13:20:18 - INFO - __main__ - start running soft prefix model
01/17/2024 13:20:18 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:20:23 - INFO - __main__ - Checking the first example...
Input:
negative sentence: the stars may be college kids, but the subject matter is as adult as you can get :
Output:
<glue-mrpc-0><glue-mrpc-1><glue-mrpc-2><glue-mrpc-3><glue-mrpc-4><glue-mrpc-5><glue-mrpc-6><glue-mrpc-7><glue-mrpc-8><glue-mrpc-9>
01/17/2024 13:20:23 - INFO - __main__ - torch.Size([200, 1024])
01/17/2024 13:20:38 - INFO - __main__ - time use for computing 100 examples: 19.301379680633545
01/17/2024 13:20:38 - INFO - __main__ - start running soft prefix model
01/17/2024 13:20:38 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:20:43 - INFO - __main__ - Checking the first example...
Input:
negative sentence: the stars may be college kids, but the subject matter is as adult as you can get :
Output:
<glue-qnli-0><glue-qnli-1><glue-qnli-2><glue-qnli-3><glue-qnli-4><glue-qnli-5><glue-qnli-6><glue-qnli-7><glue-qnli-8><glue-qnli-9>
01/17/2024 13:20:43 - INFO - __main__ - torch.Size([200, 1024])
01/17/2024 13:20:58 - INFO - __main__ - time use for computing 100 examples: 19.91109824180603
01/17/2024 13:20:58 - INFO - __main__ - start running soft prefix model
01/17/2024 13:20:58 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:21:02 - INFO - __main__ - Checking the first example...
Input:
negative sentence: the stars may be college kids, but the subject matter is as adult as you can get :
Output:
<glue-rte-0><glue-rte-1><glue-rte-2><glue-rte-3><glue-rte-4><glue-rte-5><glue-rte-6><glue-rte-7><glue-rte-8><glue-rte-9>
01/17/2024 13:21:02 - INFO - __main__ - torch.Size([200, 1024])
01/17/2024 13:21:17 - INFO - __main__ - time use for computing 100 examples: 19.383277893066406
01/17/2024 13:21:17 - INFO - __main__ - start running soft prefix model
01/17/2024 13:21:17 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:21:21 - INFO - __main__ - Checking the first example...
Input:
negative sentence: the stars may be college kids, but the subject matter is as adult as you can get :
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/17/2024 13:21:21 - INFO - __main__ - torch.Size([200, 1024])
01/17/2024 13:21:36 - INFO - __main__ - time use for computing 100 examples: 18.636062622070312
01/17/2024 13:21:36 - INFO - __main__ - start running soft prefix model
01/17/2024 13:21:36 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:21:39 - INFO - __main__ - Checking the first example...
Input:
negative sentence: the stars may be college kids, but the subject matter is as adult as you can get :
Output:
<glue-wnli-0><glue-wnli-1><glue-wnli-2><glue-wnli-3><glue-wnli-4><glue-wnli-5><glue-wnli-6><glue-wnli-7><glue-wnli-8><glue-wnli-9>
01/17/2024 13:21:39 - INFO - __main__ - torch.Size([200, 1024])
01/17/2024 13:21:54 - INFO - __main__ - time use for computing 100 examples: 18.802435398101807
01/17/2024 13:21:54 - INFO - __main__ - min difficulty: -inf
01/17/2024 13:21:54 - INFO - __main__ - max difficulty: -inf
01/17/2024 13:21:54 - INFO - __main__ - average difficulty: -inf
01/17/2024 13:21:54 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:21:59 - INFO - __main__ - Checking the first example...
Input:
positive sentence: the stars may be college kids, but the subject matter is as adult as you can get : negative sentence:, it isn't much fun. negative sentence: a case of too many chefs fussing over too weak a recipe positive sentence: hubert with a mixture of deadpan cool, wry humor and just the measure of tenderness required to give this comic slugfest some heart
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/17/2024 13:21:59 - INFO - __main__ - torch.Size([24, 1024])
01/17/2024 13:22:01 - INFO - __main__ - time use for computing 24 examples: 4.667229413986206
01/17/2024 13:22:01 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:22:05 - INFO - __main__ - Checking the first example...
Input:
positive sentence: the stars may be college kids, but the subject matter is as adult as you can get : negative sentence:, it isn't much fun. negative sentence: a case of too many chefs fussing over too weak a recipe positive sentence: hubert with a mixture of deadpan cool, wry humor and just the measure of tenderness required to give this comic slugfest some heart
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/17/2024 13:22:05 - INFO - __main__ - torch.Size([24, 1024])
01/17/2024 13:22:07 - INFO - __main__ - time use for computing 24 examples: 5.03186821937561
01/17/2024 13:22:07 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:22:11 - INFO - __main__ - Checking the first example...
Input:
positive sentence: the stars may be college kids, but the subject matter is as adult as you can get : negative sentence:, it isn't much fun. negative sentence: a case of too many chefs fussing over too weak a recipe positive sentence: hubert with a mixture of deadpan cool, wry humor and just the measure of tenderness required to give this comic slugfest some heart
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/17/2024 13:22:11 - INFO - __main__ - torch.Size([24, 1024])
01/17/2024 13:22:14 - INFO - __main__ - time use for computing 24 examples: 4.965062618255615
01/17/2024 13:22:14 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:22:18 - INFO - __main__ - Checking the first example...
Input:
positive sentence: the stars may be college kids, but the subject matter is as adult as you can get : negative sentence:, it isn't much fun. negative sentence: a case of too many chefs fussing over too weak a recipe positive sentence: hubert with a mixture of deadpan cool, wry humor and just the measure of tenderness required to give this comic slugfest some heart
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/17/2024 13:22:18 - INFO - __main__ - torch.Size([24, 1024])
01/17/2024 13:22:20 - INFO - __main__ - time use for computing 24 examples: 4.833455801010132
01/17/2024 13:22:20 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:22:24 - INFO - __main__ - Checking the first example...
Input:
positive sentence: the stars may be college kids, but the subject matter is as adult as you can get : negative sentence:, it isn't much fun. negative sentence: a case of too many chefs fussing over too weak a recipe positive sentence: hubert with a mixture of deadpan cool, wry humor and just the measure of tenderness required to give this comic slugfest some heart
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/17/2024 13:22:24 - INFO - __main__ - torch.Size([24, 1024])
01/17/2024 13:22:27 - INFO - __main__ - time use for computing 24 examples: 5.341408967971802
01/17/2024 13:22:27 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:22:30 - INFO - __main__ - Checking the first example...
Input:
positive sentence: the stars may be college kids, but the subject matter is as adult as you can get : negative sentence:, it isn't much fun. negative sentence: a case of too many chefs fussing over too weak a recipe positive sentence: hubert with a mixture of deadpan cool, wry humor and just the measure of tenderness required to give this comic slugfest some heart
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/17/2024 13:22:30 - INFO - __main__ - torch.Size([24, 1024])
01/17/2024 13:22:32 - INFO - __main__ - time use for computing 24 examples: 4.276894569396973
01/17/2024 13:22:32 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:22:36 - INFO - __main__ - Checking the first example...
Input:
positive sentence: the stars may be college kids, but the subject matter is as adult as you can get : negative sentence:, it isn't much fun. negative sentence: a case of too many chefs fussing over too weak a recipe positive sentence: hubert with a mixture of deadpan cool, wry humor and just the measure of tenderness required to give this comic slugfest some heart
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/17/2024 13:22:36 - INFO - __main__ - torch.Size([24, 1024])
01/17/2024 13:22:38 - INFO - __main__ - time use for computing 24 examples: 4.311421871185303
01/17/2024 13:22:38 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:22:42 - INFO - __main__ - Checking the first example...
Input:
positive sentence: the stars may be college kids, but the subject matter is as adult as you can get : negative sentence:, it isn't much fun. negative sentence: a case of too many chefs fussing over too weak a recipe positive sentence: hubert with a mixture of deadpan cool, wry humor and just the measure of tenderness required to give this comic slugfest some heart
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/17/2024 13:22:42 - INFO - __main__ - torch.Size([24, 1024])
01/17/2024 13:22:44 - INFO - __main__ - time use for computing 24 examples: 4.488827228546143
01/17/2024 13:22:44 - INFO - __main__ - Checking the first example...
Input:
positive sentence: the stars may be college kids, but the subject matter is as adult as you can get : negative sentence:, it isn't much fun. negative sentence: a case of too many chefs fussing over too weak a recipe positive sentence: hubert with a mixture of deadpan cool, wry humor and just the measure of tenderness required to give this comic slugfest some heart negative
Output:
 sentence: it's a charming and often affecting journey.
01/17/2024 13:22:44 - INFO - __main__ - torch.Size([1744, 1024])
01/17/2024 13:24:58 - INFO - __main__ - None task (seed=100): Macro-F1: 78.7, Accuracy: 78.7
01/17/2024 13:24:59 - INFO - __main__ - [Train] glue-sst2	67349
01/17/2024 13:24:59 - INFO - __main__ - [Dev] glue-sst2	872
01/17/2024 13:24:59 - INFO - __main__ - channel on None (1 train, 1 dev)
01/17/2024 13:24:59 - INFO - __main__ - start running soft prefix model
01/17/2024 13:24:59 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:25:03 - INFO - __main__ - Checking the first example...
Input:
negative sentence: well worth revisiting as many times
Output:
<glue-cola-0><glue-cola-1><glue-cola-2><glue-cola-3><glue-cola-4><glue-cola-5><glue-cola-6><glue-cola-7><glue-cola-8><glue-cola-9>
01/17/2024 13:25:03 - INFO - __main__ - torch.Size([200, 1024])
01/17/2024 13:25:18 - INFO - __main__ - time use for computing 100 examples: 19.25933337211609
01/17/2024 13:25:18 - INFO - __main__ - start running soft prefix model
01/17/2024 13:25:18 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:25:22 - INFO - __main__ - Checking the first example...
Input:
negative sentence: well worth revisiting as many times
Output:
<glue-mnli-0><glue-mnli-1><glue-mnli-2><glue-mnli-3><glue-mnli-4><glue-mnli-5><glue-mnli-6><glue-mnli-7><glue-mnli-8><glue-mnli-9>
01/17/2024 13:25:22 - INFO - __main__ - torch.Size([200, 1024])
01/17/2024 13:25:37 - INFO - __main__ - time use for computing 100 examples: 18.73877716064453
01/17/2024 13:25:37 - INFO - __main__ - start running soft prefix model
01/17/2024 13:25:37 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:25:40 - INFO - __main__ - Checking the first example...
Input:
negative sentence: well worth revisiting as many times
Output:
<glue-qqp-0><glue-qqp-1><glue-qqp-2><glue-qqp-3><glue-qqp-4><glue-qqp-5><glue-qqp-6><glue-qqp-7><glue-qqp-8><glue-qqp-9>
01/17/2024 13:25:40 - INFO - __main__ - torch.Size([200, 1024])
01/17/2024 13:25:56 - INFO - __main__ - time use for computing 100 examples: 19.037906408309937
01/17/2024 13:25:56 - INFO - __main__ - start running soft prefix model
01/17/2024 13:25:56 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:26:00 - INFO - __main__ - Checking the first example...
Input:
negative sentence: well worth revisiting as many times
Output:
<glue-mrpc-0><glue-mrpc-1><glue-mrpc-2><glue-mrpc-3><glue-mrpc-4><glue-mrpc-5><glue-mrpc-6><glue-mrpc-7><glue-mrpc-8><glue-mrpc-9>
01/17/2024 13:26:00 - INFO - __main__ - torch.Size([200, 1024])
01/17/2024 13:26:15 - INFO - __main__ - time use for computing 100 examples: 19.14007878303528
01/17/2024 13:26:15 - INFO - __main__ - start running soft prefix model
01/17/2024 13:26:15 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:26:19 - INFO - __main__ - Checking the first example...
Input:
negative sentence: well worth revisiting as many times
Output:
<glue-qnli-0><glue-qnli-1><glue-qnli-2><glue-qnli-3><glue-qnli-4><glue-qnli-5><glue-qnli-6><glue-qnli-7><glue-qnli-8><glue-qnli-9>
01/17/2024 13:26:19 - INFO - __main__ - torch.Size([200, 1024])
01/17/2024 13:26:34 - INFO - __main__ - time use for computing 100 examples: 18.784010410308838
01/17/2024 13:26:34 - INFO - __main__ - start running soft prefix model
01/17/2024 13:26:34 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:26:37 - INFO - __main__ - Checking the first example...
Input:
negative sentence: well worth revisiting as many times
Output:
<glue-rte-0><glue-rte-1><glue-rte-2><glue-rte-3><glue-rte-4><glue-rte-5><glue-rte-6><glue-rte-7><glue-rte-8><glue-rte-9>
01/17/2024 13:26:37 - INFO - __main__ - torch.Size([200, 1024])
01/17/2024 13:26:52 - INFO - __main__ - time use for computing 100 examples: 18.65919065475464
01/17/2024 13:26:52 - INFO - __main__ - start running soft prefix model
01/17/2024 13:26:52 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:26:56 - INFO - __main__ - Checking the first example...
Input:
negative sentence: well worth revisiting as many times
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/17/2024 13:26:56 - INFO - __main__ - torch.Size([200, 1024])
01/17/2024 13:27:12 - INFO - __main__ - time use for computing 100 examples: 19.26768183708191
01/17/2024 13:27:12 - INFO - __main__ - start running soft prefix model
01/17/2024 13:27:12 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:27:15 - INFO - __main__ - Checking the first example...
Input:
negative sentence: well worth revisiting as many times
Output:
<glue-wnli-0><glue-wnli-1><glue-wnli-2><glue-wnli-3><glue-wnli-4><glue-wnli-5><glue-wnli-6><glue-wnli-7><glue-wnli-8><glue-wnli-9>
01/17/2024 13:27:15 - INFO - __main__ - torch.Size([200, 1024])
01/17/2024 13:27:30 - INFO - __main__ - time use for computing 100 examples: 18.564469814300537
01/17/2024 13:27:30 - INFO - __main__ - min difficulty: -inf
01/17/2024 13:27:30 - INFO - __main__ - max difficulty: -inf
01/17/2024 13:27:30 - INFO - __main__ - average difficulty: -inf
01/17/2024 13:27:30 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:27:33 - INFO - __main__ - Checking the first example...
Input:
positive sentence: well worth revisiting as many times negative sentence:'re just a couple of cops in copmovieland, these two positive sentence: is impressively true for being so hot-blooded positive sentence: like the rugrats movies, the wild thornberrys movie doesn't offer much more than the series, but its emphasis on caring for animals and respecting other cultures is particularly welcome
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/17/2024 13:27:33 - INFO - __main__ - torch.Size([24, 1024])
01/17/2024 13:27:35 - INFO - __main__ - time use for computing 24 examples: 4.067410230636597
01/17/2024 13:27:35 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:27:39 - INFO - __main__ - Checking the first example...
Input:
positive sentence: well worth revisiting as many times negative sentence:'re just a couple of cops in copmovieland, these two positive sentence: is impressively true for being so hot-blooded positive sentence: like the rugrats movies, the wild thornberrys movie doesn't offer much more than the series, but its emphasis on caring for animals and respecting other cultures is particularly welcome
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/17/2024 13:27:39 - INFO - __main__ - torch.Size([24, 1024])
01/17/2024 13:27:41 - INFO - __main__ - time use for computing 24 examples: 4.079103946685791
01/17/2024 13:27:41 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:27:48 - INFO - __main__ - Checking the first example...
Input:
positive sentence: well worth revisiting as many times negative sentence:'re just a couple of cops in copmovieland, these two positive sentence: is impressively true for being so hot-blooded positive sentence: like the rugrats movies, the wild thornberrys movie doesn't offer much more than the series, but its emphasis on caring for animals and respecting other cultures is particularly welcome
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/17/2024 13:27:48 - INFO - __main__ - torch.Size([24, 1024])
01/17/2024 13:27:50 - INFO - __main__ - time use for computing 24 examples: 7.2745702266693115
01/17/2024 13:27:50 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:27:53 - INFO - __main__ - Checking the first example...
Input:
positive sentence: well worth revisiting as many times negative sentence:'re just a couple of cops in copmovieland, these two positive sentence: is impressively true for being so hot-blooded positive sentence: like the rugrats movies, the wild thornberrys movie doesn't offer much more than the series, but its emphasis on caring for animals and respecting other cultures is particularly welcome
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/17/2024 13:27:53 - INFO - __main__ - torch.Size([24, 1024])
01/17/2024 13:27:55 - INFO - __main__ - time use for computing 24 examples: 4.3753087520599365
01/17/2024 13:27:55 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:27:59 - INFO - __main__ - Checking the first example...
Input:
positive sentence: well worth revisiting as many times negative sentence:'re just a couple of cops in copmovieland, these two positive sentence: is impressively true for being so hot-blooded positive sentence: like the rugrats movies, the wild thornberrys movie doesn't offer much more than the series, but its emphasis on caring for animals and respecting other cultures is particularly welcome
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/17/2024 13:27:59 - INFO - __main__ - torch.Size([24, 1024])
01/17/2024 13:28:01 - INFO - __main__ - time use for computing 24 examples: 4.499491930007935
01/17/2024 13:28:01 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:28:05 - INFO - __main__ - Checking the first example...
Input:
positive sentence: well worth revisiting as many times negative sentence:'re just a couple of cops in copmovieland, these two positive sentence: is impressively true for being so hot-blooded positive sentence: like the rugrats movies, the wild thornberrys movie doesn't offer much more than the series, but its emphasis on caring for animals and respecting other cultures is particularly welcome
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/17/2024 13:28:05 - INFO - __main__ - torch.Size([24, 1024])
01/17/2024 13:28:07 - INFO - __main__ - time use for computing 24 examples: 4.825359106063843
01/17/2024 13:28:07 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:28:11 - INFO - __main__ - Checking the first example...
Input:
positive sentence: well worth revisiting as many times negative sentence:'re just a couple of cops in copmovieland, these two positive sentence: is impressively true for being so hot-blooded positive sentence: like the rugrats movies, the wild thornberrys movie doesn't offer much more than the series, but its emphasis on caring for animals and respecting other cultures is particularly welcome
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/17/2024 13:28:11 - INFO - __main__ - torch.Size([24, 1024])
01/17/2024 13:28:13 - INFO - __main__ - time use for computing 24 examples: 4.29520058631897
01/17/2024 13:28:13 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:28:17 - INFO - __main__ - Checking the first example...
Input:
positive sentence: well worth revisiting as many times negative sentence:'re just a couple of cops in copmovieland, these two positive sentence: is impressively true for being so hot-blooded positive sentence: like the rugrats movies, the wild thornberrys movie doesn't offer much more than the series, but its emphasis on caring for animals and respecting other cultures is particularly welcome
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/17/2024 13:28:17 - INFO - __main__ - torch.Size([24, 1024])
01/17/2024 13:28:19 - INFO - __main__ - time use for computing 24 examples: 4.1815876960754395
01/17/2024 13:28:19 - INFO - __main__ - Checking the first example...
Input:
positive sentence: well worth revisiting as many times negative sentence:'re just a couple of cops in copmovieland, these two positive sentence: is impressively true for being so hot-blooded positive sentence: like the rugrats movies, the wild thornberrys movie doesn't offer much more than the series, but its emphasis on caring for animals and respecting other cultures is particularly welcome negative
Output:
 sentence: it's a charming and often affecting journey.
01/17/2024 13:28:19 - INFO - __main__ - torch.Size([1744, 1024])
01/17/2024 13:30:34 - INFO - __main__ - None task (seed=13): Macro-F1: 78.4, Accuracy: 78.4
01/17/2024 13:30:34 - INFO - __main__ - [Train] glue-sst2	67349
01/17/2024 13:30:34 - INFO - __main__ - [Dev] glue-sst2	872
01/17/2024 13:30:34 - INFO - __main__ - channel on None (1 train, 1 dev)
01/17/2024 13:30:34 - INFO - __main__ - start running soft prefix model
01/17/2024 13:30:34 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:30:38 - INFO - __main__ - Checking the first example...
Input:
negative sentence: in his role of observer of the scene, lawrence sounds whiny and defensive, as if his life-altering experiences made him bitter and less mature.
Output:
<glue-cola-0><glue-cola-1><glue-cola-2><glue-cola-3><glue-cola-4><glue-cola-5><glue-cola-6><glue-cola-7><glue-cola-8><glue-cola-9>
01/17/2024 13:30:38 - INFO - __main__ - torch.Size([200, 1024])
01/17/2024 13:30:53 - INFO - __main__ - time use for computing 100 examples: 19.565085887908936
01/17/2024 13:30:53 - INFO - __main__ - start running soft prefix model
01/17/2024 13:30:53 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:30:57 - INFO - __main__ - Checking the first example...
Input:
negative sentence: in his role of observer of the scene, lawrence sounds whiny and defensive, as if his life-altering experiences made him bitter and less mature.
Output:
<glue-mnli-0><glue-mnli-1><glue-mnli-2><glue-mnli-3><glue-mnli-4><glue-mnli-5><glue-mnli-6><glue-mnli-7><glue-mnli-8><glue-mnli-9>
01/17/2024 13:30:57 - INFO - __main__ - torch.Size([200, 1024])
01/17/2024 13:31:12 - INFO - __main__ - time use for computing 100 examples: 18.951488494873047
01/17/2024 13:31:12 - INFO - __main__ - start running soft prefix model
01/17/2024 13:31:12 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:31:17 - INFO - __main__ - Checking the first example...
Input:
negative sentence: in his role of observer of the scene, lawrence sounds whiny and defensive, as if his life-altering experiences made him bitter and less mature.
Output:
<glue-qqp-0><glue-qqp-1><glue-qqp-2><glue-qqp-3><glue-qqp-4><glue-qqp-5><glue-qqp-6><glue-qqp-7><glue-qqp-8><glue-qqp-9>
01/17/2024 13:31:17 - INFO - __main__ - torch.Size([200, 1024])
01/17/2024 13:31:32 - INFO - __main__ - time use for computing 100 examples: 19.532307147979736
01/17/2024 13:31:32 - INFO - __main__ - start running soft prefix model
01/17/2024 13:31:32 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:31:36 - INFO - __main__ - Checking the first example...
Input:
negative sentence: in his role of observer of the scene, lawrence sounds whiny and defensive, as if his life-altering experiences made him bitter and less mature.
Output:
<glue-mrpc-0><glue-mrpc-1><glue-mrpc-2><glue-mrpc-3><glue-mrpc-4><glue-mrpc-5><glue-mrpc-6><glue-mrpc-7><glue-mrpc-8><glue-mrpc-9>
01/17/2024 13:31:36 - INFO - __main__ - torch.Size([200, 1024])
01/17/2024 13:31:51 - INFO - __main__ - time use for computing 100 examples: 19.247937440872192
01/17/2024 13:31:51 - INFO - __main__ - start running soft prefix model
01/17/2024 13:31:51 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:31:56 - INFO - __main__ - Checking the first example...
Input:
negative sentence: in his role of observer of the scene, lawrence sounds whiny and defensive, as if his life-altering experiences made him bitter and less mature.
Output:
<glue-qnli-0><glue-qnli-1><glue-qnli-2><glue-qnli-3><glue-qnli-4><glue-qnli-5><glue-qnli-6><glue-qnli-7><glue-qnli-8><glue-qnli-9>
01/17/2024 13:31:56 - INFO - __main__ - torch.Size([200, 1024])
01/17/2024 13:32:11 - INFO - __main__ - time use for computing 100 examples: 19.600883722305298
01/17/2024 13:32:11 - INFO - __main__ - start running soft prefix model
01/17/2024 13:32:11 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:32:15 - INFO - __main__ - Checking the first example...
Input:
negative sentence: in his role of observer of the scene, lawrence sounds whiny and defensive, as if his life-altering experiences made him bitter and less mature.
Output:
<glue-rte-0><glue-rte-1><glue-rte-2><glue-rte-3><glue-rte-4><glue-rte-5><glue-rte-6><glue-rte-7><glue-rte-8><glue-rte-9>
01/17/2024 13:32:15 - INFO - __main__ - torch.Size([200, 1024])
01/17/2024 13:32:30 - INFO - __main__ - time use for computing 100 examples: 19.035354137420654
01/17/2024 13:32:30 - INFO - __main__ - start running soft prefix model
01/17/2024 13:32:30 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:32:34 - INFO - __main__ - Checking the first example...
Input:
negative sentence: in his role of observer of the scene, lawrence sounds whiny and defensive, as if his life-altering experiences made him bitter and less mature.
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/17/2024 13:32:34 - INFO - __main__ - torch.Size([200, 1024])
01/17/2024 13:32:49 - INFO - __main__ - time use for computing 100 examples: 19.340776205062866
01/17/2024 13:32:49 - INFO - __main__ - start running soft prefix model
01/17/2024 13:32:49 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:32:53 - INFO - __main__ - Checking the first example...
Input:
negative sentence: in his role of observer of the scene, lawrence sounds whiny and defensive, as if his life-altering experiences made him bitter and less mature.
Output:
<glue-wnli-0><glue-wnli-1><glue-wnli-2><glue-wnli-3><glue-wnli-4><glue-wnli-5><glue-wnli-6><glue-wnli-7><glue-wnli-8><glue-wnli-9>
01/17/2024 13:32:53 - INFO - __main__ - torch.Size([200, 1024])
01/17/2024 13:33:08 - INFO - __main__ - time use for computing 100 examples: 19.199833154678345
01/17/2024 13:33:08 - INFO - __main__ - min difficulty: -inf
01/17/2024 13:33:08 - INFO - __main__ - max difficulty: -inf
01/17/2024 13:33:08 - INFO - __main__ - average difficulty: -inf
01/17/2024 13:33:08 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:33:12 - INFO - __main__ - Checking the first example...
Input:
negative sentence: in his role of observer of the scene, lawrence sounds whiny and defensive, as if his life-altering experiences made him bitter and less mature. negative sentence: disgusted positive sentence: self-promotion ends and negative sentence: while american adobo has its heart ( and its palate ) in the right place, its brain is a little scattered -- ditsy, even.
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/17/2024 13:33:12 - INFO - __main__ - torch.Size([24, 1024])
01/17/2024 13:33:14 - INFO - __main__ - time use for computing 24 examples: 4.1924378871917725
01/17/2024 13:33:14 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:33:17 - INFO - __main__ - Checking the first example...
Input:
negative sentence: in his role of observer of the scene, lawrence sounds whiny and defensive, as if his life-altering experiences made him bitter and less mature. negative sentence: disgusted positive sentence: self-promotion ends and negative sentence: while american adobo has its heart ( and its palate ) in the right place, its brain is a little scattered -- ditsy, even.
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/17/2024 13:33:17 - INFO - __main__ - torch.Size([24, 1024])
01/17/2024 13:33:19 - INFO - __main__ - time use for computing 24 examples: 4.308467864990234
01/17/2024 13:33:19 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:33:23 - INFO - __main__ - Checking the first example...
Input:
negative sentence: in his role of observer of the scene, lawrence sounds whiny and defensive, as if his life-altering experiences made him bitter and less mature. negative sentence: disgusted positive sentence: self-promotion ends and negative sentence: while american adobo has its heart ( and its palate ) in the right place, its brain is a little scattered -- ditsy, even.
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/17/2024 13:33:23 - INFO - __main__ - torch.Size([24, 1024])
01/17/2024 13:33:25 - INFO - __main__ - time use for computing 24 examples: 4.292628765106201
01/17/2024 13:33:25 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:33:29 - INFO - __main__ - Checking the first example...
Input:
negative sentence: in his role of observer of the scene, lawrence sounds whiny and defensive, as if his life-altering experiences made him bitter and less mature. negative sentence: disgusted positive sentence: self-promotion ends and negative sentence: while american adobo has its heart ( and its palate ) in the right place, its brain is a little scattered -- ditsy, even.
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/17/2024 13:33:29 - INFO - __main__ - torch.Size([24, 1024])
01/17/2024 13:33:31 - INFO - __main__ - time use for computing 24 examples: 4.617227077484131
01/17/2024 13:33:31 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:33:35 - INFO - __main__ - Checking the first example...
Input:
negative sentence: in his role of observer of the scene, lawrence sounds whiny and defensive, as if his life-altering experiences made him bitter and less mature. negative sentence: disgusted positive sentence: self-promotion ends and negative sentence: while american adobo has its heart ( and its palate ) in the right place, its brain is a little scattered -- ditsy, even.
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/17/2024 13:33:35 - INFO - __main__ - torch.Size([24, 1024])
01/17/2024 13:33:37 - INFO - __main__ - time use for computing 24 examples: 4.245244979858398
01/17/2024 13:33:37 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:33:40 - INFO - __main__ - Checking the first example...
Input:
negative sentence: in his role of observer of the scene, lawrence sounds whiny and defensive, as if his life-altering experiences made him bitter and less mature. negative sentence: disgusted positive sentence: self-promotion ends and negative sentence: while american adobo has its heart ( and its palate ) in the right place, its brain is a little scattered -- ditsy, even.
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/17/2024 13:33:40 - INFO - __main__ - torch.Size([24, 1024])
01/17/2024 13:33:42 - INFO - __main__ - time use for computing 24 examples: 4.201569318771362
01/17/2024 13:33:42 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:33:46 - INFO - __main__ - Checking the first example...
Input:
negative sentence: in his role of observer of the scene, lawrence sounds whiny and defensive, as if his life-altering experiences made him bitter and less mature. negative sentence: disgusted positive sentence: self-promotion ends and negative sentence: while american adobo has its heart ( and its palate ) in the right place, its brain is a little scattered -- ditsy, even.
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/17/2024 13:33:46 - INFO - __main__ - torch.Size([24, 1024])
01/17/2024 13:33:48 - INFO - __main__ - time use for computing 24 examples: 4.345361232757568
01/17/2024 13:33:48 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:33:52 - INFO - __main__ - Checking the first example...
Input:
negative sentence: in his role of observer of the scene, lawrence sounds whiny and defensive, as if his life-altering experiences made him bitter and less mature. negative sentence: disgusted positive sentence: self-promotion ends and negative sentence: while american adobo has its heart ( and its palate ) in the right place, its brain is a little scattered -- ditsy, even.
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/17/2024 13:33:52 - INFO - __main__ - torch.Size([24, 1024])
01/17/2024 13:33:54 - INFO - __main__ - time use for computing 24 examples: 4.266091823577881
01/17/2024 13:33:55 - INFO - __main__ - Checking the first example...
Input:
negative sentence: in his role of observer of the scene, lawrence sounds whiny and defensive, as if his life-altering experiences made him bitter and less mature. negative sentence: disgusted positive sentence: self-promotion ends and negative sentence: while american adobo has its heart ( and its palate ) in the right place, its brain is a little scattered -- ditsy, even. negative
Output:
 sentence: it's a charming and often affecting journey.
01/17/2024 13:33:55 - INFO - __main__ - torch.Size([1744, 1024])
01/17/2024 13:36:09 - INFO - __main__ - None task (seed=21): Macro-F1: 72.5, Accuracy: 72.8
01/17/2024 13:36:09 - INFO - __main__ - [Train] glue-sst2	67349
01/17/2024 13:36:09 - INFO - __main__ - [Dev] glue-sst2	872
01/17/2024 13:36:09 - INFO - __main__ - channel on None (1 train, 1 dev)
01/17/2024 13:36:09 - INFO - __main__ - start running soft prefix model
01/17/2024 13:36:09 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:36:13 - INFO - __main__ - Checking the first example...
Input:
negative sentence: with outtakes in which most of the characters forget their lines and just utter ` uhhh,'which is better than most of the writing in the movie
Output:
<glue-cola-0><glue-cola-1><glue-cola-2><glue-cola-3><glue-cola-4><glue-cola-5><glue-cola-6><glue-cola-7><glue-cola-8><glue-cola-9>
01/17/2024 13:36:13 - INFO - __main__ - torch.Size([200, 1024])
01/17/2024 13:36:28 - INFO - __main__ - time use for computing 100 examples: 18.71872091293335
01/17/2024 13:36:28 - INFO - __main__ - start running soft prefix model
01/17/2024 13:36:28 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:36:32 - INFO - __main__ - Checking the first example...
Input:
negative sentence: with outtakes in which most of the characters forget their lines and just utter ` uhhh,'which is better than most of the writing in the movie
Output:
<glue-mnli-0><glue-mnli-1><glue-mnli-2><glue-mnli-3><glue-mnli-4><glue-mnli-5><glue-mnli-6><glue-mnli-7><glue-mnli-8><glue-mnli-9>
01/17/2024 13:36:32 - INFO - __main__ - torch.Size([200, 1024])
01/17/2024 13:36:47 - INFO - __main__ - time use for computing 100 examples: 18.892655849456787
01/17/2024 13:36:47 - INFO - __main__ - start running soft prefix model
01/17/2024 13:36:47 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:36:51 - INFO - __main__ - Checking the first example...
Input:
negative sentence: with outtakes in which most of the characters forget their lines and just utter ` uhhh,'which is better than most of the writing in the movie
Output:
<glue-qqp-0><glue-qqp-1><glue-qqp-2><glue-qqp-3><glue-qqp-4><glue-qqp-5><glue-qqp-6><glue-qqp-7><glue-qqp-8><glue-qqp-9>
01/17/2024 13:36:51 - INFO - __main__ - torch.Size([200, 1024])
01/17/2024 13:37:06 - INFO - __main__ - time use for computing 100 examples: 18.91571021080017
01/17/2024 13:37:06 - INFO - __main__ - start running soft prefix model
01/17/2024 13:37:06 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:37:10 - INFO - __main__ - Checking the first example...
Input:
negative sentence: with outtakes in which most of the characters forget their lines and just utter ` uhhh,'which is better than most of the writing in the movie
Output:
<glue-mrpc-0><glue-mrpc-1><glue-mrpc-2><glue-mrpc-3><glue-mrpc-4><glue-mrpc-5><glue-mrpc-6><glue-mrpc-7><glue-mrpc-8><glue-mrpc-9>
01/17/2024 13:37:10 - INFO - __main__ - torch.Size([200, 1024])
01/17/2024 13:37:25 - INFO - __main__ - time use for computing 100 examples: 19.288591146469116
01/17/2024 13:37:25 - INFO - __main__ - start running soft prefix model
01/17/2024 13:37:25 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:37:29 - INFO - __main__ - Checking the first example...
Input:
negative sentence: with outtakes in which most of the characters forget their lines and just utter ` uhhh,'which is better than most of the writing in the movie
Output:
<glue-qnli-0><glue-qnli-1><glue-qnli-2><glue-qnli-3><glue-qnli-4><glue-qnli-5><glue-qnli-6><glue-qnli-7><glue-qnli-8><glue-qnli-9>
01/17/2024 13:37:29 - INFO - __main__ - torch.Size([200, 1024])
01/17/2024 13:37:44 - INFO - __main__ - time use for computing 100 examples: 19.139400243759155
01/17/2024 13:37:44 - INFO - __main__ - start running soft prefix model
01/17/2024 13:37:44 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:37:48 - INFO - __main__ - Checking the first example...
Input:
negative sentence: with outtakes in which most of the characters forget their lines and just utter ` uhhh,'which is better than most of the writing in the movie
Output:
<glue-rte-0><glue-rte-1><glue-rte-2><glue-rte-3><glue-rte-4><glue-rte-5><glue-rte-6><glue-rte-7><glue-rte-8><glue-rte-9>
01/17/2024 13:37:48 - INFO - __main__ - torch.Size([200, 1024])
01/17/2024 13:38:03 - INFO - __main__ - time use for computing 100 examples: 18.96844983100891
01/17/2024 13:38:03 - INFO - __main__ - start running soft prefix model
01/17/2024 13:38:03 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:38:08 - INFO - __main__ - Checking the first example...
Input:
negative sentence: with outtakes in which most of the characters forget their lines and just utter ` uhhh,'which is better than most of the writing in the movie
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/17/2024 13:38:08 - INFO - __main__ - torch.Size([200, 1024])
01/17/2024 13:38:23 - INFO - __main__ - time use for computing 100 examples: 19.66237783432007
01/17/2024 13:38:23 - INFO - __main__ - start running soft prefix model
01/17/2024 13:38:23 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:38:27 - INFO - __main__ - Checking the first example...
Input:
negative sentence: with outtakes in which most of the characters forget their lines and just utter ` uhhh,'which is better than most of the writing in the movie
Output:
<glue-wnli-0><glue-wnli-1><glue-wnli-2><glue-wnli-3><glue-wnli-4><glue-wnli-5><glue-wnli-6><glue-wnli-7><glue-wnli-8><glue-wnli-9>
01/17/2024 13:38:27 - INFO - __main__ - torch.Size([200, 1024])
01/17/2024 13:38:42 - INFO - __main__ - time use for computing 100 examples: 18.872393369674683
01/17/2024 13:38:42 - INFO - __main__ - min difficulty: -inf
01/17/2024 13:38:42 - INFO - __main__ - max difficulty: -inf
01/17/2024 13:38:42 - INFO - __main__ - average difficulty: -inf
01/17/2024 13:38:42 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:38:46 - INFO - __main__ - Checking the first example...
Input:
negative sentence: with outtakes in which most of the characters forget their lines and just utter ` uhhh,'which is better than most of the writing in the movie negative sentence: gets very ugly, very fast negative sentence: called best bad film you thought was going to be really awful but positive sentence: delicate treatment
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/17/2024 13:38:46 - INFO - __main__ - torch.Size([24, 1024])
01/17/2024 13:38:48 - INFO - __main__ - time use for computing 24 examples: 4.8842315673828125
01/17/2024 13:38:48 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:38:52 - INFO - __main__ - Checking the first example...
Input:
negative sentence: with outtakes in which most of the characters forget their lines and just utter ` uhhh,'which is better than most of the writing in the movie negative sentence: gets very ugly, very fast negative sentence: called best bad film you thought was going to be really awful but positive sentence: delicate treatment
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/17/2024 13:38:52 - INFO - __main__ - torch.Size([24, 1024])
01/17/2024 13:38:54 - INFO - __main__ - time use for computing 24 examples: 4.699720859527588
01/17/2024 13:38:54 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:38:58 - INFO - __main__ - Checking the first example...
Input:
negative sentence: with outtakes in which most of the characters forget their lines and just utter ` uhhh,'which is better than most of the writing in the movie negative sentence: gets very ugly, very fast negative sentence: called best bad film you thought was going to be really awful but positive sentence: delicate treatment
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/17/2024 13:38:58 - INFO - __main__ - torch.Size([24, 1024])
01/17/2024 13:39:00 - INFO - __main__ - time use for computing 24 examples: 4.308062791824341
01/17/2024 13:39:00 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:39:04 - INFO - __main__ - Checking the first example...
Input:
negative sentence: with outtakes in which most of the characters forget their lines and just utter ` uhhh,'which is better than most of the writing in the movie negative sentence: gets very ugly, very fast negative sentence: called best bad film you thought was going to be really awful but positive sentence: delicate treatment
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/17/2024 13:39:04 - INFO - __main__ - torch.Size([24, 1024])
01/17/2024 13:39:06 - INFO - __main__ - time use for computing 24 examples: 4.816232204437256
01/17/2024 13:39:06 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:39:10 - INFO - __main__ - Checking the first example...
Input:
negative sentence: with outtakes in which most of the characters forget their lines and just utter ` uhhh,'which is better than most of the writing in the movie negative sentence: gets very ugly, very fast negative sentence: called best bad film you thought was going to be really awful but positive sentence: delicate treatment
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/17/2024 13:39:10 - INFO - __main__ - torch.Size([24, 1024])
01/17/2024 13:39:12 - INFO - __main__ - time use for computing 24 examples: 4.920488357543945
01/17/2024 13:39:12 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:39:17 - INFO - __main__ - Checking the first example...
Input:
negative sentence: with outtakes in which most of the characters forget their lines and just utter ` uhhh,'which is better than most of the writing in the movie negative sentence: gets very ugly, very fast negative sentence: called best bad film you thought was going to be really awful but positive sentence: delicate treatment
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/17/2024 13:39:17 - INFO - __main__ - torch.Size([24, 1024])
01/17/2024 13:39:19 - INFO - __main__ - time use for computing 24 examples: 4.93477201461792
01/17/2024 13:39:19 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:39:23 - INFO - __main__ - Checking the first example...
Input:
negative sentence: with outtakes in which most of the characters forget their lines and just utter ` uhhh,'which is better than most of the writing in the movie negative sentence: gets very ugly, very fast negative sentence: called best bad film you thought was going to be really awful but positive sentence: delicate treatment
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/17/2024 13:39:23 - INFO - __main__ - torch.Size([24, 1024])
01/17/2024 13:39:25 - INFO - __main__ - time use for computing 24 examples: 4.41292405128479
01/17/2024 13:39:25 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:39:29 - INFO - __main__ - Checking the first example...
Input:
negative sentence: with outtakes in which most of the characters forget their lines and just utter ` uhhh,'which is better than most of the writing in the movie negative sentence: gets very ugly, very fast negative sentence: called best bad film you thought was going to be really awful but positive sentence: delicate treatment
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/17/2024 13:39:29 - INFO - __main__ - torch.Size([24, 1024])
01/17/2024 13:39:31 - INFO - __main__ - time use for computing 24 examples: 4.696887254714966
01/17/2024 13:39:31 - INFO - __main__ - Checking the first example...
Input:
negative sentence: with outtakes in which most of the characters forget their lines and just utter ` uhhh,'which is better than most of the writing in the movie negative sentence: gets very ugly, very fast negative sentence: called best bad film you thought was going to be really awful but positive sentence: delicate treatment negative
Output:
 sentence: it's a charming and often affecting journey.
01/17/2024 13:39:31 - INFO - __main__ - torch.Size([1744, 1024])
01/17/2024 13:41:46 - INFO - __main__ - None task (seed=42): Macro-F1: 68.9, Accuracy: 69.2
01/17/2024 13:41:46 - INFO - __main__ - [Train] glue-sst2	67349
01/17/2024 13:41:46 - INFO - __main__ - [Dev] glue-sst2	872
01/17/2024 13:41:46 - INFO - __main__ - channel on None (1 train, 1 dev)
01/17/2024 13:41:46 - INFO - __main__ - start running soft prefix model
01/17/2024 13:41:46 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:41:50 - INFO - __main__ - Checking the first example...
Input:
negative sentence: titular
Output:
<glue-cola-0><glue-cola-1><glue-cola-2><glue-cola-3><glue-cola-4><glue-cola-5><glue-cola-6><glue-cola-7><glue-cola-8><glue-cola-9>
01/17/2024 13:41:50 - INFO - __main__ - torch.Size([200, 1024])
01/17/2024 13:42:06 - INFO - __main__ - time use for computing 100 examples: 19.5913667678833
01/17/2024 13:42:06 - INFO - __main__ - start running soft prefix model
01/17/2024 13:42:06 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:42:11 - INFO - __main__ - Checking the first example...
Input:
negative sentence: titular
Output:
<glue-mnli-0><glue-mnli-1><glue-mnli-2><glue-mnli-3><glue-mnli-4><glue-mnli-5><glue-mnli-6><glue-mnli-7><glue-mnli-8><glue-mnli-9>
01/17/2024 13:42:11 - INFO - __main__ - torch.Size([200, 1024])
01/17/2024 13:42:27 - INFO - __main__ - time use for computing 100 examples: 21.065857887268066
01/17/2024 13:42:27 - INFO - __main__ - start running soft prefix model
01/17/2024 13:42:27 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:42:32 - INFO - __main__ - Checking the first example...
Input:
negative sentence: titular
Output:
<glue-qqp-0><glue-qqp-1><glue-qqp-2><glue-qqp-3><glue-qqp-4><glue-qqp-5><glue-qqp-6><glue-qqp-7><glue-qqp-8><glue-qqp-9>
01/17/2024 13:42:32 - INFO - __main__ - torch.Size([200, 1024])
01/17/2024 13:42:47 - INFO - __main__ - time use for computing 100 examples: 20.196561813354492
01/17/2024 13:42:47 - INFO - __main__ - start running soft prefix model
01/17/2024 13:42:47 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:42:51 - INFO - __main__ - Checking the first example...
Input:
negative sentence: titular
Output:
<glue-mrpc-0><glue-mrpc-1><glue-mrpc-2><glue-mrpc-3><glue-mrpc-4><glue-mrpc-5><glue-mrpc-6><glue-mrpc-7><glue-mrpc-8><glue-mrpc-9>
01/17/2024 13:42:51 - INFO - __main__ - torch.Size([200, 1024])
01/17/2024 13:43:06 - INFO - __main__ - time use for computing 100 examples: 19.335709810256958
01/17/2024 13:43:06 - INFO - __main__ - start running soft prefix model
01/17/2024 13:43:06 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:43:10 - INFO - __main__ - Checking the first example...
Input:
negative sentence: titular
Output:
<glue-qnli-0><glue-qnli-1><glue-qnli-2><glue-qnli-3><glue-qnli-4><glue-qnli-5><glue-qnli-6><glue-qnli-7><glue-qnli-8><glue-qnli-9>
01/17/2024 13:43:10 - INFO - __main__ - torch.Size([200, 1024])
01/17/2024 13:43:25 - INFO - __main__ - time use for computing 100 examples: 18.763084411621094
01/17/2024 13:43:25 - INFO - __main__ - start running soft prefix model
01/17/2024 13:43:25 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:43:29 - INFO - __main__ - Checking the first example...
Input:
negative sentence: titular
Output:
<glue-rte-0><glue-rte-1><glue-rte-2><glue-rte-3><glue-rte-4><glue-rte-5><glue-rte-6><glue-rte-7><glue-rte-8><glue-rte-9>
01/17/2024 13:43:29 - INFO - __main__ - torch.Size([200, 1024])
01/17/2024 13:43:44 - INFO - __main__ - time use for computing 100 examples: 19.070727348327637
01/17/2024 13:43:44 - INFO - __main__ - start running soft prefix model
01/17/2024 13:43:44 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:43:48 - INFO - __main__ - Checking the first example...
Input:
negative sentence: titular
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/17/2024 13:43:48 - INFO - __main__ - torch.Size([200, 1024])
01/17/2024 13:44:04 - INFO - __main__ - time use for computing 100 examples: 19.579150199890137
01/17/2024 13:44:04 - INFO - __main__ - start running soft prefix model
01/17/2024 13:44:04 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:44:07 - INFO - __main__ - Checking the first example...
Input:
negative sentence: titular
Output:
<glue-wnli-0><glue-wnli-1><glue-wnli-2><glue-wnli-3><glue-wnli-4><glue-wnli-5><glue-wnli-6><glue-wnli-7><glue-wnli-8><glue-wnli-9>
01/17/2024 13:44:07 - INFO - __main__ - torch.Size([200, 1024])
01/17/2024 13:44:22 - INFO - __main__ - time use for computing 100 examples: 18.73804473876953
01/17/2024 13:44:22 - INFO - __main__ - min difficulty: -inf
01/17/2024 13:44:22 - INFO - __main__ - max difficulty: -inf
01/17/2024 13:44:22 - INFO - __main__ - average difficulty: -inf
01/17/2024 13:44:22 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:44:26 - INFO - __main__ - Checking the first example...
Input:
positive sentence: titular positive sentence: various amusing sidekicks negative sentence: loses its sense of humor negative sentence: maintaining consciousness just long enough to achieve callow pretension
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/17/2024 13:44:26 - INFO - __main__ - torch.Size([24, 1024])
01/17/2024 13:44:28 - INFO - __main__ - time use for computing 24 examples: 4.449251890182495
01/17/2024 13:44:28 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:44:32 - INFO - __main__ - Checking the first example...
Input:
positive sentence: titular positive sentence: various amusing sidekicks negative sentence: loses its sense of humor negative sentence: maintaining consciousness just long enough to achieve callow pretension
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/17/2024 13:44:32 - INFO - __main__ - torch.Size([24, 1024])
01/17/2024 13:44:34 - INFO - __main__ - time use for computing 24 examples: 4.17912220954895
01/17/2024 13:44:34 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:44:37 - INFO - __main__ - Checking the first example...
Input:
positive sentence: titular positive sentence: various amusing sidekicks negative sentence: loses its sense of humor negative sentence: maintaining consciousness just long enough to achieve callow pretension
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/17/2024 13:44:37 - INFO - __main__ - torch.Size([24, 1024])
01/17/2024 13:44:39 - INFO - __main__ - time use for computing 24 examples: 4.431641101837158
01/17/2024 13:44:39 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:44:44 - INFO - __main__ - Checking the first example...
Input:
positive sentence: titular positive sentence: various amusing sidekicks negative sentence: loses its sense of humor negative sentence: maintaining consciousness just long enough to achieve callow pretension
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/17/2024 13:44:44 - INFO - __main__ - torch.Size([24, 1024])
01/17/2024 13:44:46 - INFO - __main__ - time use for computing 24 examples: 5.069882869720459
01/17/2024 13:44:46 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:44:50 - INFO - __main__ - Checking the first example...
Input:
positive sentence: titular positive sentence: various amusing sidekicks negative sentence: loses its sense of humor negative sentence: maintaining consciousness just long enough to achieve callow pretension
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/17/2024 13:44:50 - INFO - __main__ - torch.Size([24, 1024])
01/17/2024 13:44:52 - INFO - __main__ - time use for computing 24 examples: 4.650854587554932
01/17/2024 13:44:52 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:44:56 - INFO - __main__ - Checking the first example...
Input:
positive sentence: titular positive sentence: various amusing sidekicks negative sentence: loses its sense of humor negative sentence: maintaining consciousness just long enough to achieve callow pretension
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/17/2024 13:44:56 - INFO - __main__ - torch.Size([24, 1024])
01/17/2024 13:44:58 - INFO - __main__ - time use for computing 24 examples: 4.5283119678497314
01/17/2024 13:44:58 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:45:02 - INFO - __main__ - Checking the first example...
Input:
positive sentence: titular positive sentence: various amusing sidekicks negative sentence: loses its sense of humor negative sentence: maintaining consciousness just long enough to achieve callow pretension
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/17/2024 13:45:02 - INFO - __main__ - torch.Size([24, 1024])
01/17/2024 13:45:04 - INFO - __main__ - time use for computing 24 examples: 4.706279277801514
01/17/2024 13:45:04 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/17/2024 13:45:08 - INFO - __main__ - Checking the first example...
Input:
positive sentence: titular positive sentence: various amusing sidekicks negative sentence: loses its sense of humor negative sentence: maintaining consciousness just long enough to achieve callow pretension
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/17/2024 13:45:08 - INFO - __main__ - torch.Size([24, 1024])
01/17/2024 13:45:10 - INFO - __main__ - time use for computing 24 examples: 4.827654600143433
01/17/2024 13:45:11 - INFO - __main__ - Checking the first example...
Input:
positive sentence: titular positive sentence: various amusing sidekicks negative sentence: loses its sense of humor negative sentence: maintaining consciousness just long enough to achieve callow pretension negative
Output:
 sentence: it's a charming and often affecting journey.
01/17/2024 13:45:11 - INFO - __main__ - torch.Size([1744, 1024])
01/17/2024 13:47:25 - INFO - __main__ - None task (seed=87): Macro-F1: 66.2, Accuracy: 67.0
01/17/2024 13:47:25 - INFO - __main__ - None over 1 target tasks with majority vote: Macro-F1: 78.9, Accuracy: 78.9
01/17/2024 13:47:25 - INFO - __main__ - None over 1 target tasks on average: Macro-F1: 72.9 +- 5.0, Accuracy: 73.2 +- 4.7
