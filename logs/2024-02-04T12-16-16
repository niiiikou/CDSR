02/04/2024 12:16:16 - INFO - __main__ - Namespace(use_demonstrations=True, use_soft_prefix=False, use_soft_postfix=False, n_prefix_tokens=10, max_length=1024, prior=['easiest'], difficulty='concept_calibrated', reorder=True, log_dir='logs', out_dir='out\\gpt2', load_dir=None, concept_dir='concept_likelihood\\gpt2\\glue-glue-100\\glue-sst2-channel-prefix=10-lr=1e-5-3000', prefix_embed_file='checkpoints\\gpt2\\glue-glue\\prefix={10}-{channel}-lr={1e-5}-initByVocab\\soft_embeddings-3000.pt', task=None, dataset='glue-sst2', data_dir='data/', k=4, seed='100,13,21,42,87', test_batch_size=8, global_step=None, use_random_english_words=False, use_random_label=False, use_instruction=False, unseen_domain_only=False, split='test', method='channel', gpt='gpt2', api=None, test_size=1000, train_size=100, embedding_dir='embeddings\\', embedding_model='all-mpnet-base-v2', similarity_temperature=0.1, concept_temperature=50.0)
02/04/2024 12:16:18 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:16:19 - INFO - __main__ - batch_size=8	max_length=1024	max_length_per_example=256
02/04/2024 12:16:20 - INFO - __main__ - [Train] glue-sst2	67349
02/04/2024 12:16:20 - INFO - __main__ - [Dev] glue-sst2	872
02/04/2024 12:16:20 - INFO - __main__ - channel on None (1 train, 1 dev)
02/04/2024 12:16:20 - INFO - __main__ - start running soft prefix model
02/04/2024 12:16:20 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:16:21 - INFO - __main__ - Checking the first example...
Input:
negative sentence: the stars may be college kids, but the subject matter is as adult as you can get :
Output:
<glue-cola-0><glue-cola-1><glue-cola-2><glue-cola-3><glue-cola-4><glue-cola-5><glue-cola-6><glue-cola-7><glue-cola-8><glue-cola-9>
02/04/2024 12:16:21 - INFO - __main__ - torch.Size([200, 1024])
02/04/2024 12:16:36 - INFO - __main__ - time use for computing 100 examples: 16.30138850212097
02/04/2024 12:16:36 - INFO - __main__ - start running soft prefix model
02/04/2024 12:16:36 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:16:37 - INFO - __main__ - Checking the first example...
Input:
negative sentence: the stars may be college kids, but the subject matter is as adult as you can get :
Output:
<glue-mnli-0><glue-mnli-1><glue-mnli-2><glue-mnli-3><glue-mnli-4><glue-mnli-5><glue-mnli-6><glue-mnli-7><glue-mnli-8><glue-mnli-9>
02/04/2024 12:16:37 - INFO - __main__ - torch.Size([200, 1024])
02/04/2024 12:16:52 - INFO - __main__ - time use for computing 100 examples: 15.67658543586731
02/04/2024 12:16:52 - INFO - __main__ - start running soft prefix model
02/04/2024 12:16:52 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:16:52 - INFO - __main__ - Checking the first example...
Input:
negative sentence: the stars may be college kids, but the subject matter is as adult as you can get :
Output:
<glue-qqp-0><glue-qqp-1><glue-qqp-2><glue-qqp-3><glue-qqp-4><glue-qqp-5><glue-qqp-6><glue-qqp-7><glue-qqp-8><glue-qqp-9>
02/04/2024 12:16:52 - INFO - __main__ - torch.Size([200, 1024])
02/04/2024 12:17:07 - INFO - __main__ - time use for computing 100 examples: 15.678330183029175
02/04/2024 12:17:07 - INFO - __main__ - start running soft prefix model
02/04/2024 12:17:07 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:17:08 - INFO - __main__ - Checking the first example...
Input:
negative sentence: the stars may be college kids, but the subject matter is as adult as you can get :
Output:
<glue-mrpc-0><glue-mrpc-1><glue-mrpc-2><glue-mrpc-3><glue-mrpc-4><glue-mrpc-5><glue-mrpc-6><glue-mrpc-7><glue-mrpc-8><glue-mrpc-9>
02/04/2024 12:17:08 - INFO - __main__ - torch.Size([200, 1024])
02/04/2024 12:17:23 - INFO - __main__ - time use for computing 100 examples: 15.736950397491455
02/04/2024 12:17:23 - INFO - __main__ - start running soft prefix model
02/04/2024 12:17:23 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:17:24 - INFO - __main__ - Checking the first example...
Input:
negative sentence: the stars may be college kids, but the subject matter is as adult as you can get :
Output:
<glue-qnli-0><glue-qnli-1><glue-qnli-2><glue-qnli-3><glue-qnli-4><glue-qnli-5><glue-qnli-6><glue-qnli-7><glue-qnli-8><glue-qnli-9>
02/04/2024 12:17:24 - INFO - __main__ - torch.Size([200, 1024])
02/04/2024 12:17:39 - INFO - __main__ - time use for computing 100 examples: 15.714645862579346
02/04/2024 12:17:39 - INFO - __main__ - start running soft prefix model
02/04/2024 12:17:39 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:17:39 - INFO - __main__ - Checking the first example...
Input:
negative sentence: the stars may be college kids, but the subject matter is as adult as you can get :
Output:
<glue-rte-0><glue-rte-1><glue-rte-2><glue-rte-3><glue-rte-4><glue-rte-5><glue-rte-6><glue-rte-7><glue-rte-8><glue-rte-9>
02/04/2024 12:17:39 - INFO - __main__ - torch.Size([200, 1024])
02/04/2024 12:17:54 - INFO - __main__ - time use for computing 100 examples: 15.7399160861969
02/04/2024 12:17:54 - INFO - __main__ - start running soft prefix model
02/04/2024 12:17:54 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:17:55 - INFO - __main__ - Checking the first example...
Input:
negative sentence: the stars may be college kids, but the subject matter is as adult as you can get :
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
02/04/2024 12:17:55 - INFO - __main__ - torch.Size([200, 1024])
02/04/2024 12:18:10 - INFO - __main__ - time use for computing 100 examples: 15.718546152114868
02/04/2024 12:18:10 - INFO - __main__ - start running soft prefix model
02/04/2024 12:18:10 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:18:11 - INFO - __main__ - Checking the first example...
Input:
negative sentence: the stars may be college kids, but the subject matter is as adult as you can get :
Output:
<glue-wnli-0><glue-wnli-1><glue-wnli-2><glue-wnli-3><glue-wnli-4><glue-wnli-5><glue-wnli-6><glue-wnli-7><glue-wnli-8><glue-wnli-9>
02/04/2024 12:18:11 - INFO - __main__ - torch.Size([200, 1024])
02/04/2024 12:18:26 - INFO - __main__ - time use for computing 100 examples: 15.729446172714233
02/04/2024 12:18:26 - INFO - __main__ - min difficulty: -inf
02/04/2024 12:18:26 - INFO - __main__ - max difficulty: 1.0
02/04/2024 12:18:26 - INFO - __main__ - average difficulty: -inf
02/04/2024 12:18:26 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:18:27 - INFO - __main__ - Checking the first example...
Input:
positive sentence: the stars may be college kids, but the subject matter is as adult as you can get : negative sentence:, it isn't much fun. negative sentence: a case of too many chefs fussing over too weak a recipe negative sentence: onto what's left of his passe'chopsocky glory
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
02/04/2024 12:18:27 - INFO - __main__ - torch.Size([24, 1024])
02/04/2024 12:18:28 - INFO - __main__ - time use for computing 24 examples: 1.9811038970947266
02/04/2024 12:18:28 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:18:29 - INFO - __main__ - Checking the first example...
Input:
positive sentence: the stars may be college kids, but the subject matter is as adult as you can get : negative sentence:, it isn't much fun. negative sentence: a case of too many chefs fussing over too weak a recipe negative sentence: onto what's left of his passe'chopsocky glory
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
02/04/2024 12:18:29 - INFO - __main__ - torch.Size([24, 1024])
02/04/2024 12:18:31 - INFO - __main__ - time use for computing 24 examples: 1.967543601989746
02/04/2024 12:18:31 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:18:32 - INFO - __main__ - Checking the first example...
Input:
positive sentence: the stars may be college kids, but the subject matter is as adult as you can get : negative sentence:, it isn't much fun. negative sentence: a case of too many chefs fussing over too weak a recipe negative sentence: onto what's left of his passe'chopsocky glory
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
02/04/2024 12:18:32 - INFO - __main__ - torch.Size([24, 1024])
02/04/2024 12:18:34 - INFO - __main__ - time use for computing 24 examples: 1.9652910232543945
02/04/2024 12:18:34 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:18:35 - INFO - __main__ - Checking the first example...
Input:
positive sentence: the stars may be college kids, but the subject matter is as adult as you can get : negative sentence:, it isn't much fun. negative sentence: a case of too many chefs fussing over too weak a recipe negative sentence: onto what's left of his passe'chopsocky glory
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
02/04/2024 12:18:35 - INFO - __main__ - torch.Size([24, 1024])
02/04/2024 12:18:36 - INFO - __main__ - time use for computing 24 examples: 1.955594539642334
02/04/2024 12:18:36 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:18:37 - INFO - __main__ - Checking the first example...
Input:
positive sentence: the stars may be college kids, but the subject matter is as adult as you can get : negative sentence:, it isn't much fun. negative sentence: a case of too many chefs fussing over too weak a recipe negative sentence: onto what's left of his passe'chopsocky glory
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
02/04/2024 12:18:37 - INFO - __main__ - torch.Size([24, 1024])
02/04/2024 12:18:39 - INFO - __main__ - time use for computing 24 examples: 1.968498706817627
02/04/2024 12:18:39 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:18:40 - INFO - __main__ - Checking the first example...
Input:
positive sentence: the stars may be college kids, but the subject matter is as adult as you can get : negative sentence:, it isn't much fun. negative sentence: a case of too many chefs fussing over too weak a recipe negative sentence: onto what's left of his passe'chopsocky glory
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
02/04/2024 12:18:40 - INFO - __main__ - torch.Size([24, 1024])
02/04/2024 12:18:42 - INFO - __main__ - time use for computing 24 examples: 1.9662833213806152
02/04/2024 12:18:42 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:18:43 - INFO - __main__ - Checking the first example...
Input:
positive sentence: the stars may be college kids, but the subject matter is as adult as you can get : negative sentence:, it isn't much fun. negative sentence: a case of too many chefs fussing over too weak a recipe negative sentence: onto what's left of his passe'chopsocky glory
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
02/04/2024 12:18:43 - INFO - __main__ - torch.Size([24, 1024])
02/04/2024 12:18:44 - INFO - __main__ - time use for computing 24 examples: 1.9690420627593994
02/04/2024 12:18:44 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:18:45 - INFO - __main__ - Checking the first example...
Input:
positive sentence: the stars may be college kids, but the subject matter is as adult as you can get : negative sentence:, it isn't much fun. negative sentence: a case of too many chefs fussing over too weak a recipe negative sentence: onto what's left of his passe'chopsocky glory
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
02/04/2024 12:18:45 - INFO - __main__ - torch.Size([24, 1024])
02/04/2024 12:18:47 - INFO - __main__ - time use for computing 24 examples: 1.9827725887298584
02/04/2024 12:18:48 - INFO - __main__ - Checking the first example...
Input:
positive sentence: the stars may be college kids, but the subject matter is as adult as you can get : negative sentence:, it isn't much fun. negative sentence: a case of too many chefs fussing over too weak a recipe negative sentence: onto what's left of his passe'chopsocky glory negative
Output:
 sentence: it's a charming and often affecting journey.
02/04/2024 12:18:48 - INFO - __main__ - torch.Size([1744, 1024])
02/04/2024 12:21:02 - INFO - __main__ - None task (seed=100): Macro-F1: 56.5, Accuracy: 57.7
02/04/2024 12:21:02 - INFO - __main__ - [Train] glue-sst2	67349
02/04/2024 12:21:02 - INFO - __main__ - [Dev] glue-sst2	872
02/04/2024 12:21:02 - INFO - __main__ - channel on None (1 train, 1 dev)
02/04/2024 12:21:02 - INFO - __main__ - start running soft prefix model
02/04/2024 12:21:02 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:21:03 - INFO - __main__ - Checking the first example...
Input:
negative sentence: well worth revisiting as many times
Output:
<glue-cola-0><glue-cola-1><glue-cola-2><glue-cola-3><glue-cola-4><glue-cola-5><glue-cola-6><glue-cola-7><glue-cola-8><glue-cola-9>
02/04/2024 12:21:03 - INFO - __main__ - torch.Size([200, 1024])
02/04/2024 12:21:18 - INFO - __main__ - time use for computing 100 examples: 15.81079363822937
02/04/2024 12:21:18 - INFO - __main__ - start running soft prefix model
02/04/2024 12:21:18 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:21:19 - INFO - __main__ - Checking the first example...
Input:
negative sentence: well worth revisiting as many times
Output:
<glue-mnli-0><glue-mnli-1><glue-mnli-2><glue-mnli-3><glue-mnli-4><glue-mnli-5><glue-mnli-6><glue-mnli-7><glue-mnli-8><glue-mnli-9>
02/04/2024 12:21:19 - INFO - __main__ - torch.Size([200, 1024])
02/04/2024 12:21:34 - INFO - __main__ - time use for computing 100 examples: 15.73811149597168
02/04/2024 12:21:34 - INFO - __main__ - start running soft prefix model
02/04/2024 12:21:34 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:21:35 - INFO - __main__ - Checking the first example...
Input:
negative sentence: well worth revisiting as many times
Output:
<glue-qqp-0><glue-qqp-1><glue-qqp-2><glue-qqp-3><glue-qqp-4><glue-qqp-5><glue-qqp-6><glue-qqp-7><glue-qqp-8><glue-qqp-9>
02/04/2024 12:21:35 - INFO - __main__ - torch.Size([200, 1024])
02/04/2024 12:21:50 - INFO - __main__ - time use for computing 100 examples: 15.825252294540405
02/04/2024 12:21:50 - INFO - __main__ - start running soft prefix model
02/04/2024 12:21:50 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:21:50 - INFO - __main__ - Checking the first example...
Input:
negative sentence: well worth revisiting as many times
Output:
<glue-mrpc-0><glue-mrpc-1><glue-mrpc-2><glue-mrpc-3><glue-mrpc-4><glue-mrpc-5><glue-mrpc-6><glue-mrpc-7><glue-mrpc-8><glue-mrpc-9>
02/04/2024 12:21:50 - INFO - __main__ - torch.Size([200, 1024])
02/04/2024 12:22:05 - INFO - __main__ - time use for computing 100 examples: 15.796137809753418
02/04/2024 12:22:05 - INFO - __main__ - start running soft prefix model
02/04/2024 12:22:05 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:22:06 - INFO - __main__ - Checking the first example...
Input:
negative sentence: well worth revisiting as many times
Output:
<glue-qnli-0><glue-qnli-1><glue-qnli-2><glue-qnli-3><glue-qnli-4><glue-qnli-5><glue-qnli-6><glue-qnli-7><glue-qnli-8><glue-qnli-9>
02/04/2024 12:22:06 - INFO - __main__ - torch.Size([200, 1024])
02/04/2024 12:22:21 - INFO - __main__ - time use for computing 100 examples: 15.803418636322021
02/04/2024 12:22:21 - INFO - __main__ - start running soft prefix model
02/04/2024 12:22:21 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:22:22 - INFO - __main__ - Checking the first example...
Input:
negative sentence: well worth revisiting as many times
Output:
<glue-rte-0><glue-rte-1><glue-rte-2><glue-rte-3><glue-rte-4><glue-rte-5><glue-rte-6><glue-rte-7><glue-rte-8><glue-rte-9>
02/04/2024 12:22:22 - INFO - __main__ - torch.Size([200, 1024])
02/04/2024 12:22:37 - INFO - __main__ - time use for computing 100 examples: 15.790382385253906
02/04/2024 12:22:37 - INFO - __main__ - start running soft prefix model
02/04/2024 12:22:37 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:22:38 - INFO - __main__ - Checking the first example...
Input:
negative sentence: well worth revisiting as many times
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
02/04/2024 12:22:38 - INFO - __main__ - torch.Size([200, 1024])
02/04/2024 12:22:53 - INFO - __main__ - time use for computing 100 examples: 15.819254398345947
02/04/2024 12:22:53 - INFO - __main__ - start running soft prefix model
02/04/2024 12:22:53 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:22:54 - INFO - __main__ - Checking the first example...
Input:
negative sentence: well worth revisiting as many times
Output:
<glue-wnli-0><glue-wnli-1><glue-wnli-2><glue-wnli-3><glue-wnli-4><glue-wnli-5><glue-wnli-6><glue-wnli-7><glue-wnli-8><glue-wnli-9>
02/04/2024 12:22:54 - INFO - __main__ - torch.Size([200, 1024])
02/04/2024 12:23:09 - INFO - __main__ - time use for computing 100 examples: 15.847822427749634
02/04/2024 12:23:09 - INFO - __main__ - min difficulty: -inf
02/04/2024 12:23:09 - INFO - __main__ - max difficulty: 1.0
02/04/2024 12:23:09 - INFO - __main__ - average difficulty: -inf
02/04/2024 12:23:09 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:23:09 - INFO - __main__ - Checking the first example...
Input:
positive sentence: well worth revisiting as many times negative sentence:'re just a couple of cops in copmovieland, these two positive sentence: is impressively true for being so hot-blooded positive sentence: like the rugrats movies, the wild thornberrys movie doesn't offer much more than the series, but its emphasis on caring for animals and respecting other cultures is particularly welcome
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
02/04/2024 12:23:09 - INFO - __main__ - torch.Size([24, 1024])
02/04/2024 12:23:11 - INFO - __main__ - time use for computing 24 examples: 1.9590160846710205
02/04/2024 12:23:11 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:23:12 - INFO - __main__ - Checking the first example...
Input:
positive sentence: well worth revisiting as many times negative sentence:'re just a couple of cops in copmovieland, these two positive sentence: is impressively true for being so hot-blooded positive sentence: like the rugrats movies, the wild thornberrys movie doesn't offer much more than the series, but its emphasis on caring for animals and respecting other cultures is particularly welcome
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
02/04/2024 12:23:12 - INFO - __main__ - torch.Size([24, 1024])
02/04/2024 12:23:14 - INFO - __main__ - time use for computing 24 examples: 1.9622061252593994
02/04/2024 12:23:14 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:23:15 - INFO - __main__ - Checking the first example...
Input:
positive sentence: well worth revisiting as many times negative sentence:'re just a couple of cops in copmovieland, these two positive sentence: is impressively true for being so hot-blooded positive sentence: like the rugrats movies, the wild thornberrys movie doesn't offer much more than the series, but its emphasis on caring for animals and respecting other cultures is particularly welcome
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
02/04/2024 12:23:15 - INFO - __main__ - torch.Size([24, 1024])
02/04/2024 12:23:17 - INFO - __main__ - time use for computing 24 examples: 1.9798262119293213
02/04/2024 12:23:17 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:23:18 - INFO - __main__ - Checking the first example...
Input:
positive sentence: well worth revisiting as many times negative sentence:'re just a couple of cops in copmovieland, these two positive sentence: is impressively true for being so hot-blooded positive sentence: like the rugrats movies, the wild thornberrys movie doesn't offer much more than the series, but its emphasis on caring for animals and respecting other cultures is particularly welcome
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
02/04/2024 12:23:18 - INFO - __main__ - torch.Size([24, 1024])
02/04/2024 12:23:19 - INFO - __main__ - time use for computing 24 examples: 1.9734117984771729
02/04/2024 12:23:19 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:23:20 - INFO - __main__ - Checking the first example...
Input:
positive sentence: well worth revisiting as many times negative sentence:'re just a couple of cops in copmovieland, these two positive sentence: is impressively true for being so hot-blooded positive sentence: like the rugrats movies, the wild thornberrys movie doesn't offer much more than the series, but its emphasis on caring for animals and respecting other cultures is particularly welcome
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
02/04/2024 12:23:20 - INFO - __main__ - torch.Size([24, 1024])
02/04/2024 12:23:22 - INFO - __main__ - time use for computing 24 examples: 1.9659647941589355
02/04/2024 12:23:22 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:23:23 - INFO - __main__ - Checking the first example...
Input:
positive sentence: well worth revisiting as many times negative sentence:'re just a couple of cops in copmovieland, these two positive sentence: is impressively true for being so hot-blooded positive sentence: like the rugrats movies, the wild thornberrys movie doesn't offer much more than the series, but its emphasis on caring for animals and respecting other cultures is particularly welcome
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
02/04/2024 12:23:23 - INFO - __main__ - torch.Size([24, 1024])
02/04/2024 12:23:25 - INFO - __main__ - time use for computing 24 examples: 1.9624450206756592
02/04/2024 12:23:25 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:23:26 - INFO - __main__ - Checking the first example...
Input:
positive sentence: well worth revisiting as many times negative sentence:'re just a couple of cops in copmovieland, these two positive sentence: is impressively true for being so hot-blooded positive sentence: like the rugrats movies, the wild thornberrys movie doesn't offer much more than the series, but its emphasis on caring for animals and respecting other cultures is particularly welcome
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
02/04/2024 12:23:26 - INFO - __main__ - torch.Size([24, 1024])
02/04/2024 12:23:27 - INFO - __main__ - time use for computing 24 examples: 1.9692997932434082
02/04/2024 12:23:27 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:23:28 - INFO - __main__ - Checking the first example...
Input:
positive sentence: well worth revisiting as many times negative sentence:'re just a couple of cops in copmovieland, these two positive sentence: is impressively true for being so hot-blooded positive sentence: like the rugrats movies, the wild thornberrys movie doesn't offer much more than the series, but its emphasis on caring for animals and respecting other cultures is particularly welcome
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
02/04/2024 12:23:28 - INFO - __main__ - torch.Size([24, 1024])
02/04/2024 12:23:30 - INFO - __main__ - time use for computing 24 examples: 1.9596490859985352
02/04/2024 12:23:31 - INFO - __main__ - Checking the first example...
Input:
positive sentence: well worth revisiting as many times negative sentence:'re just a couple of cops in copmovieland, these two positive sentence: is impressively true for being so hot-blooded positive sentence: like the rugrats movies, the wild thornberrys movie doesn't offer much more than the series, but its emphasis on caring for animals and respecting other cultures is particularly welcome negative
Output:
 sentence: it's a charming and often affecting journey.
02/04/2024 12:23:31 - INFO - __main__ - torch.Size([1744, 1024])
02/04/2024 12:25:45 - INFO - __main__ - None task (seed=13): Macro-F1: 78.4, Accuracy: 78.4
02/04/2024 12:25:45 - INFO - __main__ - [Train] glue-sst2	67349
02/04/2024 12:25:45 - INFO - __main__ - [Dev] glue-sst2	872
02/04/2024 12:25:45 - INFO - __main__ - channel on None (1 train, 1 dev)
02/04/2024 12:25:45 - INFO - __main__ - start running soft prefix model
02/04/2024 12:25:45 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:25:46 - INFO - __main__ - Checking the first example...
Input:
negative sentence: in his role of observer of the scene, lawrence sounds whiny and defensive, as if his life-altering experiences made him bitter and less mature.
Output:
<glue-cola-0><glue-cola-1><glue-cola-2><glue-cola-3><glue-cola-4><glue-cola-5><glue-cola-6><glue-cola-7><glue-cola-8><glue-cola-9>
02/04/2024 12:25:46 - INFO - __main__ - torch.Size([200, 1024])
02/04/2024 12:26:01 - INFO - __main__ - time use for computing 100 examples: 15.881446361541748
02/04/2024 12:26:01 - INFO - __main__ - start running soft prefix model
02/04/2024 12:26:01 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:26:02 - INFO - __main__ - Checking the first example...
Input:
negative sentence: in his role of observer of the scene, lawrence sounds whiny and defensive, as if his life-altering experiences made him bitter and less mature.
Output:
<glue-mnli-0><glue-mnli-1><glue-mnli-2><glue-mnli-3><glue-mnli-4><glue-mnli-5><glue-mnli-6><glue-mnli-7><glue-mnli-8><glue-mnli-9>
02/04/2024 12:26:02 - INFO - __main__ - torch.Size([200, 1024])
02/04/2024 12:26:17 - INFO - __main__ - time use for computing 100 examples: 15.81450891494751
02/04/2024 12:26:17 - INFO - __main__ - start running soft prefix model
02/04/2024 12:26:17 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:26:18 - INFO - __main__ - Checking the first example...
Input:
negative sentence: in his role of observer of the scene, lawrence sounds whiny and defensive, as if his life-altering experiences made him bitter and less mature.
Output:
<glue-qqp-0><glue-qqp-1><glue-qqp-2><glue-qqp-3><glue-qqp-4><glue-qqp-5><glue-qqp-6><glue-qqp-7><glue-qqp-8><glue-qqp-9>
02/04/2024 12:26:18 - INFO - __main__ - torch.Size([200, 1024])
02/04/2024 12:26:33 - INFO - __main__ - time use for computing 100 examples: 15.894627571105957
02/04/2024 12:26:33 - INFO - __main__ - start running soft prefix model
02/04/2024 12:26:33 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:26:34 - INFO - __main__ - Checking the first example...
Input:
negative sentence: in his role of observer of the scene, lawrence sounds whiny and defensive, as if his life-altering experiences made him bitter and less mature.
Output:
<glue-mrpc-0><glue-mrpc-1><glue-mrpc-2><glue-mrpc-3><glue-mrpc-4><glue-mrpc-5><glue-mrpc-6><glue-mrpc-7><glue-mrpc-8><glue-mrpc-9>
02/04/2024 12:26:34 - INFO - __main__ - torch.Size([200, 1024])
02/04/2024 12:26:49 - INFO - __main__ - time use for computing 100 examples: 15.875643968582153
02/04/2024 12:26:49 - INFO - __main__ - start running soft prefix model
02/04/2024 12:26:49 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:26:50 - INFO - __main__ - Checking the first example...
Input:
negative sentence: in his role of observer of the scene, lawrence sounds whiny and defensive, as if his life-altering experiences made him bitter and less mature.
Output:
<glue-qnli-0><glue-qnli-1><glue-qnli-2><glue-qnli-3><glue-qnli-4><glue-qnli-5><glue-qnli-6><glue-qnli-7><glue-qnli-8><glue-qnli-9>
02/04/2024 12:26:50 - INFO - __main__ - torch.Size([200, 1024])
02/04/2024 12:27:05 - INFO - __main__ - time use for computing 100 examples: 15.879530906677246
02/04/2024 12:27:05 - INFO - __main__ - start running soft prefix model
02/04/2024 12:27:05 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:27:06 - INFO - __main__ - Checking the first example...
Input:
negative sentence: in his role of observer of the scene, lawrence sounds whiny and defensive, as if his life-altering experiences made him bitter and less mature.
Output:
<glue-rte-0><glue-rte-1><glue-rte-2><glue-rte-3><glue-rte-4><glue-rte-5><glue-rte-6><glue-rte-7><glue-rte-8><glue-rte-9>
02/04/2024 12:27:06 - INFO - __main__ - torch.Size([200, 1024])
02/04/2024 12:27:21 - INFO - __main__ - time use for computing 100 examples: 15.882846117019653
02/04/2024 12:27:21 - INFO - __main__ - start running soft prefix model
02/04/2024 12:27:21 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:27:22 - INFO - __main__ - Checking the first example...
Input:
negative sentence: in his role of observer of the scene, lawrence sounds whiny and defensive, as if his life-altering experiences made him bitter and less mature.
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
02/04/2024 12:27:22 - INFO - __main__ - torch.Size([200, 1024])
02/04/2024 12:27:37 - INFO - __main__ - time use for computing 100 examples: 15.884488582611084
02/04/2024 12:27:37 - INFO - __main__ - start running soft prefix model
02/04/2024 12:27:37 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:27:38 - INFO - __main__ - Checking the first example...
Input:
negative sentence: in his role of observer of the scene, lawrence sounds whiny and defensive, as if his life-altering experiences made him bitter and less mature.
Output:
<glue-wnli-0><glue-wnli-1><glue-wnli-2><glue-wnli-3><glue-wnli-4><glue-wnli-5><glue-wnli-6><glue-wnli-7><glue-wnli-8><glue-wnli-9>
02/04/2024 12:27:38 - INFO - __main__ - torch.Size([200, 1024])
02/04/2024 12:27:53 - INFO - __main__ - time use for computing 100 examples: 15.913170099258423
02/04/2024 12:27:53 - INFO - __main__ - min difficulty: -inf
02/04/2024 12:27:53 - INFO - __main__ - max difficulty: 1.0
02/04/2024 12:27:53 - INFO - __main__ - average difficulty: -inf
02/04/2024 12:27:53 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:27:53 - INFO - __main__ - Checking the first example...
Input:
negative sentence: in his role of observer of the scene, lawrence sounds whiny and defensive, as if his life-altering experiences made him bitter and less mature. negative sentence: disgusted positive sentence: self-promotion ends and negative sentence: while american adobo has its heart ( and its palate ) in the right place, its brain is a little scattered -- ditsy, even.
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
02/04/2024 12:27:53 - INFO - __main__ - torch.Size([24, 1024])
02/04/2024 12:27:55 - INFO - __main__ - time use for computing 24 examples: 1.98537015914917
02/04/2024 12:27:55 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:27:56 - INFO - __main__ - Checking the first example...
Input:
negative sentence: in his role of observer of the scene, lawrence sounds whiny and defensive, as if his life-altering experiences made him bitter and less mature. negative sentence: disgusted positive sentence: self-promotion ends and negative sentence: while american adobo has its heart ( and its palate ) in the right place, its brain is a little scattered -- ditsy, even.
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
02/04/2024 12:27:56 - INFO - __main__ - torch.Size([24, 1024])
02/04/2024 12:27:58 - INFO - __main__ - time use for computing 24 examples: 1.9892148971557617
02/04/2024 12:27:58 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:27:59 - INFO - __main__ - Checking the first example...
Input:
negative sentence: in his role of observer of the scene, lawrence sounds whiny and defensive, as if his life-altering experiences made him bitter and less mature. negative sentence: disgusted positive sentence: self-promotion ends and negative sentence: while american adobo has its heart ( and its palate ) in the right place, its brain is a little scattered -- ditsy, even.
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
02/04/2024 12:27:59 - INFO - __main__ - torch.Size([24, 1024])
02/04/2024 12:28:01 - INFO - __main__ - time use for computing 24 examples: 1.9802751541137695
02/04/2024 12:28:01 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:28:01 - INFO - __main__ - Checking the first example...
Input:
negative sentence: in his role of observer of the scene, lawrence sounds whiny and defensive, as if his life-altering experiences made him bitter and less mature. negative sentence: disgusted positive sentence: self-promotion ends and negative sentence: while american adobo has its heart ( and its palate ) in the right place, its brain is a little scattered -- ditsy, even.
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
02/04/2024 12:28:02 - INFO - __main__ - torch.Size([24, 1024])
02/04/2024 12:28:03 - INFO - __main__ - time use for computing 24 examples: 1.9834096431732178
02/04/2024 12:28:03 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:28:04 - INFO - __main__ - Checking the first example...
Input:
negative sentence: in his role of observer of the scene, lawrence sounds whiny and defensive, as if his life-altering experiences made him bitter and less mature. negative sentence: disgusted positive sentence: self-promotion ends and negative sentence: while american adobo has its heart ( and its palate ) in the right place, its brain is a little scattered -- ditsy, even.
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
02/04/2024 12:28:04 - INFO - __main__ - torch.Size([24, 1024])
02/04/2024 12:28:06 - INFO - __main__ - time use for computing 24 examples: 1.9862148761749268
02/04/2024 12:28:06 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:28:07 - INFO - __main__ - Checking the first example...
Input:
negative sentence: in his role of observer of the scene, lawrence sounds whiny and defensive, as if his life-altering experiences made him bitter and less mature. negative sentence: disgusted positive sentence: self-promotion ends and negative sentence: while american adobo has its heart ( and its palate ) in the right place, its brain is a little scattered -- ditsy, even.
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
02/04/2024 12:28:07 - INFO - __main__ - torch.Size([24, 1024])
02/04/2024 12:28:09 - INFO - __main__ - time use for computing 24 examples: 1.9843683242797852
02/04/2024 12:28:09 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:28:10 - INFO - __main__ - Checking the first example...
Input:
negative sentence: in his role of observer of the scene, lawrence sounds whiny and defensive, as if his life-altering experiences made him bitter and less mature. negative sentence: disgusted positive sentence: self-promotion ends and negative sentence: while american adobo has its heart ( and its palate ) in the right place, its brain is a little scattered -- ditsy, even.
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
02/04/2024 12:28:10 - INFO - __main__ - torch.Size([24, 1024])
02/04/2024 12:28:11 - INFO - __main__ - time use for computing 24 examples: 1.9832751750946045
02/04/2024 12:28:11 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:28:12 - INFO - __main__ - Checking the first example...
Input:
negative sentence: in his role of observer of the scene, lawrence sounds whiny and defensive, as if his life-altering experiences made him bitter and less mature. negative sentence: disgusted positive sentence: self-promotion ends and negative sentence: while american adobo has its heart ( and its palate ) in the right place, its brain is a little scattered -- ditsy, even.
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
02/04/2024 12:28:12 - INFO - __main__ - torch.Size([24, 1024])
02/04/2024 12:28:14 - INFO - __main__ - time use for computing 24 examples: 1.976886510848999
02/04/2024 12:28:15 - INFO - __main__ - Checking the first example...
Input:
negative sentence: in his role of observer of the scene, lawrence sounds whiny and defensive, as if his life-altering experiences made him bitter and less mature. negative sentence: disgusted positive sentence: self-promotion ends and negative sentence: while american adobo has its heart ( and its palate ) in the right place, its brain is a little scattered -- ditsy, even. negative
Output:
 sentence: it's a charming and often affecting journey.
02/04/2024 12:28:15 - INFO - __main__ - torch.Size([1744, 1024])
02/04/2024 12:30:30 - INFO - __main__ - None task (seed=21): Macro-F1: 72.5, Accuracy: 72.8
02/04/2024 12:30:30 - INFO - __main__ - [Train] glue-sst2	67349
02/04/2024 12:30:30 - INFO - __main__ - [Dev] glue-sst2	872
02/04/2024 12:30:30 - INFO - __main__ - channel on None (1 train, 1 dev)
02/04/2024 12:30:30 - INFO - __main__ - start running soft prefix model
02/04/2024 12:30:30 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:30:34 - INFO - __main__ - Checking the first example...
Input:
negative sentence: with outtakes in which most of the characters forget their lines and just utter ` uhhh,'which is better than most of the writing in the movie
Output:
<glue-cola-0><glue-cola-1><glue-cola-2><glue-cola-3><glue-cola-4><glue-cola-5><glue-cola-6><glue-cola-7><glue-cola-8><glue-cola-9>
02/04/2024 12:30:34 - INFO - __main__ - torch.Size([200, 1024])
02/04/2024 12:30:49 - INFO - __main__ - time use for computing 100 examples: 18.993657112121582
02/04/2024 12:30:49 - INFO - __main__ - start running soft prefix model
02/04/2024 12:30:49 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:30:54 - INFO - __main__ - Checking the first example...
Input:
negative sentence: with outtakes in which most of the characters forget their lines and just utter ` uhhh,'which is better than most of the writing in the movie
Output:
<glue-mnli-0><glue-mnli-1><glue-mnli-2><glue-mnli-3><glue-mnli-4><glue-mnli-5><glue-mnli-6><glue-mnli-7><glue-mnli-8><glue-mnli-9>
02/04/2024 12:30:54 - INFO - __main__ - torch.Size([200, 1024])
02/04/2024 12:31:09 - INFO - __main__ - time use for computing 100 examples: 19.4275164604187
02/04/2024 12:31:09 - INFO - __main__ - start running soft prefix model
02/04/2024 12:31:09 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:31:12 - INFO - __main__ - Checking the first example...
Input:
negative sentence: with outtakes in which most of the characters forget their lines and just utter ` uhhh,'which is better than most of the writing in the movie
Output:
<glue-qqp-0><glue-qqp-1><glue-qqp-2><glue-qqp-3><glue-qqp-4><glue-qqp-5><glue-qqp-6><glue-qqp-7><glue-qqp-8><glue-qqp-9>
02/04/2024 12:31:12 - INFO - __main__ - torch.Size([200, 1024])
02/04/2024 12:31:28 - INFO - __main__ - time use for computing 100 examples: 18.884739875793457
02/04/2024 12:31:28 - INFO - __main__ - start running soft prefix model
02/04/2024 12:31:28 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:31:31 - INFO - __main__ - Checking the first example...
Input:
negative sentence: with outtakes in which most of the characters forget their lines and just utter ` uhhh,'which is better than most of the writing in the movie
Output:
<glue-mrpc-0><glue-mrpc-1><glue-mrpc-2><glue-mrpc-3><glue-mrpc-4><glue-mrpc-5><glue-mrpc-6><glue-mrpc-7><glue-mrpc-8><glue-mrpc-9>
02/04/2024 12:31:31 - INFO - __main__ - torch.Size([200, 1024])
02/04/2024 12:31:46 - INFO - __main__ - time use for computing 100 examples: 18.48186421394348
02/04/2024 12:31:46 - INFO - __main__ - start running soft prefix model
02/04/2024 12:31:46 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:31:50 - INFO - __main__ - Checking the first example...
Input:
negative sentence: with outtakes in which most of the characters forget their lines and just utter ` uhhh,'which is better than most of the writing in the movie
Output:
<glue-qnli-0><glue-qnli-1><glue-qnli-2><glue-qnli-3><glue-qnli-4><glue-qnli-5><glue-qnli-6><glue-qnli-7><glue-qnli-8><glue-qnli-9>
02/04/2024 12:31:50 - INFO - __main__ - torch.Size([200, 1024])
02/04/2024 12:32:05 - INFO - __main__ - time use for computing 100 examples: 18.55551028251648
02/04/2024 12:32:05 - INFO - __main__ - start running soft prefix model
02/04/2024 12:32:05 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:32:08 - INFO - __main__ - Checking the first example...
Input:
negative sentence: with outtakes in which most of the characters forget their lines and just utter ` uhhh,'which is better than most of the writing in the movie
Output:
<glue-rte-0><glue-rte-1><glue-rte-2><glue-rte-3><glue-rte-4><glue-rte-5><glue-rte-6><glue-rte-7><glue-rte-8><glue-rte-9>
02/04/2024 12:32:08 - INFO - __main__ - torch.Size([200, 1024])
02/04/2024 12:32:23 - INFO - __main__ - time use for computing 100 examples: 18.392903804779053
02/04/2024 12:32:23 - INFO - __main__ - start running soft prefix model
02/04/2024 12:32:23 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:32:26 - INFO - __main__ - Checking the first example...
Input:
negative sentence: with outtakes in which most of the characters forget their lines and just utter ` uhhh,'which is better than most of the writing in the movie
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
02/04/2024 12:32:26 - INFO - __main__ - torch.Size([200, 1024])
02/04/2024 12:32:42 - INFO - __main__ - time use for computing 100 examples: 18.512688159942627
02/04/2024 12:32:42 - INFO - __main__ - start running soft prefix model
02/04/2024 12:32:42 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:32:46 - INFO - __main__ - Checking the first example...
Input:
negative sentence: with outtakes in which most of the characters forget their lines and just utter ` uhhh,'which is better than most of the writing in the movie
Output:
<glue-wnli-0><glue-wnli-1><glue-wnli-2><glue-wnli-3><glue-wnli-4><glue-wnli-5><glue-wnli-6><glue-wnli-7><glue-wnli-8><glue-wnli-9>
02/04/2024 12:32:46 - INFO - __main__ - torch.Size([200, 1024])
02/04/2024 12:33:01 - INFO - __main__ - time use for computing 100 examples: 19.322899341583252
02/04/2024 12:33:01 - INFO - __main__ - min difficulty: -inf
02/04/2024 12:33:01 - INFO - __main__ - max difficulty: 1.0
02/04/2024 12:33:01 - INFO - __main__ - average difficulty: -inf
02/04/2024 12:33:01 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:33:04 - INFO - __main__ - Checking the first example...
Input:
negative sentence: with outtakes in which most of the characters forget their lines and just utter ` uhhh,'which is better than most of the writing in the movie negative sentence: gets very ugly, very fast negative sentence: called best bad film you thought was going to be really awful but positive sentence: delicate treatment
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
02/04/2024 12:33:04 - INFO - __main__ - torch.Size([24, 1024])
02/04/2024 12:33:06 - INFO - __main__ - time use for computing 24 examples: 4.1308066844940186
02/04/2024 12:33:06 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:33:10 - INFO - __main__ - Checking the first example...
Input:
negative sentence: with outtakes in which most of the characters forget their lines and just utter ` uhhh,'which is better than most of the writing in the movie negative sentence: gets very ugly, very fast negative sentence: called best bad film you thought was going to be really awful but positive sentence: delicate treatment
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
02/04/2024 12:33:10 - INFO - __main__ - torch.Size([24, 1024])
02/04/2024 12:33:12 - INFO - __main__ - time use for computing 24 examples: 4.056518316268921
02/04/2024 12:33:12 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:33:15 - INFO - __main__ - Checking the first example...
Input:
negative sentence: with outtakes in which most of the characters forget their lines and just utter ` uhhh,'which is better than most of the writing in the movie negative sentence: gets very ugly, very fast negative sentence: called best bad film you thought was going to be really awful but positive sentence: delicate treatment
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
02/04/2024 12:33:15 - INFO - __main__ - torch.Size([24, 1024])
02/04/2024 12:33:17 - INFO - __main__ - time use for computing 24 examples: 4.040119171142578
02/04/2024 12:33:17 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:33:20 - INFO - __main__ - Checking the first example...
Input:
negative sentence: with outtakes in which most of the characters forget their lines and just utter ` uhhh,'which is better than most of the writing in the movie negative sentence: gets very ugly, very fast negative sentence: called best bad film you thought was going to be really awful but positive sentence: delicate treatment
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
02/04/2024 12:33:20 - INFO - __main__ - torch.Size([24, 1024])
02/04/2024 12:33:23 - INFO - __main__ - time use for computing 24 examples: 4.117347717285156
02/04/2024 12:33:23 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:33:26 - INFO - __main__ - Checking the first example...
Input:
negative sentence: with outtakes in which most of the characters forget their lines and just utter ` uhhh,'which is better than most of the writing in the movie negative sentence: gets very ugly, very fast negative sentence: called best bad film you thought was going to be really awful but positive sentence: delicate treatment
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
02/04/2024 12:33:26 - INFO - __main__ - torch.Size([24, 1024])
02/04/2024 12:33:28 - INFO - __main__ - time use for computing 24 examples: 3.993708372116089
02/04/2024 12:33:28 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:33:31 - INFO - __main__ - Checking the first example...
Input:
negative sentence: with outtakes in which most of the characters forget their lines and just utter ` uhhh,'which is better than most of the writing in the movie negative sentence: gets very ugly, very fast negative sentence: called best bad film you thought was going to be really awful but positive sentence: delicate treatment
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
02/04/2024 12:33:31 - INFO - __main__ - torch.Size([24, 1024])
02/04/2024 12:33:33 - INFO - __main__ - time use for computing 24 examples: 4.069398880004883
02/04/2024 12:33:33 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:33:37 - INFO - __main__ - Checking the first example...
Input:
negative sentence: with outtakes in which most of the characters forget their lines and just utter ` uhhh,'which is better than most of the writing in the movie negative sentence: gets very ugly, very fast negative sentence: called best bad film you thought was going to be really awful but positive sentence: delicate treatment
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
02/04/2024 12:33:37 - INFO - __main__ - torch.Size([24, 1024])
02/04/2024 12:33:39 - INFO - __main__ - time use for computing 24 examples: 4.254250526428223
02/04/2024 12:33:39 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:33:42 - INFO - __main__ - Checking the first example...
Input:
negative sentence: with outtakes in which most of the characters forget their lines and just utter ` uhhh,'which is better than most of the writing in the movie negative sentence: gets very ugly, very fast negative sentence: called best bad film you thought was going to be really awful but positive sentence: delicate treatment
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
02/04/2024 12:33:42 - INFO - __main__ - torch.Size([24, 1024])
02/04/2024 12:33:44 - INFO - __main__ - time use for computing 24 examples: 4.1579742431640625
02/04/2024 12:33:45 - INFO - __main__ - Checking the first example...
Input:
negative sentence: with outtakes in which most of the characters forget their lines and just utter ` uhhh,'which is better than most of the writing in the movie negative sentence: gets very ugly, very fast negative sentence: called best bad film you thought was going to be really awful but positive sentence: delicate treatment negative
Output:
 sentence: it's a charming and often affecting journey.
02/04/2024 12:33:45 - INFO - __main__ - torch.Size([1744, 1024])
02/04/2024 12:35:59 - INFO - __main__ - None task (seed=42): Macro-F1: 68.9, Accuracy: 69.2
02/04/2024 12:36:00 - INFO - __main__ - [Train] glue-sst2	67349
02/04/2024 12:36:00 - INFO - __main__ - [Dev] glue-sst2	872
02/04/2024 12:36:00 - INFO - __main__ - channel on None (1 train, 1 dev)
02/04/2024 12:36:00 - INFO - __main__ - start running soft prefix model
02/04/2024 12:36:00 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:36:03 - INFO - __main__ - Checking the first example...
Input:
negative sentence: titular
Output:
<glue-cola-0><glue-cola-1><glue-cola-2><glue-cola-3><glue-cola-4><glue-cola-5><glue-cola-6><glue-cola-7><glue-cola-8><glue-cola-9>
02/04/2024 12:36:03 - INFO - __main__ - torch.Size([200, 1024])
02/04/2024 12:36:19 - INFO - __main__ - time use for computing 100 examples: 19.216624975204468
02/04/2024 12:36:19 - INFO - __main__ - start running soft prefix model
02/04/2024 12:36:19 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:36:22 - INFO - __main__ - Checking the first example...
Input:
negative sentence: titular
Output:
<glue-mnli-0><glue-mnli-1><glue-mnli-2><glue-mnli-3><glue-mnli-4><glue-mnli-5><glue-mnli-6><glue-mnli-7><glue-mnli-8><glue-mnli-9>
02/04/2024 12:36:22 - INFO - __main__ - torch.Size([200, 1024])
02/04/2024 12:36:37 - INFO - __main__ - time use for computing 100 examples: 18.548951864242554
02/04/2024 12:36:37 - INFO - __main__ - start running soft prefix model
02/04/2024 12:36:37 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:36:41 - INFO - __main__ - Checking the first example...
Input:
negative sentence: titular
Output:
<glue-qqp-0><glue-qqp-1><glue-qqp-2><glue-qqp-3><glue-qqp-4><glue-qqp-5><glue-qqp-6><glue-qqp-7><glue-qqp-8><glue-qqp-9>
02/04/2024 12:36:41 - INFO - __main__ - torch.Size([200, 1024])
02/04/2024 12:36:56 - INFO - __main__ - time use for computing 100 examples: 18.45780348777771
02/04/2024 12:36:56 - INFO - __main__ - start running soft prefix model
02/04/2024 12:36:56 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:36:59 - INFO - __main__ - Checking the first example...
Input:
negative sentence: titular
Output:
<glue-mrpc-0><glue-mrpc-1><glue-mrpc-2><glue-mrpc-3><glue-mrpc-4><glue-mrpc-5><glue-mrpc-6><glue-mrpc-7><glue-mrpc-8><glue-mrpc-9>
02/04/2024 12:36:59 - INFO - __main__ - torch.Size([200, 1024])
02/04/2024 12:37:14 - INFO - __main__ - time use for computing 100 examples: 18.351612329483032
02/04/2024 12:37:14 - INFO - __main__ - start running soft prefix model
02/04/2024 12:37:14 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:37:18 - INFO - __main__ - Checking the first example...
Input:
negative sentence: titular
Output:
<glue-qnli-0><glue-qnli-1><glue-qnli-2><glue-qnli-3><glue-qnli-4><glue-qnli-5><glue-qnli-6><glue-qnli-7><glue-qnli-8><glue-qnli-9>
02/04/2024 12:37:18 - INFO - __main__ - torch.Size([200, 1024])
02/04/2024 12:37:33 - INFO - __main__ - time use for computing 100 examples: 18.94496202468872
02/04/2024 12:37:33 - INFO - __main__ - start running soft prefix model
02/04/2024 12:37:33 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:37:37 - INFO - __main__ - Checking the first example...
Input:
negative sentence: titular
Output:
<glue-rte-0><glue-rte-1><glue-rte-2><glue-rte-3><glue-rte-4><glue-rte-5><glue-rte-6><glue-rte-7><glue-rte-8><glue-rte-9>
02/04/2024 12:37:37 - INFO - __main__ - torch.Size([200, 1024])
02/04/2024 12:37:52 - INFO - __main__ - time use for computing 100 examples: 18.993044137954712
02/04/2024 12:37:52 - INFO - __main__ - start running soft prefix model
02/04/2024 12:37:52 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:37:56 - INFO - __main__ - Checking the first example...
Input:
negative sentence: titular
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
02/04/2024 12:37:56 - INFO - __main__ - torch.Size([200, 1024])
02/04/2024 12:38:11 - INFO - __main__ - time use for computing 100 examples: 18.602434635162354
02/04/2024 12:38:11 - INFO - __main__ - start running soft prefix model
02/04/2024 12:38:11 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:38:14 - INFO - __main__ - Checking the first example...
Input:
negative sentence: titular
Output:
<glue-wnli-0><glue-wnli-1><glue-wnli-2><glue-wnli-3><glue-wnli-4><glue-wnli-5><glue-wnli-6><glue-wnli-7><glue-wnli-8><glue-wnli-9>
02/04/2024 12:38:14 - INFO - __main__ - torch.Size([200, 1024])
02/04/2024 12:38:30 - INFO - __main__ - time use for computing 100 examples: 18.836923837661743
02/04/2024 12:38:30 - INFO - __main__ - min difficulty: -inf
02/04/2024 12:38:30 - INFO - __main__ - max difficulty: 1.0
02/04/2024 12:38:30 - INFO - __main__ - average difficulty: -inf
02/04/2024 12:38:30 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:38:33 - INFO - __main__ - Checking the first example...
Input:
positive sentence: titular positive sentence: various amusing sidekicks negative sentence: loses its sense of humor negative sentence: maintaining consciousness just long enough to achieve callow pretension
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
02/04/2024 12:38:33 - INFO - __main__ - torch.Size([24, 1024])
02/04/2024 12:38:35 - INFO - __main__ - time use for computing 24 examples: 4.063978433609009
02/04/2024 12:38:35 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:38:39 - INFO - __main__ - Checking the first example...
Input:
positive sentence: titular positive sentence: various amusing sidekicks negative sentence: loses its sense of humor negative sentence: maintaining consciousness just long enough to achieve callow pretension
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
02/04/2024 12:38:39 - INFO - __main__ - torch.Size([24, 1024])
02/04/2024 12:38:41 - INFO - __main__ - time use for computing 24 examples: 4.329118013381958
02/04/2024 12:38:41 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:38:44 - INFO - __main__ - Checking the first example...
Input:
positive sentence: titular positive sentence: various amusing sidekicks negative sentence: loses its sense of humor negative sentence: maintaining consciousness just long enough to achieve callow pretension
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
02/04/2024 12:38:44 - INFO - __main__ - torch.Size([24, 1024])
02/04/2024 12:38:46 - INFO - __main__ - time use for computing 24 examples: 4.150157690048218
02/04/2024 12:38:46 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:38:50 - INFO - __main__ - Checking the first example...
Input:
positive sentence: titular positive sentence: various amusing sidekicks negative sentence: loses its sense of humor negative sentence: maintaining consciousness just long enough to achieve callow pretension
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
02/04/2024 12:38:50 - INFO - __main__ - torch.Size([24, 1024])
02/04/2024 12:38:52 - INFO - __main__ - time use for computing 24 examples: 4.088766098022461
02/04/2024 12:38:52 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:38:56 - INFO - __main__ - Checking the first example...
Input:
positive sentence: titular positive sentence: various amusing sidekicks negative sentence: loses its sense of humor negative sentence: maintaining consciousness just long enough to achieve callow pretension
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
02/04/2024 12:38:56 - INFO - __main__ - torch.Size([24, 1024])
02/04/2024 12:38:58 - INFO - __main__ - time use for computing 24 examples: 4.691589117050171
02/04/2024 12:38:58 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:39:02 - INFO - __main__ - Checking the first example...
Input:
positive sentence: titular positive sentence: various amusing sidekicks negative sentence: loses its sense of humor negative sentence: maintaining consciousness just long enough to achieve callow pretension
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
02/04/2024 12:39:02 - INFO - __main__ - torch.Size([24, 1024])
02/04/2024 12:39:04 - INFO - __main__ - time use for computing 24 examples: 4.054879665374756
02/04/2024 12:39:04 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:39:07 - INFO - __main__ - Checking the first example...
Input:
positive sentence: titular positive sentence: various amusing sidekicks negative sentence: loses its sense of humor negative sentence: maintaining consciousness just long enough to achieve callow pretension
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
02/04/2024 12:39:07 - INFO - __main__ - torch.Size([24, 1024])
02/04/2024 12:39:10 - INFO - __main__ - time use for computing 24 examples: 4.521990776062012
02/04/2024 12:39:10 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/04/2024 12:39:13 - INFO - __main__ - Checking the first example...
Input:
positive sentence: titular positive sentence: various amusing sidekicks negative sentence: loses its sense of humor negative sentence: maintaining consciousness just long enough to achieve callow pretension
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
02/04/2024 12:39:13 - INFO - __main__ - torch.Size([24, 1024])
02/04/2024 12:39:15 - INFO - __main__ - time use for computing 24 examples: 4.3195085525512695
02/04/2024 12:39:16 - INFO - __main__ - Checking the first example...
Input:
positive sentence: titular positive sentence: various amusing sidekicks negative sentence: loses its sense of humor negative sentence: maintaining consciousness just long enough to achieve callow pretension negative
Output:
 sentence: it's a charming and often affecting journey.
02/04/2024 12:39:16 - INFO - __main__ - torch.Size([1744, 1024])
02/04/2024 12:41:30 - INFO - __main__ - None task (seed=87): Macro-F1: 66.2, Accuracy: 67.0
02/04/2024 12:41:30 - INFO - __main__ - None over 1 target tasks with majority vote: Macro-F1: 73.3, Accuracy: 73.4
02/04/2024 12:41:30 - INFO - __main__ - None over 1 target tasks on average: Macro-F1: 68.5 +- 7.2, Accuracy: 69.0 +- 6.9
