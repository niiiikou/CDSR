01/15/2024 10:50:33 - INFO - __main__ - Namespace(use_demonstrations=True, use_soft_prefix=False, use_soft_postfix=False, n_prefix_tokens=10, max_length=1024, prior=['easiest'], difficulty='concept_calibrated', reorder=True, log_dir='logs', out_dir='out\\gpt2', load_dir=None, concept_dir='concept_likelihood\\gpt2\\glue-glue-100\\glue-cola-direct-prefix=10-lr=1e-2-3000', prefix_embed_file='checkpoints\\gpt2\\glue-glue\\prefix={10}-{direct}-lr={1e-2}-initByVocab\\soft_embeddings-3000.pt', task=None, dataset='glue-cola', data_dir='data/', k=4, seed='100,13,21,42,87', test_batch_size=8, global_step=None, use_random_english_words=False, use_random_label=False, use_instruction=False, unseen_domain_only=False, split='test', method='direct', gpt='gpt2', api=None, test_size=1000, train_size=100, embedding_dir='embeddings\\', embedding_model='all-mpnet-base-v2', similarity_temperature=0.1, concept_temperature=50.0)
01/15/2024 10:50:35 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 10:50:36 - INFO - __main__ - batch_size=8	max_length=1024	max_length_per_example=256
01/15/2024 10:50:36 - INFO - __main__ - [Train] glue-cola	8551
01/15/2024 10:50:36 - INFO - __main__ - [Dev] glue-cola	1043
01/15/2024 10:50:36 - INFO - __main__ - direct on None (1 train, 1 dev)
01/15/2024 10:50:36 - INFO - __main__ - start running soft prefix model
01/15/2024 10:50:36 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 10:50:36 - INFO - __main__ - Checking the first example...
Input:
Can he not have been working? acceptable
Output:
<glue-cola-0><glue-cola-1><glue-cola-2><glue-cola-3><glue-cola-4><glue-cola-5><glue-cola-6><glue-cola-7><glue-cola-8><glue-cola-9>
01/15/2024 10:50:36 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 10:50:52 - INFO - __main__ - time use for computing 100 examples: 15.915931463241577
01/15/2024 10:50:52 - INFO - __main__ - start running soft prefix model
01/15/2024 10:50:52 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 10:50:52 - INFO - __main__ - Checking the first example...
Input:
Can he not have been working? acceptable
Output:
<glue-mnli-0><glue-mnli-1><glue-mnli-2><glue-mnli-3><glue-mnli-4><glue-mnli-5><glue-mnli-6><glue-mnli-7><glue-mnli-8><glue-mnli-9>
01/15/2024 10:50:52 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 10:51:07 - INFO - __main__ - time use for computing 100 examples: 15.599363088607788
01/15/2024 10:51:07 - INFO - __main__ - start running soft prefix model
01/15/2024 10:51:07 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 10:51:08 - INFO - __main__ - Checking the first example...
Input:
Can he not have been working? acceptable
Output:
<glue-qqp-0><glue-qqp-1><glue-qqp-2><glue-qqp-3><glue-qqp-4><glue-qqp-5><glue-qqp-6><glue-qqp-7><glue-qqp-8><glue-qqp-9>
01/15/2024 10:51:08 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 10:51:23 - INFO - __main__ - time use for computing 100 examples: 15.641621112823486
01/15/2024 10:51:23 - INFO - __main__ - start running soft prefix model
01/15/2024 10:51:23 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 10:51:24 - INFO - __main__ - Checking the first example...
Input:
Can he not have been working? acceptable
Output:
<glue-mrpc-0><glue-mrpc-1><glue-mrpc-2><glue-mrpc-3><glue-mrpc-4><glue-mrpc-5><glue-mrpc-6><glue-mrpc-7><glue-mrpc-8><glue-mrpc-9>
01/15/2024 10:51:24 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 10:51:38 - INFO - __main__ - time use for computing 100 examples: 15.605701208114624
01/15/2024 10:51:38 - INFO - __main__ - start running soft prefix model
01/15/2024 10:51:38 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 10:51:39 - INFO - __main__ - Checking the first example...
Input:
Can he not have been working? acceptable
Output:
<glue-qnli-0><glue-qnli-1><glue-qnli-2><glue-qnli-3><glue-qnli-4><glue-qnli-5><glue-qnli-6><glue-qnli-7><glue-qnli-8><glue-qnli-9>
01/15/2024 10:51:39 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 10:51:54 - INFO - __main__ - time use for computing 100 examples: 15.637986898422241
01/15/2024 10:51:54 - INFO - __main__ - start running soft prefix model
01/15/2024 10:51:54 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 10:51:55 - INFO - __main__ - Checking the first example...
Input:
Can he not have been working? acceptable
Output:
<glue-rte-0><glue-rte-1><glue-rte-2><glue-rte-3><glue-rte-4><glue-rte-5><glue-rte-6><glue-rte-7><glue-rte-8><glue-rte-9>
01/15/2024 10:51:55 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 10:52:10 - INFO - __main__ - time use for computing 100 examples: 15.657450437545776
01/15/2024 10:52:10 - INFO - __main__ - start running soft prefix model
01/15/2024 10:52:10 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 10:52:11 - INFO - __main__ - Checking the first example...
Input:
Can he not have been working? acceptable
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 10:52:11 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 10:52:25 - INFO - __main__ - time use for computing 100 examples: 15.760919332504272
01/15/2024 10:52:25 - INFO - __main__ - start running soft prefix model
01/15/2024 10:52:25 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 10:52:26 - INFO - __main__ - Checking the first example...
Input:
Can he not have been working? acceptable
Output:
<glue-wnli-0><glue-wnli-1><glue-wnli-2><glue-wnli-3><glue-wnli-4><glue-wnli-5><glue-wnli-6><glue-wnli-7><glue-wnli-8><glue-wnli-9>
01/15/2024 10:52:26 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 10:52:41 - INFO - __main__ - time use for computing 100 examples: 15.796017408370972
01/15/2024 10:52:41 - INFO - __main__ - min difficulty: -inf
01/15/2024 10:52:41 - INFO - __main__ - max difficulty: 1.0
01/15/2024 10:52:41 - INFO - __main__ - average difficulty: -inf
01/15/2024 10:52:41 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 10:52:42 - INFO - __main__ - Checking the first example...
Input:
Can he not have been working? acceptable John made a fool of himself in front of everyone who was there. acceptable The only travelers who anybody has ever robbed don't carry machetes. acceptable John and Mary will play with Henry and with Sue. acceptable
Output:
<glue-cola-0><glue-cola-1><glue-cola-2><glue-cola-3><glue-cola-4><glue-cola-5><glue-cola-6><glue-cola-7><glue-cola-8><glue-cola-9>
01/15/2024 10:52:42 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 10:52:44 - INFO - __main__ - time use for computing 24 examples: 1.9843180179595947
01/15/2024 10:52:44 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 10:52:45 - INFO - __main__ - Checking the first example...
Input:
Can he not have been working? acceptable John made a fool of himself in front of everyone who was there. acceptable The only travelers who anybody has ever robbed don't carry machetes. acceptable John and Mary will play with Henry and with Sue. acceptable
Output:
<glue-cola-0><glue-cola-1><glue-cola-2><glue-cola-3><glue-cola-4><glue-cola-5><glue-cola-6><glue-cola-7><glue-cola-8><glue-cola-9>
01/15/2024 10:52:45 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 10:52:47 - INFO - __main__ - time use for computing 24 examples: 1.9645648002624512
01/15/2024 10:52:47 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 10:52:48 - INFO - __main__ - Checking the first example...
Input:
Can he not have been working? acceptable John made a fool of himself in front of everyone who was there. acceptable The only travelers who anybody has ever robbed don't carry machetes. acceptable John and Mary will play with Henry and with Sue. acceptable
Output:
<glue-cola-0><glue-cola-1><glue-cola-2><glue-cola-3><glue-cola-4><glue-cola-5><glue-cola-6><glue-cola-7><glue-cola-8><glue-cola-9>
01/15/2024 10:52:48 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 10:52:50 - INFO - __main__ - time use for computing 24 examples: 1.966041088104248
01/15/2024 10:52:50 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 10:52:51 - INFO - __main__ - Checking the first example...
Input:
Can he not have been working? acceptable John made a fool of himself in front of everyone who was there. acceptable The only travelers who anybody has ever robbed don't carry machetes. acceptable John and Mary will play with Henry and with Sue. acceptable
Output:
<glue-cola-0><glue-cola-1><glue-cola-2><glue-cola-3><glue-cola-4><glue-cola-5><glue-cola-6><glue-cola-7><glue-cola-8><glue-cola-9>
01/15/2024 10:52:51 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 10:52:52 - INFO - __main__ - time use for computing 24 examples: 1.9660615921020508
01/15/2024 10:52:52 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 10:52:53 - INFO - __main__ - Checking the first example...
Input:
Can he not have been working? acceptable John made a fool of himself in front of everyone who was there. acceptable The only travelers who anybody has ever robbed don't carry machetes. acceptable John and Mary will play with Henry and with Sue. acceptable
Output:
<glue-cola-0><glue-cola-1><glue-cola-2><glue-cola-3><glue-cola-4><glue-cola-5><glue-cola-6><glue-cola-7><glue-cola-8><glue-cola-9>
01/15/2024 10:52:53 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 10:52:55 - INFO - __main__ - time use for computing 24 examples: 1.9668948650360107
01/15/2024 10:52:55 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 10:52:56 - INFO - __main__ - Checking the first example...
Input:
Can he not have been working? acceptable John made a fool of himself in front of everyone who was there. acceptable The only travelers who anybody has ever robbed don't carry machetes. acceptable John and Mary will play with Henry and with Sue. acceptable
Output:
<glue-cola-0><glue-cola-1><glue-cola-2><glue-cola-3><glue-cola-4><glue-cola-5><glue-cola-6><glue-cola-7><glue-cola-8><glue-cola-9>
01/15/2024 10:52:56 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 10:52:58 - INFO - __main__ - time use for computing 24 examples: 1.9576725959777832
01/15/2024 10:52:58 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 10:52:59 - INFO - __main__ - Checking the first example...
Input:
Can he not have been working? acceptable John made a fool of himself in front of everyone who was there. acceptable The only travelers who anybody has ever robbed don't carry machetes. acceptable John and Mary will play with Henry and with Sue. acceptable
Output:
<glue-cola-0><glue-cola-1><glue-cola-2><glue-cola-3><glue-cola-4><glue-cola-5><glue-cola-6><glue-cola-7><glue-cola-8><glue-cola-9>
01/15/2024 10:52:59 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 10:53:01 - INFO - __main__ - time use for computing 24 examples: 1.9742648601531982
01/15/2024 10:53:01 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 10:53:02 - INFO - __main__ - Checking the first example...
Input:
Can he not have been working? acceptable John made a fool of himself in front of everyone who was there. acceptable The only travelers who anybody has ever robbed don't carry machetes. acceptable John and Mary will play with Henry and with Sue. acceptable
Output:
<glue-cola-0><glue-cola-1><glue-cola-2><glue-cola-3><glue-cola-4><glue-cola-5><glue-cola-6><glue-cola-7><glue-cola-8><glue-cola-9>
01/15/2024 10:53:02 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 10:53:03 - INFO - __main__ - time use for computing 24 examples: 1.963465690612793
01/15/2024 10:53:04 - INFO - __main__ - Checking the first example...
Input:
Can he not have been working? acceptable John made a fool of himself in front of everyone who was there. acceptable The only travelers who anybody has ever robbed don't carry machetes. acceptable John and Mary will play with Henry and with Sue. acceptable The kennel which Mary made and Fido sleeps has been stolen.
Output:
 acceptable
01/15/2024 10:53:04 - INFO - __main__ - torch.Size([2000, 1024])
01/15/2024 10:55:35 - INFO - __main__ - None task (seed=100): Macro-F1: 41.4, Accuracy: 68.9
01/15/2024 10:55:35 - INFO - __main__ - [Train] glue-cola	8551
01/15/2024 10:55:35 - INFO - __main__ - [Dev] glue-cola	1043
01/15/2024 10:55:35 - INFO - __main__ - direct on None (1 train, 1 dev)
01/15/2024 10:55:35 - INFO - __main__ - start running soft prefix model
01/15/2024 10:55:35 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 10:55:36 - INFO - __main__ - Checking the first example...
Input:
It is tough to please John. acceptable
Output:
<glue-cola-0><glue-cola-1><glue-cola-2><glue-cola-3><glue-cola-4><glue-cola-5><glue-cola-6><glue-cola-7><glue-cola-8><glue-cola-9>
01/15/2024 10:55:36 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 10:55:51 - INFO - __main__ - time use for computing 100 examples: 15.796745538711548
01/15/2024 10:55:51 - INFO - __main__ - start running soft prefix model
01/15/2024 10:55:51 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 10:55:52 - INFO - __main__ - Checking the first example...
Input:
It is tough to please John. acceptable
Output:
<glue-mnli-0><glue-mnli-1><glue-mnli-2><glue-mnli-3><glue-mnli-4><glue-mnli-5><glue-mnli-6><glue-mnli-7><glue-mnli-8><glue-mnli-9>
01/15/2024 10:55:52 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 10:56:07 - INFO - __main__ - time use for computing 100 examples: 15.789757251739502
01/15/2024 10:56:07 - INFO - __main__ - start running soft prefix model
01/15/2024 10:56:07 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 10:56:08 - INFO - __main__ - Checking the first example...
Input:
It is tough to please John. acceptable
Output:
<glue-qqp-0><glue-qqp-1><glue-qqp-2><glue-qqp-3><glue-qqp-4><glue-qqp-5><glue-qqp-6><glue-qqp-7><glue-qqp-8><glue-qqp-9>
01/15/2024 10:56:08 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 10:56:23 - INFO - __main__ - time use for computing 100 examples: 15.816358804702759
01/15/2024 10:56:23 - INFO - __main__ - start running soft prefix model
01/15/2024 10:56:23 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 10:56:24 - INFO - __main__ - Checking the first example...
Input:
It is tough to please John. acceptable
Output:
<glue-mrpc-0><glue-mrpc-1><glue-mrpc-2><glue-mrpc-3><glue-mrpc-4><glue-mrpc-5><glue-mrpc-6><glue-mrpc-7><glue-mrpc-8><glue-mrpc-9>
01/15/2024 10:56:24 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 10:56:39 - INFO - __main__ - time use for computing 100 examples: 15.794376134872437
01/15/2024 10:56:39 - INFO - __main__ - start running soft prefix model
01/15/2024 10:56:39 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 10:56:40 - INFO - __main__ - Checking the first example...
Input:
It is tough to please John. acceptable
Output:
<glue-qnli-0><glue-qnli-1><glue-qnli-2><glue-qnli-3><glue-qnli-4><glue-qnli-5><glue-qnli-6><glue-qnli-7><glue-qnli-8><glue-qnli-9>
01/15/2024 10:56:40 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 10:56:54 - INFO - __main__ - time use for computing 100 examples: 15.846590757369995
01/15/2024 10:56:54 - INFO - __main__ - start running soft prefix model
01/15/2024 10:56:54 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 10:56:56 - INFO - __main__ - Checking the first example...
Input:
It is tough to please John. acceptable
Output:
<glue-rte-0><glue-rte-1><glue-rte-2><glue-rte-3><glue-rte-4><glue-rte-5><glue-rte-6><glue-rte-7><glue-rte-8><glue-rte-9>
01/15/2024 10:56:56 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 10:57:10 - INFO - __main__ - time use for computing 100 examples: 15.873722791671753
01/15/2024 10:57:10 - INFO - __main__ - start running soft prefix model
01/15/2024 10:57:10 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 10:57:11 - INFO - __main__ - Checking the first example...
Input:
It is tough to please John. acceptable
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 10:57:11 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 10:57:26 - INFO - __main__ - time use for computing 100 examples: 15.688909769058228
01/15/2024 10:57:26 - INFO - __main__ - start running soft prefix model
01/15/2024 10:57:26 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 10:57:27 - INFO - __main__ - Checking the first example...
Input:
It is tough to please John. acceptable
Output:
<glue-wnli-0><glue-wnli-1><glue-wnli-2><glue-wnli-3><glue-wnli-4><glue-wnli-5><glue-wnli-6><glue-wnli-7><glue-wnli-8><glue-wnli-9>
01/15/2024 10:57:27 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 10:57:42 - INFO - __main__ - time use for computing 100 examples: 15.646539688110352
01/15/2024 10:57:42 - INFO - __main__ - min difficulty: -inf
01/15/2024 10:57:42 - INFO - __main__ - max difficulty: 1.0
01/15/2024 10:57:42 - INFO - __main__ - average difficulty: -inf
01/15/2024 10:57:42 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 10:57:43 - INFO - __main__ - Checking the first example...
Input:
It is tough to please John. acceptable Harry got to be more of a celebrity. acceptable Jack is more tall than thin. acceptable I will have eaten the beef waffles. acceptable
Output:
<glue-cola-0><glue-cola-1><glue-cola-2><glue-cola-3><glue-cola-4><glue-cola-5><glue-cola-6><glue-cola-7><glue-cola-8><glue-cola-9>
01/15/2024 10:57:43 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 10:57:44 - INFO - __main__ - time use for computing 24 examples: 1.9523124694824219
01/15/2024 10:57:44 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 10:57:45 - INFO - __main__ - Checking the first example...
Input:
It is tough to please John. acceptable Harry got to be more of a celebrity. acceptable Jack is more tall than thin. acceptable I will have eaten the beef waffles. acceptable
Output:
<glue-cola-0><glue-cola-1><glue-cola-2><glue-cola-3><glue-cola-4><glue-cola-5><glue-cola-6><glue-cola-7><glue-cola-8><glue-cola-9>
01/15/2024 10:57:45 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 10:57:47 - INFO - __main__ - time use for computing 24 examples: 1.9508657455444336
01/15/2024 10:57:47 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 10:57:48 - INFO - __main__ - Checking the first example...
Input:
It is tough to please John. acceptable Harry got to be more of a celebrity. acceptable Jack is more tall than thin. acceptable I will have eaten the beef waffles. acceptable
Output:
<glue-cola-0><glue-cola-1><glue-cola-2><glue-cola-3><glue-cola-4><glue-cola-5><glue-cola-6><glue-cola-7><glue-cola-8><glue-cola-9>
01/15/2024 10:57:48 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 10:57:50 - INFO - __main__ - time use for computing 24 examples: 1.9523115158081055
01/15/2024 10:57:50 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 10:57:50 - INFO - __main__ - Checking the first example...
Input:
It is tough to please John. acceptable Harry got to be more of a celebrity. acceptable Jack is more tall than thin. acceptable I will have eaten the beef waffles. acceptable
Output:
<glue-cola-0><glue-cola-1><glue-cola-2><glue-cola-3><glue-cola-4><glue-cola-5><glue-cola-6><glue-cola-7><glue-cola-8><glue-cola-9>
01/15/2024 10:57:50 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 10:57:52 - INFO - __main__ - time use for computing 24 examples: 1.9430522918701172
01/15/2024 10:57:52 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 10:57:53 - INFO - __main__ - Checking the first example...
Input:
It is tough to please John. acceptable Harry got to be more of a celebrity. acceptable Jack is more tall than thin. acceptable I will have eaten the beef waffles. acceptable
Output:
<glue-cola-0><glue-cola-1><glue-cola-2><glue-cola-3><glue-cola-4><glue-cola-5><glue-cola-6><glue-cola-7><glue-cola-8><glue-cola-9>
01/15/2024 10:57:53 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 10:57:55 - INFO - __main__ - time use for computing 24 examples: 1.9513068199157715
01/15/2024 10:57:55 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 10:57:56 - INFO - __main__ - Checking the first example...
Input:
It is tough to please John. acceptable Harry got to be more of a celebrity. acceptable Jack is more tall than thin. acceptable I will have eaten the beef waffles. acceptable
Output:
<glue-cola-0><glue-cola-1><glue-cola-2><glue-cola-3><glue-cola-4><glue-cola-5><glue-cola-6><glue-cola-7><glue-cola-8><glue-cola-9>
01/15/2024 10:57:56 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 10:57:57 - INFO - __main__ - time use for computing 24 examples: 1.954606056213379
01/15/2024 10:57:57 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 10:57:58 - INFO - __main__ - Checking the first example...
Input:
It is tough to please John. acceptable Harry got to be more of a celebrity. acceptable Jack is more tall than thin. acceptable I will have eaten the beef waffles. acceptable
Output:
<glue-cola-0><glue-cola-1><glue-cola-2><glue-cola-3><glue-cola-4><glue-cola-5><glue-cola-6><glue-cola-7><glue-cola-8><glue-cola-9>
01/15/2024 10:57:58 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 10:58:00 - INFO - __main__ - time use for computing 24 examples: 1.9601948261260986
01/15/2024 10:58:00 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 10:58:01 - INFO - __main__ - Checking the first example...
Input:
It is tough to please John. acceptable Harry got to be more of a celebrity. acceptable Jack is more tall than thin. acceptable I will have eaten the beef waffles. acceptable
Output:
<glue-cola-0><glue-cola-1><glue-cola-2><glue-cola-3><glue-cola-4><glue-cola-5><glue-cola-6><glue-cola-7><glue-cola-8><glue-cola-9>
01/15/2024 10:58:01 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 10:58:03 - INFO - __main__ - time use for computing 24 examples: 1.956406593322754
01/15/2024 10:58:03 - INFO - __main__ - Checking the first example...
Input:
It is tough to please John. acceptable Harry got to be more of a celebrity. acceptable Jack is more tall than thin. acceptable I will have eaten the beef waffles. acceptable Books were taken from each student and given to Mary by the other.
Output:
 acceptable
01/15/2024 10:58:03 - INFO - __main__ - torch.Size([2000, 1024])
01/15/2024 11:00:35 - INFO - __main__ - None task (seed=13): Macro-F1: 41.5, Accuracy: 69.2
01/15/2024 11:00:35 - INFO - __main__ - [Train] glue-cola	8551
01/15/2024 11:00:35 - INFO - __main__ - [Dev] glue-cola	1043
01/15/2024 11:00:35 - INFO - __main__ - direct on None (1 train, 1 dev)
01/15/2024 11:00:35 - INFO - __main__ - start running soft prefix model
01/15/2024 11:00:35 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 11:00:36 - INFO - __main__ - Checking the first example...
Input:
He's so reliable a man. acceptable
Output:
<glue-cola-0><glue-cola-1><glue-cola-2><glue-cola-3><glue-cola-4><glue-cola-5><glue-cola-6><glue-cola-7><glue-cola-8><glue-cola-9>
01/15/2024 11:00:36 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 11:00:51 - INFO - __main__ - time use for computing 100 examples: 15.678302764892578
01/15/2024 11:00:51 - INFO - __main__ - start running soft prefix model
01/15/2024 11:00:51 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 11:00:51 - INFO - __main__ - Checking the first example...
Input:
He's so reliable a man. acceptable
Output:
<glue-mnli-0><glue-mnli-1><glue-mnli-2><glue-mnli-3><glue-mnli-4><glue-mnli-5><glue-mnli-6><glue-mnli-7><glue-mnli-8><glue-mnli-9>
01/15/2024 11:00:51 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 11:01:06 - INFO - __main__ - time use for computing 100 examples: 15.663623094558716
01/15/2024 11:01:06 - INFO - __main__ - start running soft prefix model
01/15/2024 11:01:06 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 11:01:07 - INFO - __main__ - Checking the first example...
Input:
He's so reliable a man. acceptable
Output:
<glue-qqp-0><glue-qqp-1><glue-qqp-2><glue-qqp-3><glue-qqp-4><glue-qqp-5><glue-qqp-6><glue-qqp-7><glue-qqp-8><glue-qqp-9>
01/15/2024 11:01:07 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 11:01:22 - INFO - __main__ - time use for computing 100 examples: 15.670230388641357
01/15/2024 11:01:22 - INFO - __main__ - start running soft prefix model
01/15/2024 11:01:22 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 11:01:23 - INFO - __main__ - Checking the first example...
Input:
He's so reliable a man. acceptable
Output:
<glue-mrpc-0><glue-mrpc-1><glue-mrpc-2><glue-mrpc-3><glue-mrpc-4><glue-mrpc-5><glue-mrpc-6><glue-mrpc-7><glue-mrpc-8><glue-mrpc-9>
01/15/2024 11:01:23 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 11:01:38 - INFO - __main__ - time use for computing 100 examples: 15.653711318969727
01/15/2024 11:01:38 - INFO - __main__ - start running soft prefix model
01/15/2024 11:01:38 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 11:01:38 - INFO - __main__ - Checking the first example...
Input:
He's so reliable a man. acceptable
Output:
<glue-qnli-0><glue-qnli-1><glue-qnli-2><glue-qnli-3><glue-qnli-4><glue-qnli-5><glue-qnli-6><glue-qnli-7><glue-qnli-8><glue-qnli-9>
01/15/2024 11:01:38 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 11:01:53 - INFO - __main__ - time use for computing 100 examples: 15.64166808128357
01/15/2024 11:01:53 - INFO - __main__ - start running soft prefix model
01/15/2024 11:01:53 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 11:01:54 - INFO - __main__ - Checking the first example...
Input:
He's so reliable a man. acceptable
Output:
<glue-rte-0><glue-rte-1><glue-rte-2><glue-rte-3><glue-rte-4><glue-rte-5><glue-rte-6><glue-rte-7><glue-rte-8><glue-rte-9>
01/15/2024 11:01:54 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 11:02:09 - INFO - __main__ - time use for computing 100 examples: 15.663180828094482
01/15/2024 11:02:09 - INFO - __main__ - start running soft prefix model
01/15/2024 11:02:09 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 11:02:10 - INFO - __main__ - Checking the first example...
Input:
He's so reliable a man. acceptable
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 11:02:10 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 11:02:25 - INFO - __main__ - time use for computing 100 examples: 15.723926544189453
01/15/2024 11:02:25 - INFO - __main__ - start running soft prefix model
01/15/2024 11:02:25 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 11:02:25 - INFO - __main__ - Checking the first example...
Input:
He's so reliable a man. acceptable
Output:
<glue-wnli-0><glue-wnli-1><glue-wnli-2><glue-wnli-3><glue-wnli-4><glue-wnli-5><glue-wnli-6><glue-wnli-7><glue-wnli-8><glue-wnli-9>
01/15/2024 11:02:25 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 11:02:40 - INFO - __main__ - time use for computing 100 examples: 15.627333641052246
01/15/2024 11:02:40 - INFO - __main__ - min difficulty: -inf
01/15/2024 11:02:40 - INFO - __main__ - max difficulty: 1.0
01/15/2024 11:02:40 - INFO - __main__ - average difficulty: -inf
01/15/2024 11:02:40 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 11:02:41 - INFO - __main__ - Checking the first example...
Input:
He's so reliable a man. acceptable the book with a red cover from Blackwell of poems by Robert Burns takes a very long time to read. unacceptable She spruced up before the job interview. acceptable Maxwell isn't half the doctor that that he would be if he studied is certain. unacceptable
Output:
<glue-cola-0><glue-cola-1><glue-cola-2><glue-cola-3><glue-cola-4><glue-cola-5><glue-cola-6><glue-cola-7><glue-cola-8><glue-cola-9>
01/15/2024 11:02:41 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 11:02:43 - INFO - __main__ - time use for computing 24 examples: 1.9523837566375732
01/15/2024 11:02:43 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 11:02:44 - INFO - __main__ - Checking the first example...
Input:
He's so reliable a man. acceptable the book with a red cover from Blackwell of poems by Robert Burns takes a very long time to read. unacceptable She spruced up before the job interview. acceptable Maxwell isn't half the doctor that that he would be if he studied is certain. unacceptable
Output:
<glue-cola-0><glue-cola-1><glue-cola-2><glue-cola-3><glue-cola-4><glue-cola-5><glue-cola-6><glue-cola-7><glue-cola-8><glue-cola-9>
01/15/2024 11:02:44 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 11:02:45 - INFO - __main__ - time use for computing 24 examples: 1.960742473602295
01/15/2024 11:02:45 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 11:02:46 - INFO - __main__ - Checking the first example...
Input:
He's so reliable a man. acceptable the book with a red cover from Blackwell of poems by Robert Burns takes a very long time to read. unacceptable She spruced up before the job interview. acceptable Maxwell isn't half the doctor that that he would be if he studied is certain. unacceptable
Output:
<glue-cola-0><glue-cola-1><glue-cola-2><glue-cola-3><glue-cola-4><glue-cola-5><glue-cola-6><glue-cola-7><glue-cola-8><glue-cola-9>
01/15/2024 11:02:46 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 11:02:48 - INFO - __main__ - time use for computing 24 examples: 1.9435701370239258
01/15/2024 11:02:48 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 11:02:49 - INFO - __main__ - Checking the first example...
Input:
He's so reliable a man. acceptable the book with a red cover from Blackwell of poems by Robert Burns takes a very long time to read. unacceptable She spruced up before the job interview. acceptable Maxwell isn't half the doctor that that he would be if he studied is certain. unacceptable
Output:
<glue-cola-0><glue-cola-1><glue-cola-2><glue-cola-3><glue-cola-4><glue-cola-5><glue-cola-6><glue-cola-7><glue-cola-8><glue-cola-9>
01/15/2024 11:02:49 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 11:02:51 - INFO - __main__ - time use for computing 24 examples: 1.9520342350006104
01/15/2024 11:02:51 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 11:02:52 - INFO - __main__ - Checking the first example...
Input:
He's so reliable a man. acceptable the book with a red cover from Blackwell of poems by Robert Burns takes a very long time to read. unacceptable She spruced up before the job interview. acceptable Maxwell isn't half the doctor that that he would be if he studied is certain. unacceptable
Output:
<glue-cola-0><glue-cola-1><glue-cola-2><glue-cola-3><glue-cola-4><glue-cola-5><glue-cola-6><glue-cola-7><glue-cola-8><glue-cola-9>
01/15/2024 11:02:52 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 11:02:53 - INFO - __main__ - time use for computing 24 examples: 1.9497528076171875
01/15/2024 11:02:53 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 11:02:54 - INFO - __main__ - Checking the first example...
Input:
He's so reliable a man. acceptable the book with a red cover from Blackwell of poems by Robert Burns takes a very long time to read. unacceptable She spruced up before the job interview. acceptable Maxwell isn't half the doctor that that he would be if he studied is certain. unacceptable
Output:
<glue-cola-0><glue-cola-1><glue-cola-2><glue-cola-3><glue-cola-4><glue-cola-5><glue-cola-6><glue-cola-7><glue-cola-8><glue-cola-9>
01/15/2024 11:02:54 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 11:02:56 - INFO - __main__ - time use for computing 24 examples: 1.9615302085876465
01/15/2024 11:02:56 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 11:02:57 - INFO - __main__ - Checking the first example...
Input:
He's so reliable a man. acceptable the book with a red cover from Blackwell of poems by Robert Burns takes a very long time to read. unacceptable She spruced up before the job interview. acceptable Maxwell isn't half the doctor that that he would be if he studied is certain. unacceptable
Output:
<glue-cola-0><glue-cola-1><glue-cola-2><glue-cola-3><glue-cola-4><glue-cola-5><glue-cola-6><glue-cola-7><glue-cola-8><glue-cola-9>
01/15/2024 11:02:57 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 11:02:59 - INFO - __main__ - time use for computing 24 examples: 1.9527206420898438
01/15/2024 11:02:59 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 11:03:00 - INFO - __main__ - Checking the first example...
Input:
He's so reliable a man. acceptable the book with a red cover from Blackwell of poems by Robert Burns takes a very long time to read. unacceptable She spruced up before the job interview. acceptable Maxwell isn't half the doctor that that he would be if he studied is certain. unacceptable
Output:
<glue-cola-0><glue-cola-1><glue-cola-2><glue-cola-3><glue-cola-4><glue-cola-5><glue-cola-6><glue-cola-7><glue-cola-8><glue-cola-9>
01/15/2024 11:03:00 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 11:03:01 - INFO - __main__ - time use for computing 24 examples: 1.9567079544067383
01/15/2024 11:03:02 - INFO - __main__ - Checking the first example...
Input:
He's so reliable a man. acceptable the book with a red cover from Blackwell of poems by Robert Burns takes a very long time to read. unacceptable She spruced up before the job interview. acceptable Maxwell isn't half the doctor that that he would be if he studied is certain. unacceptable Frances hid the presents in the drawer.
Output:
 acceptable
01/15/2024 11:03:02 - INFO - __main__ - torch.Size([2000, 1024])
01/15/2024 11:05:33 - INFO - __main__ - None task (seed=21): Macro-F1: 50.3, Accuracy: 59.2
01/15/2024 11:05:33 - INFO - __main__ - [Train] glue-cola	8551
01/15/2024 11:05:33 - INFO - __main__ - [Dev] glue-cola	1043
01/15/2024 11:05:33 - INFO - __main__ - direct on None (1 train, 1 dev)
01/15/2024 11:05:33 - INFO - __main__ - start running soft prefix model
01/15/2024 11:05:33 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 11:05:34 - INFO - __main__ - Checking the first example...
Input:
The sign warned against skating on the pond. acceptable
Output:
<glue-cola-0><glue-cola-1><glue-cola-2><glue-cola-3><glue-cola-4><glue-cola-5><glue-cola-6><glue-cola-7><glue-cola-8><glue-cola-9>
01/15/2024 11:05:34 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 11:05:49 - INFO - __main__ - time use for computing 100 examples: 15.658299446105957
01/15/2024 11:05:49 - INFO - __main__ - start running soft prefix model
01/15/2024 11:05:49 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 11:05:50 - INFO - __main__ - Checking the first example...
Input:
The sign warned against skating on the pond. acceptable
Output:
<glue-mnli-0><glue-mnli-1><glue-mnli-2><glue-mnli-3><glue-mnli-4><glue-mnli-5><glue-mnli-6><glue-mnli-7><glue-mnli-8><glue-mnli-9>
01/15/2024 11:05:50 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 11:06:05 - INFO - __main__ - time use for computing 100 examples: 15.66074275970459
01/15/2024 11:06:05 - INFO - __main__ - start running soft prefix model
01/15/2024 11:06:05 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 11:06:06 - INFO - __main__ - Checking the first example...
Input:
The sign warned against skating on the pond. acceptable
Output:
<glue-qqp-0><glue-qqp-1><glue-qqp-2><glue-qqp-3><glue-qqp-4><glue-qqp-5><glue-qqp-6><glue-qqp-7><glue-qqp-8><glue-qqp-9>
01/15/2024 11:06:06 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 11:06:20 - INFO - __main__ - time use for computing 100 examples: 15.666935920715332
01/15/2024 11:06:20 - INFO - __main__ - start running soft prefix model
01/15/2024 11:06:20 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 11:06:21 - INFO - __main__ - Checking the first example...
Input:
The sign warned against skating on the pond. acceptable
Output:
<glue-mrpc-0><glue-mrpc-1><glue-mrpc-2><glue-mrpc-3><glue-mrpc-4><glue-mrpc-5><glue-mrpc-6><glue-mrpc-7><glue-mrpc-8><glue-mrpc-9>
01/15/2024 11:06:21 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 11:06:36 - INFO - __main__ - time use for computing 100 examples: 15.676616668701172
01/15/2024 11:06:36 - INFO - __main__ - start running soft prefix model
01/15/2024 11:06:36 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 11:06:37 - INFO - __main__ - Checking the first example...
Input:
The sign warned against skating on the pond. acceptable
Output:
<glue-qnli-0><glue-qnli-1><glue-qnli-2><glue-qnli-3><glue-qnli-4><glue-qnli-5><glue-qnli-6><glue-qnli-7><glue-qnli-8><glue-qnli-9>
01/15/2024 11:06:37 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 11:06:52 - INFO - __main__ - time use for computing 100 examples: 15.655139446258545
01/15/2024 11:06:52 - INFO - __main__ - start running soft prefix model
01/15/2024 11:06:52 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 11:06:53 - INFO - __main__ - Checking the first example...
Input:
The sign warned against skating on the pond. acceptable
Output:
<glue-rte-0><glue-rte-1><glue-rte-2><glue-rte-3><glue-rte-4><glue-rte-5><glue-rte-6><glue-rte-7><glue-rte-8><glue-rte-9>
01/15/2024 11:06:53 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 11:07:07 - INFO - __main__ - time use for computing 100 examples: 15.666785717010498
01/15/2024 11:07:07 - INFO - __main__ - start running soft prefix model
01/15/2024 11:07:07 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 11:07:08 - INFO - __main__ - Checking the first example...
Input:
The sign warned against skating on the pond. acceptable
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 11:07:08 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 11:07:23 - INFO - __main__ - time use for computing 100 examples: 15.672292947769165
01/15/2024 11:07:23 - INFO - __main__ - start running soft prefix model
01/15/2024 11:07:23 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 11:07:24 - INFO - __main__ - Checking the first example...
Input:
The sign warned against skating on the pond. acceptable
Output:
<glue-wnli-0><glue-wnli-1><glue-wnli-2><glue-wnli-3><glue-wnli-4><glue-wnli-5><glue-wnli-6><glue-wnli-7><glue-wnli-8><glue-wnli-9>
01/15/2024 11:07:24 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 11:07:39 - INFO - __main__ - time use for computing 100 examples: 15.654870986938477
01/15/2024 11:07:39 - INFO - __main__ - min difficulty: -inf
01/15/2024 11:07:39 - INFO - __main__ - max difficulty: 1.0
01/15/2024 11:07:39 - INFO - __main__ - average difficulty: -inf
01/15/2024 11:07:39 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 11:07:40 - INFO - __main__ - Checking the first example...
Input:
The sign warned against skating on the pond. acceptable The farmer loaded apples into the cart. acceptable I heated up the coffee and Sally wiped the table off. acceptable John meets often Mary. unacceptable
Output:
<glue-cola-0><glue-cola-1><glue-cola-2><glue-cola-3><glue-cola-4><glue-cola-5><glue-cola-6><glue-cola-7><glue-cola-8><glue-cola-9>
01/15/2024 11:07:40 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 11:07:41 - INFO - __main__ - time use for computing 24 examples: 1.9593687057495117
01/15/2024 11:07:41 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 11:07:42 - INFO - __main__ - Checking the first example...
Input:
The sign warned against skating on the pond. acceptable The farmer loaded apples into the cart. acceptable I heated up the coffee and Sally wiped the table off. acceptable John meets often Mary. unacceptable
Output:
<glue-cola-0><glue-cola-1><glue-cola-2><glue-cola-3><glue-cola-4><glue-cola-5><glue-cola-6><glue-cola-7><glue-cola-8><glue-cola-9>
01/15/2024 11:07:42 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 11:07:44 - INFO - __main__ - time use for computing 24 examples: 1.9565014839172363
01/15/2024 11:07:44 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 11:07:45 - INFO - __main__ - Checking the first example...
Input:
The sign warned against skating on the pond. acceptable The farmer loaded apples into the cart. acceptable I heated up the coffee and Sally wiped the table off. acceptable John meets often Mary. unacceptable
Output:
<glue-cola-0><glue-cola-1><glue-cola-2><glue-cola-3><glue-cola-4><glue-cola-5><glue-cola-6><glue-cola-7><glue-cola-8><glue-cola-9>
01/15/2024 11:07:45 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 11:07:47 - INFO - __main__ - time use for computing 24 examples: 1.9675681591033936
01/15/2024 11:07:47 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 11:07:48 - INFO - __main__ - Checking the first example...
Input:
The sign warned against skating on the pond. acceptable The farmer loaded apples into the cart. acceptable I heated up the coffee and Sally wiped the table off. acceptable John meets often Mary. unacceptable
Output:
<glue-cola-0><glue-cola-1><glue-cola-2><glue-cola-3><glue-cola-4><glue-cola-5><glue-cola-6><glue-cola-7><glue-cola-8><glue-cola-9>
01/15/2024 11:07:48 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 11:07:49 - INFO - __main__ - time use for computing 24 examples: 1.9626142978668213
01/15/2024 11:07:49 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 11:07:50 - INFO - __main__ - Checking the first example...
Input:
The sign warned against skating on the pond. acceptable The farmer loaded apples into the cart. acceptable I heated up the coffee and Sally wiped the table off. acceptable John meets often Mary. unacceptable
Output:
<glue-cola-0><glue-cola-1><glue-cola-2><glue-cola-3><glue-cola-4><glue-cola-5><glue-cola-6><glue-cola-7><glue-cola-8><glue-cola-9>
01/15/2024 11:07:50 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 11:07:52 - INFO - __main__ - time use for computing 24 examples: 1.9887516498565674
01/15/2024 11:07:52 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 11:07:53 - INFO - __main__ - Checking the first example...
Input:
The sign warned against skating on the pond. acceptable The farmer loaded apples into the cart. acceptable I heated up the coffee and Sally wiped the table off. acceptable John meets often Mary. unacceptable
Output:
<glue-cola-0><glue-cola-1><glue-cola-2><glue-cola-3><glue-cola-4><glue-cola-5><glue-cola-6><glue-cola-7><glue-cola-8><glue-cola-9>
01/15/2024 11:07:53 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 11:07:55 - INFO - __main__ - time use for computing 24 examples: 1.9784197807312012
01/15/2024 11:07:55 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 11:07:56 - INFO - __main__ - Checking the first example...
Input:
The sign warned against skating on the pond. acceptable The farmer loaded apples into the cart. acceptable I heated up the coffee and Sally wiped the table off. acceptable John meets often Mary. unacceptable
Output:
<glue-cola-0><glue-cola-1><glue-cola-2><glue-cola-3><glue-cola-4><glue-cola-5><glue-cola-6><glue-cola-7><glue-cola-8><glue-cola-9>
01/15/2024 11:07:56 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 11:07:58 - INFO - __main__ - time use for computing 24 examples: 1.9843254089355469
01/15/2024 11:07:58 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 11:07:59 - INFO - __main__ - Checking the first example...
Input:
The sign warned against skating on the pond. acceptable The farmer loaded apples into the cart. acceptable I heated up the coffee and Sally wiped the table off. acceptable John meets often Mary. unacceptable
Output:
<glue-cola-0><glue-cola-1><glue-cola-2><glue-cola-3><glue-cola-4><glue-cola-5><glue-cola-6><glue-cola-7><glue-cola-8><glue-cola-9>
01/15/2024 11:07:59 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 11:08:00 - INFO - __main__ - time use for computing 24 examples: 1.971470594406128
01/15/2024 11:08:01 - INFO - __main__ - Checking the first example...
Input:
The sign warned against skating on the pond. acceptable The farmer loaded apples into the cart. acceptable I heated up the coffee and Sally wiped the table off. acceptable John meets often Mary. unacceptable John made Bill master of himself.
Output:
 acceptable
01/15/2024 11:08:01 - INFO - __main__ - torch.Size([2000, 1024])
01/15/2024 11:10:32 - INFO - __main__ - None task (seed=42): Macro-F1: 41.3, Accuracy: 68.6
01/15/2024 11:10:32 - INFO - __main__ - [Train] glue-cola	8551
01/15/2024 11:10:32 - INFO - __main__ - [Dev] glue-cola	1043
01/15/2024 11:10:32 - INFO - __main__ - direct on None (1 train, 1 dev)
01/15/2024 11:10:32 - INFO - __main__ - start running soft prefix model
01/15/2024 11:10:32 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 11:10:33 - INFO - __main__ - Checking the first example...
Input:
Jean moved at the table. acceptable
Output:
<glue-cola-0><glue-cola-1><glue-cola-2><glue-cola-3><glue-cola-4><glue-cola-5><glue-cola-6><glue-cola-7><glue-cola-8><glue-cola-9>
01/15/2024 11:10:33 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 11:10:48 - INFO - __main__ - time use for computing 100 examples: 15.675403118133545
01/15/2024 11:10:48 - INFO - __main__ - start running soft prefix model
01/15/2024 11:10:48 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 11:10:49 - INFO - __main__ - Checking the first example...
Input:
Jean moved at the table. acceptable
Output:
<glue-mnli-0><glue-mnli-1><glue-mnli-2><glue-mnli-3><glue-mnli-4><glue-mnli-5><glue-mnli-6><glue-mnli-7><glue-mnli-8><glue-mnli-9>
01/15/2024 11:10:49 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 11:11:04 - INFO - __main__ - time use for computing 100 examples: 15.678098440170288
01/15/2024 11:11:04 - INFO - __main__ - start running soft prefix model
01/15/2024 11:11:04 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 11:11:05 - INFO - __main__ - Checking the first example...
Input:
Jean moved at the table. acceptable
Output:
<glue-qqp-0><glue-qqp-1><glue-qqp-2><glue-qqp-3><glue-qqp-4><glue-qqp-5><glue-qqp-6><glue-qqp-7><glue-qqp-8><glue-qqp-9>
01/15/2024 11:11:05 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 11:11:20 - INFO - __main__ - time use for computing 100 examples: 15.666043758392334
01/15/2024 11:11:20 - INFO - __main__ - start running soft prefix model
01/15/2024 11:11:20 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 11:11:20 - INFO - __main__ - Checking the first example...
Input:
Jean moved at the table. acceptable
Output:
<glue-mrpc-0><glue-mrpc-1><glue-mrpc-2><glue-mrpc-3><glue-mrpc-4><glue-mrpc-5><glue-mrpc-6><glue-mrpc-7><glue-mrpc-8><glue-mrpc-9>
01/15/2024 11:11:20 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 11:11:35 - INFO - __main__ - time use for computing 100 examples: 15.674875497817993
01/15/2024 11:11:35 - INFO - __main__ - start running soft prefix model
01/15/2024 11:11:35 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 11:11:36 - INFO - __main__ - Checking the first example...
Input:
Jean moved at the table. acceptable
Output:
<glue-qnli-0><glue-qnli-1><glue-qnli-2><glue-qnli-3><glue-qnli-4><glue-qnli-5><glue-qnli-6><glue-qnli-7><glue-qnli-8><glue-qnli-9>
01/15/2024 11:11:36 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 11:11:51 - INFO - __main__ - time use for computing 100 examples: 15.676931142807007
01/15/2024 11:11:51 - INFO - __main__ - start running soft prefix model
01/15/2024 11:11:51 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 11:11:52 - INFO - __main__ - Checking the first example...
Input:
Jean moved at the table. acceptable
Output:
<glue-rte-0><glue-rte-1><glue-rte-2><glue-rte-3><glue-rte-4><glue-rte-5><glue-rte-6><glue-rte-7><glue-rte-8><glue-rte-9>
01/15/2024 11:11:52 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 11:12:07 - INFO - __main__ - time use for computing 100 examples: 15.677522420883179
01/15/2024 11:12:07 - INFO - __main__ - start running soft prefix model
01/15/2024 11:12:07 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 11:12:07 - INFO - __main__ - Checking the first example...
Input:
Jean moved at the table. acceptable
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 11:12:07 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 11:12:22 - INFO - __main__ - time use for computing 100 examples: 15.681393384933472
01/15/2024 11:12:22 - INFO - __main__ - start running soft prefix model
01/15/2024 11:12:22 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 11:12:23 - INFO - __main__ - Checking the first example...
Input:
Jean moved at the table. acceptable
Output:
<glue-wnli-0><glue-wnli-1><glue-wnli-2><glue-wnli-3><glue-wnli-4><glue-wnli-5><glue-wnli-6><glue-wnli-7><glue-wnli-8><glue-wnli-9>
01/15/2024 11:12:23 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 11:12:38 - INFO - __main__ - time use for computing 100 examples: 15.673030376434326
01/15/2024 11:12:38 - INFO - __main__ - min difficulty: -inf
01/15/2024 11:12:38 - INFO - __main__ - max difficulty: 1.0
01/15/2024 11:12:38 - INFO - __main__ - average difficulty: -inf
01/15/2024 11:12:38 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 11:12:39 - INFO - __main__ - Checking the first example...
Input:
Jean moved at the table. unacceptable Into which room did Jeeves sauntered? acceptable A fire raged in the mountains. acceptable Mr Elton handed his wife into the carriage. acceptable
Output:
<glue-cola-0><glue-cola-1><glue-cola-2><glue-cola-3><glue-cola-4><glue-cola-5><glue-cola-6><glue-cola-7><glue-cola-8><glue-cola-9>
01/15/2024 11:12:39 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 11:12:41 - INFO - __main__ - time use for computing 24 examples: 1.946105718612671
01/15/2024 11:12:41 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 11:12:41 - INFO - __main__ - Checking the first example...
Input:
Jean moved at the table. unacceptable Into which room did Jeeves sauntered? acceptable A fire raged in the mountains. acceptable Mr Elton handed his wife into the carriage. acceptable
Output:
<glue-cola-0><glue-cola-1><glue-cola-2><glue-cola-3><glue-cola-4><glue-cola-5><glue-cola-6><glue-cola-7><glue-cola-8><glue-cola-9>
01/15/2024 11:12:41 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 11:12:43 - INFO - __main__ - time use for computing 24 examples: 1.9510979652404785
01/15/2024 11:12:43 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 11:12:44 - INFO - __main__ - Checking the first example...
Input:
Jean moved at the table. unacceptable Into which room did Jeeves sauntered? acceptable A fire raged in the mountains. acceptable Mr Elton handed his wife into the carriage. acceptable
Output:
<glue-cola-0><glue-cola-1><glue-cola-2><glue-cola-3><glue-cola-4><glue-cola-5><glue-cola-6><glue-cola-7><glue-cola-8><glue-cola-9>
01/15/2024 11:12:44 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 11:12:46 - INFO - __main__ - time use for computing 24 examples: 1.9484717845916748
01/15/2024 11:12:46 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 11:12:47 - INFO - __main__ - Checking the first example...
Input:
Jean moved at the table. unacceptable Into which room did Jeeves sauntered? acceptable A fire raged in the mountains. acceptable Mr Elton handed his wife into the carriage. acceptable
Output:
<glue-cola-0><glue-cola-1><glue-cola-2><glue-cola-3><glue-cola-4><glue-cola-5><glue-cola-6><glue-cola-7><glue-cola-8><glue-cola-9>
01/15/2024 11:12:47 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 11:12:48 - INFO - __main__ - time use for computing 24 examples: 1.9589226245880127
01/15/2024 11:12:48 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 11:12:49 - INFO - __main__ - Checking the first example...
Input:
Jean moved at the table. unacceptable Into which room did Jeeves sauntered? acceptable A fire raged in the mountains. acceptable Mr Elton handed his wife into the carriage. acceptable
Output:
<glue-cola-0><glue-cola-1><glue-cola-2><glue-cola-3><glue-cola-4><glue-cola-5><glue-cola-6><glue-cola-7><glue-cola-8><glue-cola-9>
01/15/2024 11:12:49 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 11:12:51 - INFO - __main__ - time use for computing 24 examples: 1.961064338684082
01/15/2024 11:12:51 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 11:12:52 - INFO - __main__ - Checking the first example...
Input:
Jean moved at the table. unacceptable Into which room did Jeeves sauntered? acceptable A fire raged in the mountains. acceptable Mr Elton handed his wife into the carriage. acceptable
Output:
<glue-cola-0><glue-cola-1><glue-cola-2><glue-cola-3><glue-cola-4><glue-cola-5><glue-cola-6><glue-cola-7><glue-cola-8><glue-cola-9>
01/15/2024 11:12:52 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 11:12:54 - INFO - __main__ - time use for computing 24 examples: 1.948286771774292
01/15/2024 11:12:54 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 11:12:55 - INFO - __main__ - Checking the first example...
Input:
Jean moved at the table. unacceptable Into which room did Jeeves sauntered? acceptable A fire raged in the mountains. acceptable Mr Elton handed his wife into the carriage. acceptable
Output:
<glue-cola-0><glue-cola-1><glue-cola-2><glue-cola-3><glue-cola-4><glue-cola-5><glue-cola-6><glue-cola-7><glue-cola-8><glue-cola-9>
01/15/2024 11:12:55 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 11:12:56 - INFO - __main__ - time use for computing 24 examples: 1.9562301635742188
01/15/2024 11:12:56 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 11:12:57 - INFO - __main__ - Checking the first example...
Input:
Jean moved at the table. unacceptable Into which room did Jeeves sauntered? acceptable A fire raged in the mountains. acceptable Mr Elton handed his wife into the carriage. acceptable
Output:
<glue-cola-0><glue-cola-1><glue-cola-2><glue-cola-3><glue-cola-4><glue-cola-5><glue-cola-6><glue-cola-7><glue-cola-8><glue-cola-9>
01/15/2024 11:12:57 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 11:12:59 - INFO - __main__ - time use for computing 24 examples: 1.9627981185913086
01/15/2024 11:13:00 - INFO - __main__ - Checking the first example...
Input:
Jean moved at the table. unacceptable Into which room did Jeeves sauntered? acceptable A fire raged in the mountains. acceptable Mr Elton handed his wife into the carriage. acceptable John is sick.
Output:
 acceptable
01/15/2024 11:13:00 - INFO - __main__ - torch.Size([2000, 1024])
01/15/2024 11:15:31 - INFO - __main__ - None task (seed=87): Macro-F1: 41.4, Accuracy: 69.0
01/15/2024 11:15:31 - INFO - __main__ - None over 1 target tasks with majority vote: Macro-F1: 40.9, Accuracy: 69.3
01/15/2024 11:15:31 - INFO - __main__ - None over 1 target tasks on average: Macro-F1: 43.2 +- 3.5, Accuracy: 67.0 +- 3.9
