01/18/2024 19:17:25 - INFO - __main__ - Namespace(use_demonstrations=True, use_soft_prefix=False, use_soft_postfix=False, n_prefix_tokens=10, max_length=1024, prior=['easiest'], difficulty='concept_calibrated', reorder=True, log_dir='logs', out_dir='out\\gpt2', load_dir=None, concept_dir='concept_likelihood\\gpt2-medium\\glue-glue-100\\glue-sst2-channel-prefix=10-lr=1e-5-3000', prefix_embed_file='checkpoints\\gpt2-medium\\glue-glue\\prefix={10}-{channel}-lr={1e-5}-initByVocab\\soft_embeddings-3000.pt', task=None, dataset='glue-sst2', data_dir='data/', k=4, seed='100,13,21,42,87', test_batch_size=8, global_step=None, use_random_english_words=False, use_random_label=False, use_instruction=False, unseen_domain_only=False, split='test', method='channel', gpt='gpt2', api=None, test_size=1000, train_size=100, embedding_dir='embeddings\\', embedding_model='all-mpnet-base-v2', similarity_temperature=0.1, concept_temperature=50.0)
01/18/2024 19:17:27 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/18/2024 19:17:29 - INFO - __main__ - batch_size=8	max_length=1024	max_length_per_example=256
01/18/2024 19:17:31 - INFO - __main__ - [Train] glue-sst2	67349
01/18/2024 19:17:31 - INFO - __main__ - [Dev] glue-sst2	872
01/18/2024 19:17:31 - INFO - __main__ - channel on None (1 train, 1 dev)
01/18/2024 19:17:31 - INFO - __main__ - start running soft prefix model
01/18/2024 19:17:31 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/18/2024 19:17:35 - INFO - __main__ - Checking the first example...
Input:
negative sentence: the stars may be college kids, but the subject matter is as adult as you can get :
Output:
<glue-cola-0><glue-cola-1><glue-cola-2><glue-cola-3><glue-cola-4><glue-cola-5><glue-cola-6><glue-cola-7><glue-cola-8><glue-cola-9>
01/18/2024 19:17:35 - INFO - __main__ - torch.Size([200, 1024])
