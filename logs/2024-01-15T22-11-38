01/15/2024 22:11:38 - INFO - __main__ - Namespace(use_demonstrations=True, use_soft_prefix=False, use_soft_postfix=False, n_prefix_tokens=10, max_length=1024, prior=['easiest'], difficulty='concept_calibrated', reorder=True, log_dir='logs', out_dir='out\\gpt2', load_dir=None, concept_dir='concept_likelihood\\gpt2-medium\\glue-glue-100\\glue-sst2-channel-prefix=10-lr=1e-5-1000', prefix_embed_file='checkpoints\\gpt2-medium\\glue-glue\\prefix={10}-{channel}-lr={1e-5}-initByVocab\\soft_embeddings-1000.pt', task=None, dataset='glue-sst2', data_dir='data/', k=4, seed='100,13,21,42,87', test_batch_size=8, global_step=None, use_random_english_words=False, use_random_label=False, use_instruction=False, unseen_domain_only=False, split='test', method='channel', gpt='gpt2', api=None, test_size=1000, train_size=100, embedding_dir='embeddings\\', embedding_model='all-mpnet-base-v2', similarity_temperature=0.1, concept_temperature=50.0)
01/15/2024 22:11:40 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:11:41 - INFO - __main__ - batch_size=8	max_length=1024	max_length_per_example=256
01/15/2024 22:11:42 - INFO - __main__ - [Train] glue-sst2	67349
01/15/2024 22:11:42 - INFO - __main__ - [Dev] glue-sst2	872
01/15/2024 22:11:42 - INFO - __main__ - channel on None (1 train, 1 dev)
01/15/2024 22:11:42 - INFO - __main__ - loading saved concept likelihoods
01/15/2024 22:11:42 - INFO - __main__ - loading saved concept likelihoods
01/15/2024 22:11:42 - INFO - __main__ - loading saved concept likelihoods
01/15/2024 22:11:42 - INFO - __main__ - loading saved concept likelihoods
01/15/2024 22:11:42 - INFO - __main__ - loading saved concept likelihoods
01/15/2024 22:11:42 - INFO - __main__ - loading saved concept likelihoods
01/15/2024 22:11:42 - INFO - __main__ - loading saved concept likelihoods
01/15/2024 22:11:42 - INFO - __main__ - loading saved concept likelihoods
01/15/2024 22:11:42 - INFO - __main__ - min difficulty: -inf
01/15/2024 22:11:42 - INFO - __main__ - max difficulty: -inf
01/15/2024 22:11:42 - INFO - __main__ - average difficulty: -inf
01/15/2024 22:11:42 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:11:44 - INFO - __main__ - loading saved demo nlls
01/15/2024 22:11:44 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:11:47 - INFO - __main__ - loading saved demo nlls
01/15/2024 22:11:47 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:11:48 - INFO - __main__ - loading saved demo nlls
01/15/2024 22:11:48 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:11:50 - INFO - __main__ - loading saved demo nlls
01/15/2024 22:11:50 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:11:52 - INFO - __main__ - loading saved demo nlls
01/15/2024 22:11:52 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:11:53 - INFO - __main__ - loading saved demo nlls
01/15/2024 22:11:53 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:11:55 - INFO - __main__ - loading saved demo nlls
01/15/2024 22:11:55 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:11:57 - INFO - __main__ - loading saved demo nlls
01/15/2024 22:11:58 - INFO - __main__ - Checking the first example...
Input:
positive
sentence: the stars may be college kids, but the subject matter is as adult as you can get :


negative
sentence:, it isn't much fun.


negative
sentence: a case of too many chefs fussing over too weak a recipe


positive
sentence: hubert with a mixture of deadpan cool, wry humor and just the measure of tenderness required to give this comic slugfest some heart


negative
Output:

sentence: it's a charming and often affecting journey.
01/15/2024 22:11:58 - INFO - __main__ - torch.Size([1744, 1024])
01/15/2024 22:14:28 - INFO - __main__ - None task (seed=100): Macro-F1: 34.4, Accuracy: 49.8
01/15/2024 22:14:28 - INFO - __main__ - [Train] glue-sst2	67349
01/15/2024 22:14:28 - INFO - __main__ - [Dev] glue-sst2	872
01/15/2024 22:14:28 - INFO - __main__ - channel on None (1 train, 1 dev)
01/15/2024 22:14:28 - INFO - __main__ - start running soft prefix model
01/15/2024 22:14:28 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:14:33 - INFO - __main__ - Checking the first example...
Input:
negative
sentence: well worth revisiting as many times
Output:
<glue-cola-0><glue-cola-1><glue-cola-2><glue-cola-3><glue-cola-4><glue-cola-5><glue-cola-6><glue-cola-7><glue-cola-8><glue-cola-9>
01/15/2024 22:14:33 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 22:15:27 - INFO - __main__ - time use for computing 100 examples: 59.02879095077515
01/15/2024 22:15:27 - INFO - __main__ - start running soft prefix model
01/15/2024 22:15:27 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:15:32 - INFO - __main__ - Checking the first example...
Input:
negative
sentence: well worth revisiting as many times
Output:
<glue-mnli-0><glue-mnli-1><glue-mnli-2><glue-mnli-3><glue-mnli-4><glue-mnli-5><glue-mnli-6><glue-mnli-7><glue-mnli-8><glue-mnli-9>
01/15/2024 22:15:32 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 22:16:25 - INFO - __main__ - time use for computing 100 examples: 58.185747146606445
01/15/2024 22:16:25 - INFO - __main__ - start running soft prefix model
01/15/2024 22:16:25 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:16:30 - INFO - __main__ - Checking the first example...
Input:
negative
sentence: well worth revisiting as many times
Output:
<glue-qqp-0><glue-qqp-1><glue-qqp-2><glue-qqp-3><glue-qqp-4><glue-qqp-5><glue-qqp-6><glue-qqp-7><glue-qqp-8><glue-qqp-9>
01/15/2024 22:16:30 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 22:17:24 - INFO - __main__ - time use for computing 100 examples: 58.35821461677551
01/15/2024 22:17:24 - INFO - __main__ - start running soft prefix model
01/15/2024 22:17:24 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:17:28 - INFO - __main__ - Checking the first example...
Input:
negative
sentence: well worth revisiting as many times
Output:
<glue-mrpc-0><glue-mrpc-1><glue-mrpc-2><glue-mrpc-3><glue-mrpc-4><glue-mrpc-5><glue-mrpc-6><glue-mrpc-7><glue-mrpc-8><glue-mrpc-9>
01/15/2024 22:17:28 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 22:18:22 - INFO - __main__ - time use for computing 100 examples: 58.20786190032959
01/15/2024 22:18:22 - INFO - __main__ - start running soft prefix model
01/15/2024 22:18:22 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:18:26 - INFO - __main__ - Checking the first example...
Input:
negative
sentence: well worth revisiting as many times
Output:
<glue-qnli-0><glue-qnli-1><glue-qnli-2><glue-qnli-3><glue-qnli-4><glue-qnli-5><glue-qnli-6><glue-qnli-7><glue-qnli-8><glue-qnli-9>
01/15/2024 22:18:26 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 22:19:20 - INFO - __main__ - time use for computing 100 examples: 58.36520743370056
01/15/2024 22:19:20 - INFO - __main__ - start running soft prefix model
01/15/2024 22:19:20 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:19:25 - INFO - __main__ - Checking the first example...
Input:
negative
sentence: well worth revisiting as many times
Output:
<glue-rte-0><glue-rte-1><glue-rte-2><glue-rte-3><glue-rte-4><glue-rte-5><glue-rte-6><glue-rte-7><glue-rte-8><glue-rte-9>
01/15/2024 22:19:25 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 22:20:19 - INFO - __main__ - time use for computing 100 examples: 58.42800951004028
01/15/2024 22:20:19 - INFO - __main__ - start running soft prefix model
01/15/2024 22:20:19 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:20:23 - INFO - __main__ - Checking the first example...
Input:
negative
sentence: well worth revisiting as many times
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 22:20:23 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 22:21:17 - INFO - __main__ - time use for computing 100 examples: 58.01045060157776
01/15/2024 22:21:17 - INFO - __main__ - start running soft prefix model
01/15/2024 22:21:17 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:21:21 - INFO - __main__ - Checking the first example...
Input:
negative
sentence: well worth revisiting as many times
Output:
<glue-wnli-0><glue-wnli-1><glue-wnli-2><glue-wnli-3><glue-wnli-4><glue-wnli-5><glue-wnli-6><glue-wnli-7><glue-wnli-8><glue-wnli-9>
01/15/2024 22:21:21 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 22:22:15 - INFO - __main__ - time use for computing 100 examples: 58.083003997802734
01/15/2024 22:22:15 - INFO - __main__ - min difficulty: -inf
01/15/2024 22:22:15 - INFO - __main__ - max difficulty: -inf
01/15/2024 22:22:15 - INFO - __main__ - average difficulty: -inf
01/15/2024 22:22:15 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:22:19 - INFO - __main__ - Checking the first example...
Input:
positive
sentence: well worth revisiting as many times


negative
sentence:'re just a couple of cops in copmovieland, these two


positive
sentence: is impressively true for being so hot-blooded


positive
sentence: like the rugrats movies, the wild thornberrys movie doesn't offer much more than the series, but its emphasis on caring for animals and respecting other cultures is particularly welcome
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 22:22:19 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 22:22:26 - INFO - __main__ - time use for computing 24 examples: 8.963380813598633
01/15/2024 22:22:26 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:22:30 - INFO - __main__ - Checking the first example...
Input:
positive
sentence: well worth revisiting as many times


negative
sentence:'re just a couple of cops in copmovieland, these two


positive
sentence: is impressively true for being so hot-blooded


positive
sentence: like the rugrats movies, the wild thornberrys movie doesn't offer much more than the series, but its emphasis on caring for animals and respecting other cultures is particularly welcome
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 22:22:30 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 22:22:37 - INFO - __main__ - time use for computing 24 examples: 9.27206301689148
01/15/2024 22:22:37 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:22:41 - INFO - __main__ - Checking the first example...
Input:
positive
sentence: well worth revisiting as many times


negative
sentence:'re just a couple of cops in copmovieland, these two


positive
sentence: is impressively true for being so hot-blooded


positive
sentence: like the rugrats movies, the wild thornberrys movie doesn't offer much more than the series, but its emphasis on caring for animals and respecting other cultures is particularly welcome
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 22:22:41 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 22:22:48 - INFO - __main__ - time use for computing 24 examples: 8.95155382156372
01/15/2024 22:22:48 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:22:52 - INFO - __main__ - Checking the first example...
Input:
positive
sentence: well worth revisiting as many times


negative
sentence:'re just a couple of cops in copmovieland, these two


positive
sentence: is impressively true for being so hot-blooded


positive
sentence: like the rugrats movies, the wild thornberrys movie doesn't offer much more than the series, but its emphasis on caring for animals and respecting other cultures is particularly welcome
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 22:22:52 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 22:22:59 - INFO - __main__ - time use for computing 24 examples: 9.139304876327515
01/15/2024 22:22:59 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:23:04 - INFO - __main__ - Checking the first example...
Input:
positive
sentence: well worth revisiting as many times


negative
sentence:'re just a couple of cops in copmovieland, these two


positive
sentence: is impressively true for being so hot-blooded


positive
sentence: like the rugrats movies, the wild thornberrys movie doesn't offer much more than the series, but its emphasis on caring for animals and respecting other cultures is particularly welcome
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 22:23:04 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 22:23:11 - INFO - __main__ - time use for computing 24 examples: 8.946771621704102
01/15/2024 22:23:11 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:23:15 - INFO - __main__ - Checking the first example...
Input:
positive
sentence: well worth revisiting as many times


negative
sentence:'re just a couple of cops in copmovieland, these two


positive
sentence: is impressively true for being so hot-blooded


positive
sentence: like the rugrats movies, the wild thornberrys movie doesn't offer much more than the series, but its emphasis on caring for animals and respecting other cultures is particularly welcome
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 22:23:15 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 22:23:22 - INFO - __main__ - time use for computing 24 examples: 9.18709135055542
01/15/2024 22:23:22 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:23:26 - INFO - __main__ - Checking the first example...
Input:
positive
sentence: well worth revisiting as many times


negative
sentence:'re just a couple of cops in copmovieland, these two


positive
sentence: is impressively true for being so hot-blooded


positive
sentence: like the rugrats movies, the wild thornberrys movie doesn't offer much more than the series, but its emphasis on caring for animals and respecting other cultures is particularly welcome
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 22:23:26 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 22:23:33 - INFO - __main__ - time use for computing 24 examples: 9.17984414100647
01/15/2024 22:23:33 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:23:37 - INFO - __main__ - Checking the first example...
Input:
positive
sentence: well worth revisiting as many times


negative
sentence:'re just a couple of cops in copmovieland, these two


positive
sentence: is impressively true for being so hot-blooded


positive
sentence: like the rugrats movies, the wild thornberrys movie doesn't offer much more than the series, but its emphasis on caring for animals and respecting other cultures is particularly welcome
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 22:23:37 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 22:23:44 - INFO - __main__ - time use for computing 24 examples: 9.055961608886719
01/15/2024 22:23:45 - INFO - __main__ - Checking the first example...
Input:
positive
sentence: well worth revisiting as many times


negative
sentence:'re just a couple of cops in copmovieland, these two


positive
sentence: is impressively true for being so hot-blooded


positive
sentence: like the rugrats movies, the wild thornberrys movie doesn't offer much more than the series, but its emphasis on caring for animals and respecting other cultures is particularly welcome


negative
Output:

sentence: it's a charming and often affecting journey.
01/15/2024 22:23:45 - INFO - __main__ - torch.Size([1744, 1024])
01/15/2024 22:26:21 - INFO - __main__ - None task (seed=13): Macro-F1: 34.3, Accuracy: 51.1
01/15/2024 22:26:21 - INFO - __main__ - [Train] glue-sst2	67349
01/15/2024 22:26:21 - INFO - __main__ - [Dev] glue-sst2	872
01/15/2024 22:26:21 - INFO - __main__ - channel on None (1 train, 1 dev)
01/15/2024 22:26:21 - INFO - __main__ - start running soft prefix model
01/15/2024 22:26:21 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:26:26 - INFO - __main__ - Checking the first example...
Input:
negative
sentence: in his role of observer of the scene, lawrence sounds whiny and defensive, as if his life-altering experiences made him bitter and less mature.
Output:
<glue-cola-0><glue-cola-1><glue-cola-2><glue-cola-3><glue-cola-4><glue-cola-5><glue-cola-6><glue-cola-7><glue-cola-8><glue-cola-9>
01/15/2024 22:26:26 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 22:27:20 - INFO - __main__ - time use for computing 100 examples: 58.434680461883545
01/15/2024 22:27:20 - INFO - __main__ - start running soft prefix model
01/15/2024 22:27:20 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:27:24 - INFO - __main__ - Checking the first example...
Input:
negative
sentence: in his role of observer of the scene, lawrence sounds whiny and defensive, as if his life-altering experiences made him bitter and less mature.
Output:
<glue-mnli-0><glue-mnli-1><glue-mnli-2><glue-mnli-3><glue-mnli-4><glue-mnli-5><glue-mnli-6><glue-mnli-7><glue-mnli-8><glue-mnli-9>
01/15/2024 22:27:24 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 22:28:18 - INFO - __main__ - time use for computing 100 examples: 58.56483483314514
01/15/2024 22:28:18 - INFO - __main__ - start running soft prefix model
01/15/2024 22:28:18 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:28:23 - INFO - __main__ - Checking the first example...
Input:
negative
sentence: in his role of observer of the scene, lawrence sounds whiny and defensive, as if his life-altering experiences made him bitter and less mature.
Output:
<glue-qqp-0><glue-qqp-1><glue-qqp-2><glue-qqp-3><glue-qqp-4><glue-qqp-5><glue-qqp-6><glue-qqp-7><glue-qqp-8><glue-qqp-9>
01/15/2024 22:28:23 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 22:29:17 - INFO - __main__ - time use for computing 100 examples: 58.2462739944458
01/15/2024 22:29:17 - INFO - __main__ - start running soft prefix model
01/15/2024 22:29:17 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:29:21 - INFO - __main__ - Checking the first example...
Input:
negative
sentence: in his role of observer of the scene, lawrence sounds whiny and defensive, as if his life-altering experiences made him bitter and less mature.
Output:
<glue-mrpc-0><glue-mrpc-1><glue-mrpc-2><glue-mrpc-3><glue-mrpc-4><glue-mrpc-5><glue-mrpc-6><glue-mrpc-7><glue-mrpc-8><glue-mrpc-9>
01/15/2024 22:29:21 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 22:30:15 - INFO - __main__ - time use for computing 100 examples: 58.033530712127686
01/15/2024 22:30:15 - INFO - __main__ - start running soft prefix model
01/15/2024 22:30:15 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:30:29 - INFO - __main__ - Checking the first example...
Input:
negative
sentence: in his role of observer of the scene, lawrence sounds whiny and defensive, as if his life-altering experiences made him bitter and less mature.
Output:
<glue-qnli-0><glue-qnli-1><glue-qnli-2><glue-qnli-3><glue-qnli-4><glue-qnli-5><glue-qnli-6><glue-qnli-7><glue-qnli-8><glue-qnli-9>
01/15/2024 22:30:29 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 22:31:23 - INFO - __main__ - time use for computing 100 examples: 68.47039413452148
01/15/2024 22:31:23 - INFO - __main__ - start running soft prefix model
01/15/2024 22:31:23 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:31:34 - INFO - __main__ - Checking the first example...
Input:
negative
sentence: in his role of observer of the scene, lawrence sounds whiny and defensive, as if his life-altering experiences made him bitter and less mature.
Output:
<glue-rte-0><glue-rte-1><glue-rte-2><glue-rte-3><glue-rte-4><glue-rte-5><glue-rte-6><glue-rte-7><glue-rte-8><glue-rte-9>
01/15/2024 22:31:34 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 22:32:28 - INFO - __main__ - time use for computing 100 examples: 64.80334830284119
01/15/2024 22:32:28 - INFO - __main__ - start running soft prefix model
01/15/2024 22:32:28 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:32:40 - INFO - __main__ - Checking the first example...
Input:
negative
sentence: in his role of observer of the scene, lawrence sounds whiny and defensive, as if his life-altering experiences made him bitter and less mature.
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 22:32:40 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 22:33:34 - INFO - __main__ - time use for computing 100 examples: 65.84840202331543
01/15/2024 22:33:34 - INFO - __main__ - start running soft prefix model
01/15/2024 22:33:34 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:33:40 - INFO - __main__ - Checking the first example...
Input:
negative
sentence: in his role of observer of the scene, lawrence sounds whiny and defensive, as if his life-altering experiences made him bitter and less mature.
Output:
<glue-wnli-0><glue-wnli-1><glue-wnli-2><glue-wnli-3><glue-wnli-4><glue-wnli-5><glue-wnli-6><glue-wnli-7><glue-wnli-8><glue-wnli-9>
01/15/2024 22:33:40 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 22:34:34 - INFO - __main__ - time use for computing 100 examples: 60.55354881286621
01/15/2024 22:34:34 - INFO - __main__ - min difficulty: -inf
01/15/2024 22:34:34 - INFO - __main__ - max difficulty: -inf
01/15/2024 22:34:34 - INFO - __main__ - average difficulty: -inf
01/15/2024 22:34:34 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:34:39 - INFO - __main__ - Checking the first example...
Input:
negative
sentence: in his role of observer of the scene, lawrence sounds whiny and defensive, as if his life-altering experiences made him bitter and less mature.


negative
sentence: disgusted


positive
sentence: self-promotion ends and


negative
sentence: while american adobo has its heart ( and its palate ) in the right place, its brain is a little scattered -- ditsy, even.
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 22:34:39 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 22:34:46 - INFO - __main__ - time use for computing 24 examples: 9.238168716430664
01/15/2024 22:34:46 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:34:51 - INFO - __main__ - Checking the first example...
Input:
negative
sentence: in his role of observer of the scene, lawrence sounds whiny and defensive, as if his life-altering experiences made him bitter and less mature.


negative
sentence: disgusted


positive
sentence: self-promotion ends and


negative
sentence: while american adobo has its heart ( and its palate ) in the right place, its brain is a little scattered -- ditsy, even.
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 22:34:51 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 22:34:58 - INFO - __main__ - time use for computing 24 examples: 9.471479177474976
01/15/2024 22:34:58 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:35:02 - INFO - __main__ - Checking the first example...
Input:
negative
sentence: in his role of observer of the scene, lawrence sounds whiny and defensive, as if his life-altering experiences made him bitter and less mature.


negative
sentence: disgusted


positive
sentence: self-promotion ends and


negative
sentence: while american adobo has its heart ( and its palate ) in the right place, its brain is a little scattered -- ditsy, even.
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 22:35:02 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 22:35:09 - INFO - __main__ - time use for computing 24 examples: 9.04062032699585
01/15/2024 22:35:09 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:35:14 - INFO - __main__ - Checking the first example...
Input:
negative
sentence: in his role of observer of the scene, lawrence sounds whiny and defensive, as if his life-altering experiences made him bitter and less mature.


negative
sentence: disgusted


positive
sentence: self-promotion ends and


negative
sentence: while american adobo has its heart ( and its palate ) in the right place, its brain is a little scattered -- ditsy, even.
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 22:35:14 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 22:35:21 - INFO - __main__ - time use for computing 24 examples: 9.441778659820557
01/15/2024 22:35:21 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:35:25 - INFO - __main__ - Checking the first example...
Input:
negative
sentence: in his role of observer of the scene, lawrence sounds whiny and defensive, as if his life-altering experiences made him bitter and less mature.


negative
sentence: disgusted


positive
sentence: self-promotion ends and


negative
sentence: while american adobo has its heart ( and its palate ) in the right place, its brain is a little scattered -- ditsy, even.
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 22:35:25 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 22:35:32 - INFO - __main__ - time use for computing 24 examples: 9.200846672058105
01/15/2024 22:35:32 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:35:37 - INFO - __main__ - Checking the first example...
Input:
negative
sentence: in his role of observer of the scene, lawrence sounds whiny and defensive, as if his life-altering experiences made him bitter and less mature.


negative
sentence: disgusted


positive
sentence: self-promotion ends and


negative
sentence: while american adobo has its heart ( and its palate ) in the right place, its brain is a little scattered -- ditsy, even.
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 22:35:37 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 22:35:44 - INFO - __main__ - time use for computing 24 examples: 9.08818793296814
01/15/2024 22:35:44 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:35:49 - INFO - __main__ - Checking the first example...
Input:
negative
sentence: in his role of observer of the scene, lawrence sounds whiny and defensive, as if his life-altering experiences made him bitter and less mature.


negative
sentence: disgusted


positive
sentence: self-promotion ends and


negative
sentence: while american adobo has its heart ( and its palate ) in the right place, its brain is a little scattered -- ditsy, even.
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 22:35:49 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 22:35:56 - INFO - __main__ - time use for computing 24 examples: 9.124413013458252
01/15/2024 22:35:56 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:36:00 - INFO - __main__ - Checking the first example...
Input:
negative
sentence: in his role of observer of the scene, lawrence sounds whiny and defensive, as if his life-altering experiences made him bitter and less mature.


negative
sentence: disgusted


positive
sentence: self-promotion ends and


negative
sentence: while american adobo has its heart ( and its palate ) in the right place, its brain is a little scattered -- ditsy, even.
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 22:36:00 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 22:36:07 - INFO - __main__ - time use for computing 24 examples: 9.202347040176392
01/15/2024 22:36:08 - INFO - __main__ - Checking the first example...
Input:
negative
sentence: in his role of observer of the scene, lawrence sounds whiny and defensive, as if his life-altering experiences made him bitter and less mature.


negative
sentence: disgusted


positive
sentence: self-promotion ends and


negative
sentence: while american adobo has its heart ( and its palate ) in the right place, its brain is a little scattered -- ditsy, even.


negative
Output:

sentence: it's a charming and often affecting journey.
01/15/2024 22:36:08 - INFO - __main__ - torch.Size([1744, 1024])
01/15/2024 22:38:46 - INFO - __main__ - None task (seed=21): Macro-F1: 35.7, Accuracy: 51.7
01/15/2024 22:38:46 - INFO - __main__ - [Train] glue-sst2	67349
01/15/2024 22:38:46 - INFO - __main__ - [Dev] glue-sst2	872
01/15/2024 22:38:46 - INFO - __main__ - channel on None (1 train, 1 dev)
01/15/2024 22:38:46 - INFO - __main__ - start running soft prefix model
01/15/2024 22:38:46 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:38:50 - INFO - __main__ - Checking the first example...
Input:
negative
sentence: with outtakes in which most of the characters forget their lines and just utter ` uhhh,'which is better than most of the writing in the movie
Output:
<glue-cola-0><glue-cola-1><glue-cola-2><glue-cola-3><glue-cola-4><glue-cola-5><glue-cola-6><glue-cola-7><glue-cola-8><glue-cola-9>
01/15/2024 22:38:50 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 22:39:46 - INFO - __main__ - time use for computing 100 examples: 59.649370193481445
01/15/2024 22:39:46 - INFO - __main__ - start running soft prefix model
01/15/2024 22:39:46 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:39:50 - INFO - __main__ - Checking the first example...
Input:
negative
sentence: with outtakes in which most of the characters forget their lines and just utter ` uhhh,'which is better than most of the writing in the movie
Output:
<glue-mnli-0><glue-mnli-1><glue-mnli-2><glue-mnli-3><glue-mnli-4><glue-mnli-5><glue-mnli-6><glue-mnli-7><glue-mnli-8><glue-mnli-9>
01/15/2024 22:39:50 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 22:40:45 - INFO - __main__ - time use for computing 100 examples: 59.41845345497131
01/15/2024 22:40:45 - INFO - __main__ - start running soft prefix model
01/15/2024 22:40:45 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:40:49 - INFO - __main__ - Checking the first example...
Input:
negative
sentence: with outtakes in which most of the characters forget their lines and just utter ` uhhh,'which is better than most of the writing in the movie
Output:
<glue-qqp-0><glue-qqp-1><glue-qqp-2><glue-qqp-3><glue-qqp-4><glue-qqp-5><glue-qqp-6><glue-qqp-7><glue-qqp-8><glue-qqp-9>
01/15/2024 22:40:49 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 22:41:44 - INFO - __main__ - time use for computing 100 examples: 59.46807646751404
01/15/2024 22:41:44 - INFO - __main__ - start running soft prefix model
01/15/2024 22:41:44 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:41:49 - INFO - __main__ - Checking the first example...
Input:
negative
sentence: with outtakes in which most of the characters forget their lines and just utter ` uhhh,'which is better than most of the writing in the movie
Output:
<glue-mrpc-0><glue-mrpc-1><glue-mrpc-2><glue-mrpc-3><glue-mrpc-4><glue-mrpc-5><glue-mrpc-6><glue-mrpc-7><glue-mrpc-8><glue-mrpc-9>
01/15/2024 22:41:49 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 22:42:43 - INFO - __main__ - time use for computing 100 examples: 58.82624840736389
01/15/2024 22:42:43 - INFO - __main__ - start running soft prefix model
01/15/2024 22:42:43 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:42:48 - INFO - __main__ - Checking the first example...
Input:
negative
sentence: with outtakes in which most of the characters forget their lines and just utter ` uhhh,'which is better than most of the writing in the movie
Output:
<glue-qnli-0><glue-qnli-1><glue-qnli-2><glue-qnli-3><glue-qnli-4><glue-qnli-5><glue-qnli-6><glue-qnli-7><glue-qnli-8><glue-qnli-9>
01/15/2024 22:42:48 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 22:43:42 - INFO - __main__ - time use for computing 100 examples: 58.91755747795105
01/15/2024 22:43:42 - INFO - __main__ - start running soft prefix model
01/15/2024 22:43:42 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:43:47 - INFO - __main__ - Checking the first example...
Input:
negative
sentence: with outtakes in which most of the characters forget their lines and just utter ` uhhh,'which is better than most of the writing in the movie
Output:
<glue-rte-0><glue-rte-1><glue-rte-2><glue-rte-3><glue-rte-4><glue-rte-5><glue-rte-6><glue-rte-7><glue-rte-8><glue-rte-9>
01/15/2024 22:43:47 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 22:44:41 - INFO - __main__ - time use for computing 100 examples: 59.00663161277771
01/15/2024 22:44:41 - INFO - __main__ - start running soft prefix model
01/15/2024 22:44:41 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:44:46 - INFO - __main__ - Checking the first example...
Input:
negative
sentence: with outtakes in which most of the characters forget their lines and just utter ` uhhh,'which is better than most of the writing in the movie
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 22:44:46 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 22:45:40 - INFO - __main__ - time use for computing 100 examples: 58.90227651596069
01/15/2024 22:45:40 - INFO - __main__ - start running soft prefix model
01/15/2024 22:45:40 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:45:44 - INFO - __main__ - Checking the first example...
Input:
negative
sentence: with outtakes in which most of the characters forget their lines and just utter ` uhhh,'which is better than most of the writing in the movie
Output:
<glue-wnli-0><glue-wnli-1><glue-wnli-2><glue-wnli-3><glue-wnli-4><glue-wnli-5><glue-wnli-6><glue-wnli-7><glue-wnli-8><glue-wnli-9>
01/15/2024 22:45:44 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 22:46:39 - INFO - __main__ - time use for computing 100 examples: 58.894378423690796
01/15/2024 22:46:39 - INFO - __main__ - min difficulty: -inf
01/15/2024 22:46:39 - INFO - __main__ - max difficulty: -inf
01/15/2024 22:46:39 - INFO - __main__ - average difficulty: -inf
01/15/2024 22:46:39 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:46:44 - INFO - __main__ - Checking the first example...
Input:
negative
sentence: with outtakes in which most of the characters forget their lines and just utter ` uhhh,'which is better than most of the writing in the movie


negative
sentence: gets very ugly, very fast


negative
sentence: called best bad film you thought was going to be really awful but


positive
sentence: delicate treatment
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 22:46:44 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 22:46:50 - INFO - __main__ - time use for computing 24 examples: 9.332008361816406
01/15/2024 22:46:50 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:46:55 - INFO - __main__ - Checking the first example...
Input:
negative
sentence: with outtakes in which most of the characters forget their lines and just utter ` uhhh,'which is better than most of the writing in the movie


negative
sentence: gets very ugly, very fast


negative
sentence: called best bad film you thought was going to be really awful but


positive
sentence: delicate treatment
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 22:46:55 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 22:47:02 - INFO - __main__ - time use for computing 24 examples: 9.246999025344849
01/15/2024 22:47:02 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:47:06 - INFO - __main__ - Checking the first example...
Input:
negative
sentence: with outtakes in which most of the characters forget their lines and just utter ` uhhh,'which is better than most of the writing in the movie


negative
sentence: gets very ugly, very fast


negative
sentence: called best bad film you thought was going to be really awful but


positive
sentence: delicate treatment
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 22:47:06 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 22:47:13 - INFO - __main__ - time use for computing 24 examples: 9.289219617843628
01/15/2024 22:47:13 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:47:17 - INFO - __main__ - Checking the first example...
Input:
negative
sentence: with outtakes in which most of the characters forget their lines and just utter ` uhhh,'which is better than most of the writing in the movie


negative
sentence: gets very ugly, very fast


negative
sentence: called best bad film you thought was going to be really awful but


positive
sentence: delicate treatment
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 22:47:17 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 22:47:24 - INFO - __main__ - time use for computing 24 examples: 9.130174398422241
01/15/2024 22:47:24 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:47:28 - INFO - __main__ - Checking the first example...
Input:
negative
sentence: with outtakes in which most of the characters forget their lines and just utter ` uhhh,'which is better than most of the writing in the movie


negative
sentence: gets very ugly, very fast


negative
sentence: called best bad film you thought was going to be really awful but


positive
sentence: delicate treatment
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 22:47:28 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 22:47:35 - INFO - __main__ - time use for computing 24 examples: 9.223865032196045
01/15/2024 22:47:35 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:47:40 - INFO - __main__ - Checking the first example...
Input:
negative
sentence: with outtakes in which most of the characters forget their lines and just utter ` uhhh,'which is better than most of the writing in the movie


negative
sentence: gets very ugly, very fast


negative
sentence: called best bad film you thought was going to be really awful but


positive
sentence: delicate treatment
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 22:47:40 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 22:47:47 - INFO - __main__ - time use for computing 24 examples: 9.848042249679565
01/15/2024 22:47:47 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:47:52 - INFO - __main__ - Checking the first example...
Input:
negative
sentence: with outtakes in which most of the characters forget their lines and just utter ` uhhh,'which is better than most of the writing in the movie


negative
sentence: gets very ugly, very fast


negative
sentence: called best bad film you thought was going to be really awful but


positive
sentence: delicate treatment
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 22:47:52 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 22:47:58 - INFO - __main__ - time use for computing 24 examples: 9.225079536437988
01/15/2024 22:47:58 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:48:03 - INFO - __main__ - Checking the first example...
Input:
negative
sentence: with outtakes in which most of the characters forget their lines and just utter ` uhhh,'which is better than most of the writing in the movie


negative
sentence: gets very ugly, very fast


negative
sentence: called best bad film you thought was going to be really awful but


positive
sentence: delicate treatment
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 22:48:03 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 22:48:09 - INFO - __main__ - time use for computing 24 examples: 9.269846677780151
01/15/2024 22:48:10 - INFO - __main__ - Checking the first example...
Input:
negative
sentence: with outtakes in which most of the characters forget their lines and just utter ` uhhh,'which is better than most of the writing in the movie


negative
sentence: gets very ugly, very fast


negative
sentence: called best bad film you thought was going to be really awful but


positive
sentence: delicate treatment


negative
Output:

sentence: it's a charming and often affecting journey.
01/15/2024 22:48:10 - INFO - __main__ - torch.Size([1744, 1024])
01/15/2024 22:50:47 - INFO - __main__ - None task (seed=42): Macro-F1: 45.0, Accuracy: 54.9
01/15/2024 22:50:47 - INFO - __main__ - [Train] glue-sst2	67349
01/15/2024 22:50:47 - INFO - __main__ - [Dev] glue-sst2	872
01/15/2024 22:50:47 - INFO - __main__ - channel on None (1 train, 1 dev)
01/15/2024 22:50:47 - INFO - __main__ - start running soft prefix model
01/15/2024 22:50:47 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:50:52 - INFO - __main__ - Checking the first example...
Input:
negative
sentence: titular
Output:
<glue-cola-0><glue-cola-1><glue-cola-2><glue-cola-3><glue-cola-4><glue-cola-5><glue-cola-6><glue-cola-7><glue-cola-8><glue-cola-9>
01/15/2024 22:50:52 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 22:51:46 - INFO - __main__ - time use for computing 100 examples: 59.258607387542725
01/15/2024 22:51:46 - INFO - __main__ - start running soft prefix model
01/15/2024 22:51:46 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:51:51 - INFO - __main__ - Checking the first example...
Input:
negative
sentence: titular
Output:
<glue-mnli-0><glue-mnli-1><glue-mnli-2><glue-mnli-3><glue-mnli-4><glue-mnli-5><glue-mnli-6><glue-mnli-7><glue-mnli-8><glue-mnli-9>
01/15/2024 22:51:51 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 22:52:45 - INFO - __main__ - time use for computing 100 examples: 58.977463245391846
01/15/2024 22:52:45 - INFO - __main__ - start running soft prefix model
01/15/2024 22:52:45 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:52:50 - INFO - __main__ - Checking the first example...
Input:
negative
sentence: titular
Output:
<glue-qqp-0><glue-qqp-1><glue-qqp-2><glue-qqp-3><glue-qqp-4><glue-qqp-5><glue-qqp-6><glue-qqp-7><glue-qqp-8><glue-qqp-9>
01/15/2024 22:52:50 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 22:53:44 - INFO - __main__ - time use for computing 100 examples: 58.86880016326904
01/15/2024 22:53:44 - INFO - __main__ - start running soft prefix model
01/15/2024 22:53:44 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:53:49 - INFO - __main__ - Checking the first example...
Input:
negative
sentence: titular
Output:
<glue-mrpc-0><glue-mrpc-1><glue-mrpc-2><glue-mrpc-3><glue-mrpc-4><glue-mrpc-5><glue-mrpc-6><glue-mrpc-7><glue-mrpc-8><glue-mrpc-9>
01/15/2024 22:53:49 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 22:54:44 - INFO - __main__ - time use for computing 100 examples: 59.44236660003662
01/15/2024 22:54:44 - INFO - __main__ - start running soft prefix model
01/15/2024 22:54:44 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:54:48 - INFO - __main__ - Checking the first example...
Input:
negative
sentence: titular
Output:
<glue-qnli-0><glue-qnli-1><glue-qnli-2><glue-qnli-3><glue-qnli-4><glue-qnli-5><glue-qnli-6><glue-qnli-7><glue-qnli-8><glue-qnli-9>
01/15/2024 22:54:48 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 22:55:43 - INFO - __main__ - time use for computing 100 examples: 59.22432351112366
01/15/2024 22:55:43 - INFO - __main__ - start running soft prefix model
01/15/2024 22:55:43 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:55:47 - INFO - __main__ - Checking the first example...
Input:
negative
sentence: titular
Output:
<glue-rte-0><glue-rte-1><glue-rte-2><glue-rte-3><glue-rte-4><glue-rte-5><glue-rte-6><glue-rte-7><glue-rte-8><glue-rte-9>
01/15/2024 22:55:47 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 22:56:42 - INFO - __main__ - time use for computing 100 examples: 59.16430044174194
01/15/2024 22:56:42 - INFO - __main__ - start running soft prefix model
01/15/2024 22:56:42 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:56:46 - INFO - __main__ - Checking the first example...
Input:
negative
sentence: titular
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 22:56:46 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 22:57:41 - INFO - __main__ - time use for computing 100 examples: 58.91028618812561
01/15/2024 22:57:41 - INFO - __main__ - start running soft prefix model
01/15/2024 22:57:41 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:57:45 - INFO - __main__ - Checking the first example...
Input:
negative
sentence: titular
Output:
<glue-wnli-0><glue-wnli-1><glue-wnli-2><glue-wnli-3><glue-wnli-4><glue-wnli-5><glue-wnli-6><glue-wnli-7><glue-wnli-8><glue-wnli-9>
01/15/2024 22:57:45 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 22:58:40 - INFO - __main__ - time use for computing 100 examples: 58.625452280044556
01/15/2024 22:58:40 - INFO - __main__ - min difficulty: -inf
01/15/2024 22:58:40 - INFO - __main__ - max difficulty: -inf
01/15/2024 22:58:40 - INFO - __main__ - average difficulty: -inf
01/15/2024 22:58:40 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:58:44 - INFO - __main__ - Checking the first example...
Input:
positive
sentence: titular


positive
sentence: various amusing sidekicks


negative
sentence: loses its sense of humor


negative
sentence: maintaining consciousness just long enough to achieve callow pretension
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 22:58:44 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 22:58:50 - INFO - __main__ - time use for computing 24 examples: 9.059051036834717
01/15/2024 22:58:50 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:58:55 - INFO - __main__ - Checking the first example...
Input:
positive
sentence: titular


positive
sentence: various amusing sidekicks


negative
sentence: loses its sense of humor


negative
sentence: maintaining consciousness just long enough to achieve callow pretension
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 22:58:55 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 22:59:02 - INFO - __main__ - time use for computing 24 examples: 9.292404413223267
01/15/2024 22:59:02 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:59:06 - INFO - __main__ - Checking the first example...
Input:
positive
sentence: titular


positive
sentence: various amusing sidekicks


negative
sentence: loses its sense of humor


negative
sentence: maintaining consciousness just long enough to achieve callow pretension
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 22:59:06 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 22:59:13 - INFO - __main__ - time use for computing 24 examples: 9.163686513900757
01/15/2024 22:59:13 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:59:17 - INFO - __main__ - Checking the first example...
Input:
positive
sentence: titular


positive
sentence: various amusing sidekicks


negative
sentence: loses its sense of humor


negative
sentence: maintaining consciousness just long enough to achieve callow pretension
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 22:59:17 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 22:59:24 - INFO - __main__ - time use for computing 24 examples: 9.009237289428711
01/15/2024 22:59:24 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:59:28 - INFO - __main__ - Checking the first example...
Input:
positive
sentence: titular


positive
sentence: various amusing sidekicks


negative
sentence: loses its sense of humor


negative
sentence: maintaining consciousness just long enough to achieve callow pretension
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 22:59:28 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 22:59:35 - INFO - __main__ - time use for computing 24 examples: 9.26559829711914
01/15/2024 22:59:35 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:59:39 - INFO - __main__ - Checking the first example...
Input:
positive
sentence: titular


positive
sentence: various amusing sidekicks


negative
sentence: loses its sense of humor


negative
sentence: maintaining consciousness just long enough to achieve callow pretension
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 22:59:39 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 22:59:46 - INFO - __main__ - time use for computing 24 examples: 9.108421564102173
01/15/2024 22:59:46 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 22:59:51 - INFO - __main__ - Checking the first example...
Input:
positive
sentence: titular


positive
sentence: various amusing sidekicks


negative
sentence: loses its sense of humor


negative
sentence: maintaining consciousness just long enough to achieve callow pretension
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 22:59:51 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 22:59:57 - INFO - __main__ - time use for computing 24 examples: 9.214707374572754
01/15/2024 22:59:57 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 23:00:02 - INFO - __main__ - Checking the first example...
Input:
positive
sentence: titular


positive
sentence: various amusing sidekicks


negative
sentence: loses its sense of humor


negative
sentence: maintaining consciousness just long enough to achieve callow pretension
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 23:00:02 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 23:00:09 - INFO - __main__ - time use for computing 24 examples: 9.26151704788208
01/15/2024 23:00:09 - INFO - __main__ - Checking the first example...
Input:
positive
sentence: titular


positive
sentence: various amusing sidekicks


negative
sentence: loses its sense of humor


negative
sentence: maintaining consciousness just long enough to achieve callow pretension


negative
Output:

sentence: it's a charming and often affecting journey.
01/15/2024 23:00:09 - INFO - __main__ - torch.Size([1744, 1024])
01/15/2024 23:02:46 - INFO - __main__ - None task (seed=87): Macro-F1: 33.7, Accuracy: 50.9
01/15/2024 23:02:46 - INFO - __main__ - None over 1 target tasks with majority vote: Macro-F1: 36.0, Accuracy: 51.8
01/15/2024 23:02:46 - INFO - __main__ - None over 1 target tasks on average: Macro-F1: 36.6 +- 4.2, Accuracy: 51.7 +- 1.7
