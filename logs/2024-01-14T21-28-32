01/14/2024 21:28:32 - INFO - __main__ - Namespace(do_tensorize=False, tensorize_dir='tensorized', n_gpu=1, n_process=40, n_prefix_tokens=10, use_demonstrations=False, log_dir='logs', prefix_embed_file=None, dataset=None, task='glue', split='glue', data_dir='data/', k=16384, test_k=4, seed=100, train_seed=1, lr=0.01, warmup_steps=0, batch_size=8, num_training_steps=3000, weight_decay=0.0, no_masking=False, use_random_english_words=False, out_dir='checkpoints\\gpt2\\glue-glue\\prefix={10}-{direct}-lr={1e-2}-initByVocab', method='direct', gpt2='gpt2', optimization='adamw', fp16=False, local_rank=-1)
01/14/2024 21:28:32 - INFO - __main__ - batch_size=8	max_length=256	max_length_per_example=256
01/14/2024 21:28:32 - INFO - __main__ - [Train] glue-cola	8551
01/14/2024 21:28:32 - INFO - __main__ - [Train] glue-mnli	16384
01/14/2024 21:28:32 - INFO - __main__ - [Train] glue-qqp	16384
01/14/2024 21:28:32 - INFO - __main__ - [Train] glue-mrpc	3668
01/14/2024 21:28:32 - INFO - __main__ - [Train] glue-qnli	16384
01/14/2024 21:28:32 - INFO - __main__ - [Train] glue-rte	2490
01/14/2024 21:28:32 - INFO - __main__ - [Train] glue-sst2	16384
01/14/2024 21:28:32 - INFO - __main__ - [Train] glue-wnli	635
01/14/2024 21:28:32 - INFO - __main__ - direct on None (8 train)
01/14/2024 21:28:32 - INFO - __main__ - tensorized\glue_direct_k=80880_seed=100_length=10-256-rank=%d.pkl
01/14/2024 21:28:35 - INFO - __main__ - Checking the first example...
Input:
<glue-qqp-0><glue-qqp-1><glue-qqp-2><glue-qqp-3><glue-qqp-4><glue-qqp-5><glue-qqp-6><glue-qqp-7><glue-qqp-8><glue-qqp-9>question 1: What are the reasons behind the poor performance of India in Olympics? [SEP] question 2: Why India's performance is still poor in olympics?
Output:
 duplicate
01/14/2024 21:28:35 - INFO - __main__ - checkpoints\gpt2\glue-glue\prefix={10}-{direct}-lr={1e-2}-initByVocab
01/14/2024 21:28:35 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/14/2024 21:28:38 - INFO - __main__ - torch.Size([80880, 256])
01/14/2024 21:28:38 - INFO - __main__ - Training 1 parameters on 80880 examples for 3000 steps using 1 GPUs
01/14/2024 21:29:21 - INFO - __main__ - local rank -1	global step 100	train loss 5.19
01/14/2024 21:30:04 - INFO - __main__ - local rank -1	global step 200	train loss 4.22
01/14/2024 21:30:46 - INFO - __main__ - local rank -1	global step 300	train loss 3.98
01/14/2024 21:31:29 - INFO - __main__ - local rank -1	global step 400	train loss 3.95
01/14/2024 21:32:12 - INFO - __main__ - local rank -1	global step 500	train loss 4.19
01/14/2024 21:32:54 - INFO - __main__ - local rank -1	global step 600	train loss 3.83
01/14/2024 21:33:37 - INFO - __main__ - local rank -1	global step 700	train loss 3.34
01/14/2024 21:34:20 - INFO - __main__ - local rank -1	global step 800	train loss 3.53
01/14/2024 21:35:02 - INFO - __main__ - local rank -1	global step 900	train loss 3.76
01/14/2024 21:35:45 - INFO - __main__ - local rank -1	global step 1000	train loss 2.76
01/14/2024 21:36:28 - INFO - __main__ - local rank -1	global step 1100	train loss 3.08
01/14/2024 21:37:11 - INFO - __main__ - local rank -1	global step 1200	train loss 3.11
01/14/2024 21:37:53 - INFO - __main__ - local rank -1	global step 1300	train loss 3.23
01/14/2024 21:38:36 - INFO - __main__ - local rank -1	global step 1400	train loss 3.24
01/14/2024 21:39:19 - INFO - __main__ - local rank -1	global step 1500	train loss 2.31
01/14/2024 21:40:01 - INFO - __main__ - local rank -1	global step 1600	train loss 2.33
01/14/2024 21:40:44 - INFO - __main__ - local rank -1	global step 1700	train loss 2.44
01/14/2024 21:41:26 - INFO - __main__ - local rank -1	global step 1800	train loss 2.17
01/14/2024 21:42:09 - INFO - __main__ - local rank -1	global step 1900	train loss 2.22
01/14/2024 21:42:52 - INFO - __main__ - local rank -1	global step 2000	train loss 2.25
01/14/2024 21:43:35 - INFO - __main__ - local rank -1	global step 2100	train loss 2.11
01/14/2024 21:44:18 - INFO - __main__ - local rank -1	global step 2200	train loss 2.06
01/14/2024 21:45:00 - INFO - __main__ - local rank -1	global step 2300	train loss 1.72
01/14/2024 21:45:43 - INFO - __main__ - local rank -1	global step 2400	train loss 1.97
01/14/2024 21:46:26 - INFO - __main__ - local rank -1	global step 2500	train loss 1.73
01/14/2024 21:47:09 - INFO - __main__ - local rank -1	global step 2600	train loss 1.47
01/14/2024 21:47:51 - INFO - __main__ - local rank -1	global step 2700	train loss 1.51
01/14/2024 21:48:34 - INFO - __main__ - local rank -1	global step 2800	train loss 1.45
01/14/2024 21:49:17 - INFO - __main__ - local rank -1	global step 2900	train loss 1.22
01/14/2024 21:50:00 - INFO - __main__ - local rank -1	global step 3000	train loss 1.26
01/14/2024 21:50:00 - INFO - __main__ - Finish training
