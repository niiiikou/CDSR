01/13/2024 12:11:41 - INFO - __main__ - Namespace(do_tensorize=False, tensorize_dir='tensorized', n_gpu=1, n_process=40, n_prefix_tokens=10, use_demonstrations=False, log_dir='logs', prefix_embed_file=None, dataset=None, task='glue', split='glue', data_dir='data/', k=16384, test_k=4, seed=100, train_seed=1, lr=0.01, warmup_steps=0, batch_size=8, num_training_steps=3000, weight_decay=0.0, no_masking=False, use_random_english_words=False, out_dir='checkpoints\\gpt2\\glue-glue\\prefix={10}-{direct}-lr={1e-2}-initByVocab', method='direct', gpt2='gpt2', optimization='adamw', fp16=False, local_rank=-1)
01/13/2024 12:11:41 - INFO - __main__ - batch_size=8	max_length=256	max_length_per_example=256
01/13/2024 12:11:41 - INFO - __main__ - [Train] glue-cola	8551
01/13/2024 12:11:41 - INFO - __main__ - [Train] glue-mnli	16384
01/13/2024 12:11:41 - INFO - __main__ - [Train] glue-qqp	16384
01/13/2024 12:11:41 - INFO - __main__ - [Train] glue-mrpc	3668
01/13/2024 12:11:41 - INFO - __main__ - [Train] glue-qnli	16384
01/13/2024 12:11:41 - INFO - __main__ - [Train] glue-rte	2490
01/13/2024 12:11:41 - INFO - __main__ - [Train] glue-sst2	16384
01/13/2024 12:11:41 - INFO - __main__ - [Train] glue-wnli	635
01/13/2024 12:11:41 - INFO - __main__ - direct on None (8 train)
01/13/2024 12:11:44 - INFO - __main__ - tensorized\glue_direct_k=80880_seed=100_length=10-256-rank=%d.pkl
01/13/2024 12:11:46 - INFO - __main__ - Checking the first example...
Input:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>sentence: parents beware ; this is downright movie penance.
Output:
 negative
01/13/2024 12:11:46 - INFO - __main__ - checkpoints\gpt2\glue-glue\prefix={10}-{direct}-lr={1e-2}-initByVocab
01/13/2024 12:11:46 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
