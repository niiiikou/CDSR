02/05/2024 02:13:24 - INFO - __main__ - Namespace(do_tensorize=False, tensorize_dir='tensorized', n_gpu=1, n_process=40, n_prefix_tokens=10, use_demonstrations=False, log_dir='logs', prefix_embed_file=None, dataset=None, task='tune', split='train', data_dir='data/', k=16384, test_k=4, seed=100, train_seed=1, lr=0.001, warmup_steps=0, batch_size=8, num_training_steps=5000, weight_decay=0.0, no_masking=False, use_random_english_words=False, out_dir='checkpoints\\gpt2\\tune-train\\prefix={10}-{channel}-lr={1e-3}-initByVocab', method='channel', gpt2='gpt2', optimization='adamw', fp16=False, local_rank=-1)
02/05/2024 02:13:24 - INFO - __main__ - batch_size=8	max_length=256	max_length_per_example=256
02/05/2024 02:13:24 - INFO - __main__ - [Train] glue-sst2	16384
02/05/2024 02:13:24 - INFO - __main__ - [Train] amazon_polarity	10000
02/05/2024 02:13:24 - INFO - __main__ - [Train] financial_phrasebank	1811
02/05/2024 02:13:24 - INFO - __main__ - [Train] poem_sentiment	843
02/05/2024 02:13:24 - INFO - __main__ - [Train] yelp_polarity	16384
02/05/2024 02:13:24 - INFO - __main__ - [Train] glue-cola	8551
02/05/2024 02:13:24 - INFO - __main__ - [Train] blimp-sentential_negation_npi_scope	800
02/05/2024 02:13:24 - INFO - __main__ - [Train] blimp-sentential_negation_npi_licensor_present	800
02/05/2024 02:13:24 - INFO - __main__ - [Train] blimp-ellipsis_n_bar_2	800
02/05/2024 02:13:24 - INFO - __main__ - [Train] blimp-anaphor_number_agreement	800
02/05/2024 02:13:24 - INFO - __main__ - [Train] ag_news	16384
02/05/2024 02:13:24 - INFO - __main__ - [Train] dbpedia_14	16384
02/05/2024 02:13:24 - INFO - __main__ - [Train] ethos-sexual_orientation	346
02/05/2024 02:13:24 - INFO - __main__ - [Train] ethos-religion	346
02/05/2024 02:13:24 - INFO - __main__ - [Train] ethos-race	346
02/05/2024 02:13:24 - INFO - __main__ - [Train] ethos-gender	346
02/05/2024 02:13:24 - INFO - __main__ - [Train] ethos-disability	346
02/05/2024 02:13:24 - INFO - __main__ - [Train] ethos-directed_vs_generalized	346
02/05/2024 02:13:24 - INFO - __main__ - [Train] emo	16384
02/05/2024 02:13:24 - INFO - __main__ - [Train] emotion	16000
02/05/2024 02:13:24 - INFO - __main__ - channel on None (20 train)
02/05/2024 02:13:28 - INFO - __main__ - tensorized\tune_channel_k=124401_seed=100_length=10-256-rank=%d.pkl
02/05/2024 02:13:30 - INFO - __main__ - Checking the first example...
Input:
<ag_news-0><ag_news-1><ag_news-2><ag_news-3><ag_news-4><ag_news-5><ag_news-6><ag_news-7><ag_news-8><ag_news-9>Sports
Output:
 Nuggets hang on to Nene DENVER The Denver Nuggets have picked up their three million dollar option for next NBA season for forward Nene (nuh-NAY #39;) but not for Nikoloz Tskitishvili (NIH-koh-lohs skee-tish-VEE #39;-lee).
02/05/2024 02:13:30 - INFO - __main__ - checkpoints\gpt2\tune-train\prefix={10}-{channel}-lr={1e-3}-initByVocab
02/05/2024 02:13:30 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/05/2024 02:13:36 - INFO - __main__ - torch.Size([124401, 256])
02/05/2024 02:13:36 - INFO - __main__ - Training 1 parameters on 124401 examples for 5000 steps using 1 GPUs
02/05/2024 02:14:20 - INFO - __main__ - local rank -1	global step 100	train loss 8.79
02/05/2024 02:15:03 - INFO - __main__ - local rank -1	global step 200	train loss 8.56
02/05/2024 02:15:46 - INFO - __main__ - local rank -1	global step 300	train loss 8.44
02/05/2024 02:16:29 - INFO - __main__ - local rank -1	global step 400	train loss 8.38
02/05/2024 02:17:12 - INFO - __main__ - local rank -1	global step 500	train loss 8.23
02/05/2024 02:17:55 - INFO - __main__ - local rank -1	global step 600	train loss 8.15
02/05/2024 02:18:38 - INFO - __main__ - local rank -1	global step 700	train loss 8.05
02/05/2024 02:19:21 - INFO - __main__ - local rank -1	global step 800	train loss 7.97
02/05/2024 02:20:04 - INFO - __main__ - local rank -1	global step 900	train loss 7.91
02/05/2024 02:20:47 - INFO - __main__ - local rank -1	global step 1000	train loss 7.83
02/05/2024 02:21:30 - INFO - __main__ - local rank -1	global step 1100	train loss 7.82
02/05/2024 02:22:13 - INFO - __main__ - local rank -1	global step 1200	train loss 7.72
02/05/2024 02:22:56 - INFO - __main__ - local rank -1	global step 1300	train loss 7.78
02/05/2024 02:23:39 - INFO - __main__ - local rank -1	global step 1400	train loss 7.74
02/05/2024 02:24:22 - INFO - __main__ - local rank -1	global step 1500	train loss 7.75
02/05/2024 02:25:05 - INFO - __main__ - local rank -1	global step 1600	train loss 7.61
02/05/2024 02:25:48 - INFO - __main__ - local rank -1	global step 1700	train loss 7.56
02/05/2024 02:26:31 - INFO - __main__ - local rank -1	global step 1800	train loss 7.56
02/05/2024 02:27:14 - INFO - __main__ - local rank -1	global step 1900	train loss 7.49
02/05/2024 02:27:57 - INFO - __main__ - local rank -1	global step 2000	train loss 7.47
02/05/2024 02:28:40 - INFO - __main__ - local rank -1	global step 2100	train loss 7.38
02/05/2024 02:29:23 - INFO - __main__ - local rank -1	global step 2200	train loss 7.44
02/05/2024 02:30:07 - INFO - __main__ - local rank -1	global step 2300	train loss 7.35
02/05/2024 02:30:50 - INFO - __main__ - local rank -1	global step 2400	train loss 7.34
02/05/2024 02:31:33 - INFO - __main__ - local rank -1	global step 2500	train loss 7.32
02/05/2024 02:32:16 - INFO - __main__ - local rank -1	global step 2600	train loss 7.34
02/05/2024 02:32:59 - INFO - __main__ - local rank -1	global step 2700	train loss 7.27
02/05/2024 02:33:42 - INFO - __main__ - local rank -1	global step 2800	train loss 7.33
02/05/2024 02:34:25 - INFO - __main__ - local rank -1	global step 2900	train loss 7.18
02/05/2024 02:35:08 - INFO - __main__ - local rank -1	global step 3000	train loss 7.16
02/05/2024 02:35:52 - INFO - __main__ - local rank -1	global step 3100	train loss 7.19
02/05/2024 02:36:35 - INFO - __main__ - local rank -1	global step 3200	train loss 7.16
02/05/2024 02:37:18 - INFO - __main__ - local rank -1	global step 3300	train loss 7.14
02/05/2024 02:38:02 - INFO - __main__ - local rank -1	global step 3400	train loss 7.12
02/05/2024 02:38:45 - INFO - __main__ - local rank -1	global step 3500	train loss 7.12
02/05/2024 02:39:28 - INFO - __main__ - local rank -1	global step 3600	train loss 7.10
02/05/2024 02:40:11 - INFO - __main__ - local rank -1	global step 3700	train loss 7.04
02/05/2024 02:40:54 - INFO - __main__ - local rank -1	global step 3800	train loss 7.00
02/05/2024 02:41:37 - INFO - __main__ - local rank -1	global step 3900	train loss 6.95
02/05/2024 02:42:20 - INFO - __main__ - local rank -1	global step 4000	train loss 7.02
02/05/2024 02:43:04 - INFO - __main__ - local rank -1	global step 4100	train loss 7.06
02/05/2024 02:43:47 - INFO - __main__ - local rank -1	global step 4200	train loss 7.01
02/05/2024 02:44:30 - INFO - __main__ - local rank -1	global step 4300	train loss 6.87
02/05/2024 02:45:14 - INFO - __main__ - local rank -1	global step 4400	train loss 6.89
02/05/2024 02:45:57 - INFO - __main__ - local rank -1	global step 4500	train loss 6.92
02/05/2024 02:46:40 - INFO - __main__ - local rank -1	global step 4600	train loss 6.93
02/05/2024 02:47:23 - INFO - __main__ - local rank -1	global step 4700	train loss 6.93
02/05/2024 02:48:06 - INFO - __main__ - local rank -1	global step 4800	train loss 6.93
02/05/2024 02:48:49 - INFO - __main__ - local rank -1	global step 4900	train loss 6.91
02/05/2024 02:49:33 - INFO - __main__ - local rank -1	global step 5000	train loss 6.88
02/05/2024 02:49:33 - INFO - __main__ - Finish training
