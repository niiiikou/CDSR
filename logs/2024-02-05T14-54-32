02/05/2024 14:54:32 - INFO - __main__ - Namespace(do_tensorize=False, tensorize_dir='tensorized', n_gpu=1, n_process=40, n_prefix_tokens=10, use_demonstrations=False, log_dir='logs', prefix_embed_file=None, dataset=None, task='tune', split='train', data_dir='data/', k=16384, test_k=4, seed=100, train_seed=1, lr=1e-05, warmup_steps=0, batch_size=8, num_training_steps=5000, weight_decay=0.0, no_masking=False, use_random_english_words=False, out_dir='checkpoints\\gpt2\\tune-train\\prefix={10}-{channel}-lr={1e-5}-initByVocab', method='channel', gpt2='gpt2', optimization='adamw', fp16=False, local_rank=-1)
02/05/2024 14:54:32 - INFO - __main__ - batch_size=8	max_length=256	max_length_per_example=256
02/05/2024 14:54:33 - INFO - __main__ - [Train] glue-sst2	16384
02/05/2024 14:54:33 - INFO - __main__ - [Train] amazon_polarity	10000
02/05/2024 14:54:33 - INFO - __main__ - [Train] financial_phrasebank	1811
02/05/2024 14:54:33 - INFO - __main__ - [Train] poem_sentiment	843
02/05/2024 14:54:33 - INFO - __main__ - [Train] yelp_polarity	16384
02/05/2024 14:54:33 - INFO - __main__ - [Train] glue-cola	8551
02/05/2024 14:54:33 - INFO - __main__ - [Train] blimp-sentential_negation_npi_scope	800
02/05/2024 14:54:33 - INFO - __main__ - [Train] blimp-sentential_negation_npi_licensor_present	800
02/05/2024 14:54:33 - INFO - __main__ - [Train] blimp-ellipsis_n_bar_2	800
02/05/2024 14:54:33 - INFO - __main__ - [Train] blimp-anaphor_number_agreement	800
02/05/2024 14:54:33 - INFO - __main__ - [Train] ag_news	16384
02/05/2024 14:54:33 - INFO - __main__ - [Train] dbpedia_14	16384
02/05/2024 14:54:33 - INFO - __main__ - [Train] ethos-sexual_orientation	346
02/05/2024 14:54:33 - INFO - __main__ - [Train] ethos-religion	346
02/05/2024 14:54:33 - INFO - __main__ - [Train] ethos-race	346
02/05/2024 14:54:33 - INFO - __main__ - [Train] ethos-gender	346
02/05/2024 14:54:33 - INFO - __main__ - [Train] ethos-disability	346
02/05/2024 14:54:33 - INFO - __main__ - [Train] ethos-directed_vs_generalized	346
02/05/2024 14:54:33 - INFO - __main__ - [Train] emo	16384
02/05/2024 14:54:33 - INFO - __main__ - [Train] emotion	16000
02/05/2024 14:54:33 - INFO - __main__ - channel on None (20 train)
02/05/2024 14:54:36 - INFO - __main__ - tensorized\tune_channel_k=124401_seed=100_length=10-256-rank=%d.pkl
02/05/2024 14:54:40 - INFO - __main__ - Checking the first example...
Input:
<ag_news-0><ag_news-1><ag_news-2><ag_news-3><ag_news-4><ag_news-5><ag_news-6><ag_news-7><ag_news-8><ag_news-9>Sports
Output:
 Nuggets hang on to Nene DENVER The Denver Nuggets have picked up their three million dollar option for next NBA season for forward Nene (nuh-NAY #39;) but not for Nikoloz Tskitishvili (NIH-koh-lohs skee-tish-VEE #39;-lee).
02/05/2024 14:54:40 - INFO - __main__ - checkpoints\gpt2\tune-train\prefix={10}-{channel}-lr={1e-5}-initByVocab
02/05/2024 14:54:40 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
02/05/2024 14:54:45 - INFO - __main__ - torch.Size([124401, 256])
02/05/2024 14:54:45 - INFO - __main__ - Training 1 parameters on 124401 examples for 5000 steps using 1 GPUs
02/05/2024 14:55:30 - INFO - __main__ - local rank -1	global step 100	train loss 8.18
02/05/2024 14:56:15 - INFO - __main__ - local rank -1	global step 200	train loss 8.27
02/05/2024 14:56:58 - INFO - __main__ - local rank -1	global step 300	train loss 8.21
02/05/2024 14:57:44 - INFO - __main__ - local rank -1	global step 400	train loss 8.19
02/05/2024 14:58:29 - INFO - __main__ - local rank -1	global step 500	train loss 8.13
02/05/2024 14:59:16 - INFO - __main__ - local rank -1	global step 600	train loss 8.05
02/05/2024 15:00:02 - INFO - __main__ - local rank -1	global step 700	train loss 8.01
02/05/2024 15:00:47 - INFO - __main__ - local rank -1	global step 800	train loss 7.92
02/05/2024 15:01:31 - INFO - __main__ - local rank -1	global step 900	train loss 7.95
02/05/2024 15:02:17 - INFO - __main__ - local rank -1	global step 1000	train loss 7.88
02/05/2024 15:03:04 - INFO - __main__ - local rank -1	global step 1100	train loss 7.88
02/05/2024 15:03:50 - INFO - __main__ - local rank -1	global step 1200	train loss 7.83
02/05/2024 15:04:36 - INFO - __main__ - local rank -1	global step 1300	train loss 7.82
02/05/2024 15:05:21 - INFO - __main__ - local rank -1	global step 1400	train loss 7.82
02/05/2024 15:06:07 - INFO - __main__ - local rank -1	global step 1500	train loss 7.87
02/05/2024 15:06:54 - INFO - __main__ - local rank -1	global step 1600	train loss 7.79
02/05/2024 15:07:40 - INFO - __main__ - local rank -1	global step 1700	train loss 7.71
02/05/2024 15:08:25 - INFO - __main__ - local rank -1	global step 1800	train loss 7.77
02/05/2024 15:09:08 - INFO - __main__ - local rank -1	global step 1900	train loss 7.82
02/05/2024 15:09:53 - INFO - __main__ - local rank -1	global step 2000	train loss 7.79
02/05/2024 15:10:39 - INFO - __main__ - local rank -1	global step 2100	train loss 7.71
