01/15/2024 00:43:33 - INFO - __main__ - Namespace(use_demonstrations=True, use_soft_prefix=False, use_soft_postfix=False, n_prefix_tokens=10, max_length=1024, prior=['easiest'], difficulty='concept_calibrated', reorder=True, log_dir='logs', out_dir='out\\gpt2', load_dir=None, concept_dir='concept_likelihood\\gpt2\\glue-glue-100\\glue-sst2-direct-prefix=10-lr=1e-2-5000', prefix_embed_file='checkpoints\\gpt2\\glue-glue\\prefix={10}-{direct}-lr={1e-2}-initByVocab\\soft_embeddings-5000.pt', task=None, dataset='glue-sst2', data_dir='data/', k=4, seed='100,13,21,42,87', test_batch_size=8, global_step=None, use_random_english_words=False, use_random_label=False, use_instruction=False, unseen_domain_only=False, split='test', method='direct', gpt='gpt2', api=None, test_size=1000, train_size=100, embedding_dir='embeddings\\', embedding_model='all-mpnet-base-v2', similarity_temperature=0.1, concept_temperature=50.0)
01/15/2024 00:43:35 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 00:43:35 - INFO - __main__ - batch_size=8	max_length=1024	max_length_per_example=256
01/15/2024 00:43:35 - INFO - __main__ - [Train] glue-sst2	67349
01/15/2024 00:43:35 - INFO - __main__ - [Dev] glue-sst2	872
01/15/2024 00:43:35 - INFO - __main__ - direct on None (1 train, 1 dev)
01/15/2024 00:43:35 - INFO - __main__ - start running soft prefix model
01/15/2024 00:43:35 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 00:43:36 - INFO - __main__ - Checking the first example...
Input:
sentence: the stars may be college kids, but the subject matter is as adult as you can get : negative
Output:
<glue-cola-0><glue-cola-1><glue-cola-2><glue-cola-3><glue-cola-4><glue-cola-5><glue-cola-6><glue-cola-7><glue-cola-8><glue-cola-9>
01/15/2024 00:43:36 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 00:43:51 - INFO - __main__ - time use for computing 100 examples: 15.889891147613525
01/15/2024 00:43:51 - INFO - __main__ - start running soft prefix model
01/15/2024 00:43:51 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 00:43:52 - INFO - __main__ - Checking the first example...
Input:
sentence: the stars may be college kids, but the subject matter is as adult as you can get : negative
Output:
<glue-mnli-0><glue-mnli-1><glue-mnli-2><glue-mnli-3><glue-mnli-4><glue-mnli-5><glue-mnli-6><glue-mnli-7><glue-mnli-8><glue-mnli-9>
01/15/2024 00:43:52 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 00:44:07 - INFO - __main__ - time use for computing 100 examples: 15.580480813980103
01/15/2024 00:44:07 - INFO - __main__ - start running soft prefix model
01/15/2024 00:44:07 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 00:44:08 - INFO - __main__ - Checking the first example...
Input:
sentence: the stars may be college kids, but the subject matter is as adult as you can get : negative
Output:
<glue-qqp-0><glue-qqp-1><glue-qqp-2><glue-qqp-3><glue-qqp-4><glue-qqp-5><glue-qqp-6><glue-qqp-7><glue-qqp-8><glue-qqp-9>
01/15/2024 00:44:08 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 00:44:22 - INFO - __main__ - time use for computing 100 examples: 15.587005138397217
01/15/2024 00:44:22 - INFO - __main__ - start running soft prefix model
01/15/2024 00:44:22 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 00:44:23 - INFO - __main__ - Checking the first example...
Input:
sentence: the stars may be college kids, but the subject matter is as adult as you can get : negative
Output:
<glue-mrpc-0><glue-mrpc-1><glue-mrpc-2><glue-mrpc-3><glue-mrpc-4><glue-mrpc-5><glue-mrpc-6><glue-mrpc-7><glue-mrpc-8><glue-mrpc-9>
01/15/2024 00:44:23 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 00:44:38 - INFO - __main__ - time use for computing 100 examples: 15.592071533203125
01/15/2024 00:44:38 - INFO - __main__ - start running soft prefix model
01/15/2024 00:44:38 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 00:44:39 - INFO - __main__ - Checking the first example...
Input:
sentence: the stars may be college kids, but the subject matter is as adult as you can get : negative
Output:
<glue-qnli-0><glue-qnli-1><glue-qnli-2><glue-qnli-3><glue-qnli-4><glue-qnli-5><glue-qnli-6><glue-qnli-7><glue-qnli-8><glue-qnli-9>
01/15/2024 00:44:39 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 00:44:54 - INFO - __main__ - time use for computing 100 examples: 15.573608636856079
01/15/2024 00:44:54 - INFO - __main__ - start running soft prefix model
01/15/2024 00:44:54 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 00:44:54 - INFO - __main__ - Checking the first example...
Input:
sentence: the stars may be college kids, but the subject matter is as adult as you can get : negative
Output:
<glue-rte-0><glue-rte-1><glue-rte-2><glue-rte-3><glue-rte-4><glue-rte-5><glue-rte-6><glue-rte-7><glue-rte-8><glue-rte-9>
01/15/2024 00:44:54 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 00:45:09 - INFO - __main__ - time use for computing 100 examples: 15.605001211166382
01/15/2024 00:45:09 - INFO - __main__ - start running soft prefix model
01/15/2024 00:45:09 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 00:45:10 - INFO - __main__ - Checking the first example...
Input:
sentence: the stars may be college kids, but the subject matter is as adult as you can get : negative
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 00:45:10 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 00:45:25 - INFO - __main__ - time use for computing 100 examples: 15.618974924087524
01/15/2024 00:45:25 - INFO - __main__ - start running soft prefix model
01/15/2024 00:45:25 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 00:45:26 - INFO - __main__ - Checking the first example...
Input:
sentence: the stars may be college kids, but the subject matter is as adult as you can get : negative
Output:
<glue-wnli-0><glue-wnli-1><glue-wnli-2><glue-wnli-3><glue-wnli-4><glue-wnli-5><glue-wnli-6><glue-wnli-7><glue-wnli-8><glue-wnli-9>
01/15/2024 00:45:26 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 00:45:40 - INFO - __main__ - time use for computing 100 examples: 15.623539924621582
01/15/2024 00:45:40 - INFO - __main__ - min difficulty: -inf
01/15/2024 00:45:40 - INFO - __main__ - max difficulty: -inf
01/15/2024 00:45:40 - INFO - __main__ - average difficulty: -inf
01/15/2024 00:45:40 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 00:45:41 - INFO - __main__ - Checking the first example...
Input:
sentence: the stars may be college kids, but the subject matter is as adult as you can get : positive sentence:, it isn't much fun. negative sentence: a case of too many chefs fussing over too weak a recipe negative sentence: hubert with a mixture of deadpan cool, wry humor and just the measure of tenderness required to give this comic slugfest some heart positive
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 00:45:41 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 00:45:43 - INFO - __main__ - time use for computing 24 examples: 1.9454514980316162
01/15/2024 00:45:43 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 00:45:44 - INFO - __main__ - Checking the first example...
Input:
sentence: the stars may be college kids, but the subject matter is as adult as you can get : positive sentence:, it isn't much fun. negative sentence: a case of too many chefs fussing over too weak a recipe negative sentence: hubert with a mixture of deadpan cool, wry humor and just the measure of tenderness required to give this comic slugfest some heart positive
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 00:45:44 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 00:45:46 - INFO - __main__ - time use for computing 24 examples: 1.9528346061706543
01/15/2024 00:45:46 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 00:45:47 - INFO - __main__ - Checking the first example...
Input:
sentence: the stars may be college kids, but the subject matter is as adult as you can get : positive sentence:, it isn't much fun. negative sentence: a case of too many chefs fussing over too weak a recipe negative sentence: hubert with a mixture of deadpan cool, wry humor and just the measure of tenderness required to give this comic slugfest some heart positive
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 00:45:47 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 00:45:48 - INFO - __main__ - time use for computing 24 examples: 1.9516558647155762
01/15/2024 00:45:48 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 00:45:49 - INFO - __main__ - Checking the first example...
Input:
sentence: the stars may be college kids, but the subject matter is as adult as you can get : positive sentence:, it isn't much fun. negative sentence: a case of too many chefs fussing over too weak a recipe negative sentence: hubert with a mixture of deadpan cool, wry humor and just the measure of tenderness required to give this comic slugfest some heart positive
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 00:45:49 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 00:45:51 - INFO - __main__ - time use for computing 24 examples: 1.958787441253662
01/15/2024 00:45:51 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 00:45:52 - INFO - __main__ - Checking the first example...
Input:
sentence: the stars may be college kids, but the subject matter is as adult as you can get : positive sentence:, it isn't much fun. negative sentence: a case of too many chefs fussing over too weak a recipe negative sentence: hubert with a mixture of deadpan cool, wry humor and just the measure of tenderness required to give this comic slugfest some heart positive
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 00:45:52 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 00:45:54 - INFO - __main__ - time use for computing 24 examples: 1.943596601486206
01/15/2024 00:45:54 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 00:45:54 - INFO - __main__ - Checking the first example...
Input:
sentence: the stars may be college kids, but the subject matter is as adult as you can get : positive sentence:, it isn't much fun. negative sentence: a case of too many chefs fussing over too weak a recipe negative sentence: hubert with a mixture of deadpan cool, wry humor and just the measure of tenderness required to give this comic slugfest some heart positive
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 00:45:54 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 00:45:56 - INFO - __main__ - time use for computing 24 examples: 1.9509618282318115
01/15/2024 00:45:56 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 00:45:57 - INFO - __main__ - Checking the first example...
Input:
sentence: the stars may be college kids, but the subject matter is as adult as you can get : positive sentence:, it isn't much fun. negative sentence: a case of too many chefs fussing over too weak a recipe negative sentence: hubert with a mixture of deadpan cool, wry humor and just the measure of tenderness required to give this comic slugfest some heart positive
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 00:45:57 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 00:45:59 - INFO - __main__ - time use for computing 24 examples: 1.9478659629821777
01/15/2024 00:45:59 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 00:46:00 - INFO - __main__ - Checking the first example...
Input:
sentence: the stars may be college kids, but the subject matter is as adult as you can get : positive sentence:, it isn't much fun. negative sentence: a case of too many chefs fussing over too weak a recipe negative sentence: hubert with a mixture of deadpan cool, wry humor and just the measure of tenderness required to give this comic slugfest some heart positive
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 00:46:00 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 00:46:01 - INFO - __main__ - time use for computing 24 examples: 1.9514129161834717
01/15/2024 00:46:02 - INFO - __main__ - Checking the first example...
Input:
sentence: the stars may be college kids, but the subject matter is as adult as you can get : positive sentence:, it isn't much fun. negative sentence: a case of too many chefs fussing over too weak a recipe negative sentence: hubert with a mixture of deadpan cool, wry humor and just the measure of tenderness required to give this comic slugfest some heart positive sentence: it's a charming and often affecting journey.
Output:
 negative
01/15/2024 00:46:02 - INFO - __main__ - torch.Size([1744, 1024])
01/15/2024 00:48:14 - INFO - __main__ - None task (seed=100): Macro-F1: 37.0, Accuracy: 52.1
01/15/2024 00:48:14 - INFO - __main__ - [Train] glue-sst2	67349
01/15/2024 00:48:14 - INFO - __main__ - [Dev] glue-sst2	872
01/15/2024 00:48:14 - INFO - __main__ - direct on None (1 train, 1 dev)
01/15/2024 00:48:14 - INFO - __main__ - start running soft prefix model
01/15/2024 00:48:14 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 00:48:15 - INFO - __main__ - Checking the first example...
Input:
sentence: well worth revisiting as many times negative
Output:
<glue-cola-0><glue-cola-1><glue-cola-2><glue-cola-3><glue-cola-4><glue-cola-5><glue-cola-6><glue-cola-7><glue-cola-8><glue-cola-9>
01/15/2024 00:48:15 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 00:48:30 - INFO - __main__ - time use for computing 100 examples: 15.674422979354858
01/15/2024 00:48:30 - INFO - __main__ - start running soft prefix model
01/15/2024 00:48:30 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 00:48:31 - INFO - __main__ - Checking the first example...
Input:
sentence: well worth revisiting as many times negative
Output:
<glue-mnli-0><glue-mnli-1><glue-mnli-2><glue-mnli-3><glue-mnli-4><glue-mnli-5><glue-mnli-6><glue-mnli-7><glue-mnli-8><glue-mnli-9>
01/15/2024 00:48:31 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 00:48:46 - INFO - __main__ - time use for computing 100 examples: 15.613588094711304
01/15/2024 00:48:46 - INFO - __main__ - start running soft prefix model
01/15/2024 00:48:46 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 00:48:46 - INFO - __main__ - Checking the first example...
Input:
sentence: well worth revisiting as many times negative
Output:
<glue-qqp-0><glue-qqp-1><glue-qqp-2><glue-qqp-3><glue-qqp-4><glue-qqp-5><glue-qqp-6><glue-qqp-7><glue-qqp-8><glue-qqp-9>
01/15/2024 00:48:46 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 00:49:01 - INFO - __main__ - time use for computing 100 examples: 15.647234916687012
01/15/2024 00:49:01 - INFO - __main__ - start running soft prefix model
01/15/2024 00:49:01 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 00:49:02 - INFO - __main__ - Checking the first example...
Input:
sentence: well worth revisiting as many times negative
Output:
<glue-mrpc-0><glue-mrpc-1><glue-mrpc-2><glue-mrpc-3><glue-mrpc-4><glue-mrpc-5><glue-mrpc-6><glue-mrpc-7><glue-mrpc-8><glue-mrpc-9>
01/15/2024 00:49:02 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 00:49:17 - INFO - __main__ - time use for computing 100 examples: 15.693368196487427
01/15/2024 00:49:17 - INFO - __main__ - start running soft prefix model
01/15/2024 00:49:17 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 00:49:18 - INFO - __main__ - Checking the first example...
Input:
sentence: well worth revisiting as many times negative
Output:
<glue-qnli-0><glue-qnli-1><glue-qnli-2><glue-qnli-3><glue-qnli-4><glue-qnli-5><glue-qnli-6><glue-qnli-7><glue-qnli-8><glue-qnli-9>
01/15/2024 00:49:18 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 00:49:32 - INFO - __main__ - time use for computing 100 examples: 15.633665561676025
01/15/2024 00:49:32 - INFO - __main__ - start running soft prefix model
01/15/2024 00:49:32 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 00:49:33 - INFO - __main__ - Checking the first example...
Input:
sentence: well worth revisiting as many times negative
Output:
<glue-rte-0><glue-rte-1><glue-rte-2><glue-rte-3><glue-rte-4><glue-rte-5><glue-rte-6><glue-rte-7><glue-rte-8><glue-rte-9>
01/15/2024 00:49:33 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 00:49:48 - INFO - __main__ - time use for computing 100 examples: 15.664445638656616
01/15/2024 00:49:48 - INFO - __main__ - start running soft prefix model
01/15/2024 00:49:48 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 00:49:49 - INFO - __main__ - Checking the first example...
Input:
sentence: well worth revisiting as many times negative
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 00:49:49 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 00:50:04 - INFO - __main__ - time use for computing 100 examples: 15.647521734237671
01/15/2024 00:50:04 - INFO - __main__ - start running soft prefix model
01/15/2024 00:50:04 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 00:50:05 - INFO - __main__ - Checking the first example...
Input:
sentence: well worth revisiting as many times negative
Output:
<glue-wnli-0><glue-wnli-1><glue-wnli-2><glue-wnli-3><glue-wnli-4><glue-wnli-5><glue-wnli-6><glue-wnli-7><glue-wnli-8><glue-wnli-9>
01/15/2024 00:50:05 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 00:50:19 - INFO - __main__ - time use for computing 100 examples: 15.64412522315979
01/15/2024 00:50:19 - INFO - __main__ - min difficulty: -inf
01/15/2024 00:50:19 - INFO - __main__ - max difficulty: -inf
01/15/2024 00:50:19 - INFO - __main__ - average difficulty: -inf
01/15/2024 00:50:19 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 00:50:20 - INFO - __main__ - Checking the first example...
Input:
sentence: well worth revisiting as many times positive sentence:'re just a couple of cops in copmovieland, these two negative sentence: is impressively true for being so hot-blooded positive sentence: like the rugrats movies, the wild thornberrys movie doesn't offer much more than the series, but its emphasis on caring for animals and respecting other cultures is particularly welcome positive
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 00:50:20 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 00:50:22 - INFO - __main__ - time use for computing 24 examples: 1.9505834579467773
01/15/2024 00:50:22 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 00:50:23 - INFO - __main__ - Checking the first example...
Input:
sentence: well worth revisiting as many times positive sentence:'re just a couple of cops in copmovieland, these two negative sentence: is impressively true for being so hot-blooded positive sentence: like the rugrats movies, the wild thornberrys movie doesn't offer much more than the series, but its emphasis on caring for animals and respecting other cultures is particularly welcome positive
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 00:50:23 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 00:50:25 - INFO - __main__ - time use for computing 24 examples: 1.9548659324645996
01/15/2024 00:50:25 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 00:50:26 - INFO - __main__ - Checking the first example...
Input:
sentence: well worth revisiting as many times positive sentence:'re just a couple of cops in copmovieland, these two negative sentence: is impressively true for being so hot-blooded positive sentence: like the rugrats movies, the wild thornberrys movie doesn't offer much more than the series, but its emphasis on caring for animals and respecting other cultures is particularly welcome positive
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 00:50:26 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 00:50:27 - INFO - __main__ - time use for computing 24 examples: 1.9582548141479492
01/15/2024 00:50:27 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 00:50:28 - INFO - __main__ - Checking the first example...
Input:
sentence: well worth revisiting as many times positive sentence:'re just a couple of cops in copmovieland, these two negative sentence: is impressively true for being so hot-blooded positive sentence: like the rugrats movies, the wild thornberrys movie doesn't offer much more than the series, but its emphasis on caring for animals and respecting other cultures is particularly welcome positive
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 00:50:28 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 00:50:30 - INFO - __main__ - time use for computing 24 examples: 1.9627256393432617
01/15/2024 00:50:30 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 00:50:31 - INFO - __main__ - Checking the first example...
Input:
sentence: well worth revisiting as many times positive sentence:'re just a couple of cops in copmovieland, these two negative sentence: is impressively true for being so hot-blooded positive sentence: like the rugrats movies, the wild thornberrys movie doesn't offer much more than the series, but its emphasis on caring for animals and respecting other cultures is particularly welcome positive
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 00:50:31 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 00:50:33 - INFO - __main__ - time use for computing 24 examples: 1.9609177112579346
01/15/2024 00:50:33 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 00:50:33 - INFO - __main__ - Checking the first example...
Input:
sentence: well worth revisiting as many times positive sentence:'re just a couple of cops in copmovieland, these two negative sentence: is impressively true for being so hot-blooded positive sentence: like the rugrats movies, the wild thornberrys movie doesn't offer much more than the series, but its emphasis on caring for animals and respecting other cultures is particularly welcome positive
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 00:50:33 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 00:50:35 - INFO - __main__ - time use for computing 24 examples: 1.9581046104431152
01/15/2024 00:50:35 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 00:50:36 - INFO - __main__ - Checking the first example...
Input:
sentence: well worth revisiting as many times positive sentence:'re just a couple of cops in copmovieland, these two negative sentence: is impressively true for being so hot-blooded positive sentence: like the rugrats movies, the wild thornberrys movie doesn't offer much more than the series, but its emphasis on caring for animals and respecting other cultures is particularly welcome positive
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 00:50:36 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 00:50:38 - INFO - __main__ - time use for computing 24 examples: 1.9588329792022705
01/15/2024 00:50:38 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 00:50:39 - INFO - __main__ - Checking the first example...
Input:
sentence: well worth revisiting as many times positive sentence:'re just a couple of cops in copmovieland, these two negative sentence: is impressively true for being so hot-blooded positive sentence: like the rugrats movies, the wild thornberrys movie doesn't offer much more than the series, but its emphasis on caring for animals and respecting other cultures is particularly welcome positive
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 00:50:39 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 00:50:41 - INFO - __main__ - time use for computing 24 examples: 1.961244821548462
01/15/2024 00:50:41 - INFO - __main__ - Checking the first example...
Input:
sentence: well worth revisiting as many times positive sentence:'re just a couple of cops in copmovieland, these two negative sentence: is impressively true for being so hot-blooded positive sentence: like the rugrats movies, the wild thornberrys movie doesn't offer much more than the series, but its emphasis on caring for animals and respecting other cultures is particularly welcome positive sentence: it's a charming and often affecting journey.
Output:
 negative
01/15/2024 00:50:41 - INFO - __main__ - torch.Size([1744, 1024])
01/15/2024 00:52:53 - INFO - __main__ - None task (seed=13): Macro-F1: 34.4, Accuracy: 51.0
01/15/2024 00:52:53 - INFO - __main__ - [Train] glue-sst2	67349
01/15/2024 00:52:53 - INFO - __main__ - [Dev] glue-sst2	872
01/15/2024 00:52:53 - INFO - __main__ - direct on None (1 train, 1 dev)
01/15/2024 00:52:53 - INFO - __main__ - start running soft prefix model
01/15/2024 00:52:53 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 00:52:54 - INFO - __main__ - Checking the first example...
Input:
sentence: in his role of observer of the scene, lawrence sounds whiny and defensive, as if his life-altering experiences made him bitter and less mature. negative
Output:
<glue-cola-0><glue-cola-1><glue-cola-2><glue-cola-3><glue-cola-4><glue-cola-5><glue-cola-6><glue-cola-7><glue-cola-8><glue-cola-9>
01/15/2024 00:52:54 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 00:53:09 - INFO - __main__ - time use for computing 100 examples: 15.65215802192688
01/15/2024 00:53:09 - INFO - __main__ - start running soft prefix model
01/15/2024 00:53:09 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 00:53:10 - INFO - __main__ - Checking the first example...
Input:
sentence: in his role of observer of the scene, lawrence sounds whiny and defensive, as if his life-altering experiences made him bitter and less mature. negative
Output:
<glue-mnli-0><glue-mnli-1><glue-mnli-2><glue-mnli-3><glue-mnli-4><glue-mnli-5><glue-mnli-6><glue-mnli-7><glue-mnli-8><glue-mnli-9>
01/15/2024 00:53:10 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 00:53:25 - INFO - __main__ - time use for computing 100 examples: 15.613176107406616
01/15/2024 00:53:25 - INFO - __main__ - start running soft prefix model
01/15/2024 00:53:25 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 00:53:26 - INFO - __main__ - Checking the first example...
Input:
sentence: in his role of observer of the scene, lawrence sounds whiny and defensive, as if his life-altering experiences made him bitter and less mature. negative
Output:
<glue-qqp-0><glue-qqp-1><glue-qqp-2><glue-qqp-3><glue-qqp-4><glue-qqp-5><glue-qqp-6><glue-qqp-7><glue-qqp-8><glue-qqp-9>
01/15/2024 00:53:26 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 00:53:40 - INFO - __main__ - time use for computing 100 examples: 15.67193055152893
01/15/2024 00:53:40 - INFO - __main__ - start running soft prefix model
01/15/2024 00:53:40 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 00:53:41 - INFO - __main__ - Checking the first example...
Input:
sentence: in his role of observer of the scene, lawrence sounds whiny and defensive, as if his life-altering experiences made him bitter and less mature. negative
Output:
<glue-mrpc-0><glue-mrpc-1><glue-mrpc-2><glue-mrpc-3><glue-mrpc-4><glue-mrpc-5><glue-mrpc-6><glue-mrpc-7><glue-mrpc-8><glue-mrpc-9>
01/15/2024 00:53:41 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 00:53:56 - INFO - __main__ - time use for computing 100 examples: 15.637531042098999
01/15/2024 00:53:56 - INFO - __main__ - start running soft prefix model
01/15/2024 00:53:56 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 00:53:57 - INFO - __main__ - Checking the first example...
Input:
sentence: in his role of observer of the scene, lawrence sounds whiny and defensive, as if his life-altering experiences made him bitter and less mature. negative
Output:
<glue-qnli-0><glue-qnli-1><glue-qnli-2><glue-qnli-3><glue-qnli-4><glue-qnli-5><glue-qnli-6><glue-qnli-7><glue-qnli-8><glue-qnli-9>
01/15/2024 00:53:57 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 00:54:12 - INFO - __main__ - time use for computing 100 examples: 15.659599542617798
01/15/2024 00:54:12 - INFO - __main__ - start running soft prefix model
01/15/2024 00:54:12 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 00:54:13 - INFO - __main__ - Checking the first example...
Input:
sentence: in his role of observer of the scene, lawrence sounds whiny and defensive, as if his life-altering experiences made him bitter and less mature. negative
Output:
<glue-rte-0><glue-rte-1><glue-rte-2><glue-rte-3><glue-rte-4><glue-rte-5><glue-rte-6><glue-rte-7><glue-rte-8><glue-rte-9>
01/15/2024 00:54:13 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 00:54:27 - INFO - __main__ - time use for computing 100 examples: 15.666636943817139
01/15/2024 00:54:27 - INFO - __main__ - start running soft prefix model
01/15/2024 00:54:27 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 00:54:28 - INFO - __main__ - Checking the first example...
Input:
sentence: in his role of observer of the scene, lawrence sounds whiny and defensive, as if his life-altering experiences made him bitter and less mature. negative
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 00:54:28 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 00:54:43 - INFO - __main__ - time use for computing 100 examples: 15.650796175003052
01/15/2024 00:54:43 - INFO - __main__ - start running soft prefix model
01/15/2024 00:54:43 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 00:54:44 - INFO - __main__ - Checking the first example...
Input:
sentence: in his role of observer of the scene, lawrence sounds whiny and defensive, as if his life-altering experiences made him bitter and less mature. negative
Output:
<glue-wnli-0><glue-wnli-1><glue-wnli-2><glue-wnli-3><glue-wnli-4><glue-wnli-5><glue-wnli-6><glue-wnli-7><glue-wnli-8><glue-wnli-9>
01/15/2024 00:54:44 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 00:54:59 - INFO - __main__ - time use for computing 100 examples: 15.640352725982666
01/15/2024 00:54:59 - INFO - __main__ - min difficulty: -inf
01/15/2024 00:54:59 - INFO - __main__ - max difficulty: -inf
01/15/2024 00:54:59 - INFO - __main__ - average difficulty: -inf
01/15/2024 00:54:59 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 00:54:59 - INFO - __main__ - Checking the first example...
Input:
sentence: in his role of observer of the scene, lawrence sounds whiny and defensive, as if his life-altering experiences made him bitter and less mature. negative sentence: disgusted negative sentence: self-promotion ends and positive sentence: while american adobo has its heart ( and its palate ) in the right place, its brain is a little scattered -- ditsy, even. negative
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 00:54:59 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 00:55:01 - INFO - __main__ - time use for computing 24 examples: 1.9544055461883545
01/15/2024 00:55:01 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 00:55:02 - INFO - __main__ - Checking the first example...
Input:
sentence: in his role of observer of the scene, lawrence sounds whiny and defensive, as if his life-altering experiences made him bitter and less mature. negative sentence: disgusted negative sentence: self-promotion ends and positive sentence: while american adobo has its heart ( and its palate ) in the right place, its brain is a little scattered -- ditsy, even. negative
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 00:55:02 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 00:55:04 - INFO - __main__ - time use for computing 24 examples: 1.9621303081512451
01/15/2024 00:55:04 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 00:55:05 - INFO - __main__ - Checking the first example...
Input:
sentence: in his role of observer of the scene, lawrence sounds whiny and defensive, as if his life-altering experiences made him bitter and less mature. negative sentence: disgusted negative sentence: self-promotion ends and positive sentence: while american adobo has its heart ( and its palate ) in the right place, its brain is a little scattered -- ditsy, even. negative
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 00:55:05 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 00:55:07 - INFO - __main__ - time use for computing 24 examples: 1.9554696083068848
01/15/2024 00:55:07 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 00:55:07 - INFO - __main__ - Checking the first example...
Input:
sentence: in his role of observer of the scene, lawrence sounds whiny and defensive, as if his life-altering experiences made him bitter and less mature. negative sentence: disgusted negative sentence: self-promotion ends and positive sentence: while american adobo has its heart ( and its palate ) in the right place, its brain is a little scattered -- ditsy, even. negative
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 00:55:07 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 00:55:09 - INFO - __main__ - time use for computing 24 examples: 1.945655107498169
01/15/2024 00:55:09 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 00:55:10 - INFO - __main__ - Checking the first example...
Input:
sentence: in his role of observer of the scene, lawrence sounds whiny and defensive, as if his life-altering experiences made him bitter and less mature. negative sentence: disgusted negative sentence: self-promotion ends and positive sentence: while american adobo has its heart ( and its palate ) in the right place, its brain is a little scattered -- ditsy, even. negative
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 00:55:10 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 00:55:12 - INFO - __main__ - time use for computing 24 examples: 1.9578607082366943
01/15/2024 00:55:12 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 00:55:13 - INFO - __main__ - Checking the first example...
Input:
sentence: in his role of observer of the scene, lawrence sounds whiny and defensive, as if his life-altering experiences made him bitter and less mature. negative sentence: disgusted negative sentence: self-promotion ends and positive sentence: while american adobo has its heart ( and its palate ) in the right place, its brain is a little scattered -- ditsy, even. negative
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 00:55:13 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 00:55:14 - INFO - __main__ - time use for computing 24 examples: 1.9545347690582275
01/15/2024 00:55:14 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 00:55:15 - INFO - __main__ - Checking the first example...
Input:
sentence: in his role of observer of the scene, lawrence sounds whiny and defensive, as if his life-altering experiences made him bitter and less mature. negative sentence: disgusted negative sentence: self-promotion ends and positive sentence: while american adobo has its heart ( and its palate ) in the right place, its brain is a little scattered -- ditsy, even. negative
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 00:55:15 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 00:55:17 - INFO - __main__ - time use for computing 24 examples: 1.9520459175109863
01/15/2024 00:55:17 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 00:55:18 - INFO - __main__ - Checking the first example...
Input:
sentence: in his role of observer of the scene, lawrence sounds whiny and defensive, as if his life-altering experiences made him bitter and less mature. negative sentence: disgusted negative sentence: self-promotion ends and positive sentence: while american adobo has its heart ( and its palate ) in the right place, its brain is a little scattered -- ditsy, even. negative
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 00:55:18 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 00:55:20 - INFO - __main__ - time use for computing 24 examples: 1.959822654724121
01/15/2024 00:55:20 - INFO - __main__ - Checking the first example...
Input:
sentence: in his role of observer of the scene, lawrence sounds whiny and defensive, as if his life-altering experiences made him bitter and less mature. negative sentence: disgusted negative sentence: self-promotion ends and positive sentence: while american adobo has its heart ( and its palate ) in the right place, its brain is a little scattered -- ditsy, even. negative sentence: it's a charming and often affecting journey.
Output:
 negative
01/15/2024 00:55:20 - INFO - __main__ - torch.Size([1744, 1024])
01/15/2024 00:57:32 - INFO - __main__ - None task (seed=21): Macro-F1: 36.0, Accuracy: 50.3
01/15/2024 00:57:33 - INFO - __main__ - [Train] glue-sst2	67349
01/15/2024 00:57:33 - INFO - __main__ - [Dev] glue-sst2	872
01/15/2024 00:57:33 - INFO - __main__ - direct on None (1 train, 1 dev)
01/15/2024 00:57:33 - INFO - __main__ - start running soft prefix model
01/15/2024 00:57:33 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 00:57:33 - INFO - __main__ - Checking the first example...
Input:
sentence: with outtakes in which most of the characters forget their lines and just utter ` uhhh,'which is better than most of the writing in the movie negative
Output:
<glue-cola-0><glue-cola-1><glue-cola-2><glue-cola-3><glue-cola-4><glue-cola-5><glue-cola-6><glue-cola-7><glue-cola-8><glue-cola-9>
01/15/2024 00:57:33 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 00:57:48 - INFO - __main__ - time use for computing 100 examples: 15.677990674972534
01/15/2024 00:57:48 - INFO - __main__ - start running soft prefix model
01/15/2024 00:57:48 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 00:57:49 - INFO - __main__ - Checking the first example...
Input:
sentence: with outtakes in which most of the characters forget their lines and just utter ` uhhh,'which is better than most of the writing in the movie negative
Output:
<glue-mnli-0><glue-mnli-1><glue-mnli-2><glue-mnli-3><glue-mnli-4><glue-mnli-5><glue-mnli-6><glue-mnli-7><glue-mnli-8><glue-mnli-9>
01/15/2024 00:57:49 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 00:58:04 - INFO - __main__ - time use for computing 100 examples: 15.678822040557861
01/15/2024 00:58:04 - INFO - __main__ - start running soft prefix model
01/15/2024 00:58:04 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 00:58:05 - INFO - __main__ - Checking the first example...
Input:
sentence: with outtakes in which most of the characters forget their lines and just utter ` uhhh,'which is better than most of the writing in the movie negative
Output:
<glue-qqp-0><glue-qqp-1><glue-qqp-2><glue-qqp-3><glue-qqp-4><glue-qqp-5><glue-qqp-6><glue-qqp-7><glue-qqp-8><glue-qqp-9>
01/15/2024 00:58:05 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 00:58:20 - INFO - __main__ - time use for computing 100 examples: 15.66294002532959
01/15/2024 00:58:20 - INFO - __main__ - start running soft prefix model
01/15/2024 00:58:20 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 00:58:20 - INFO - __main__ - Checking the first example...
Input:
sentence: with outtakes in which most of the characters forget their lines and just utter ` uhhh,'which is better than most of the writing in the movie negative
Output:
<glue-mrpc-0><glue-mrpc-1><glue-mrpc-2><glue-mrpc-3><glue-mrpc-4><glue-mrpc-5><glue-mrpc-6><glue-mrpc-7><glue-mrpc-8><glue-mrpc-9>
01/15/2024 00:58:20 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 00:58:35 - INFO - __main__ - time use for computing 100 examples: 15.667689561843872
01/15/2024 00:58:35 - INFO - __main__ - start running soft prefix model
01/15/2024 00:58:35 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 00:58:36 - INFO - __main__ - Checking the first example...
Input:
sentence: with outtakes in which most of the characters forget their lines and just utter ` uhhh,'which is better than most of the writing in the movie negative
Output:
<glue-qnli-0><glue-qnli-1><glue-qnli-2><glue-qnli-3><glue-qnli-4><glue-qnli-5><glue-qnli-6><glue-qnli-7><glue-qnli-8><glue-qnli-9>
01/15/2024 00:58:36 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 00:58:51 - INFO - __main__ - time use for computing 100 examples: 15.678473472595215
01/15/2024 00:58:51 - INFO - __main__ - start running soft prefix model
01/15/2024 00:58:51 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 00:58:52 - INFO - __main__ - Checking the first example...
Input:
sentence: with outtakes in which most of the characters forget their lines and just utter ` uhhh,'which is better than most of the writing in the movie negative
Output:
<glue-rte-0><glue-rte-1><glue-rte-2><glue-rte-3><glue-rte-4><glue-rte-5><glue-rte-6><glue-rte-7><glue-rte-8><glue-rte-9>
01/15/2024 00:58:52 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 00:59:07 - INFO - __main__ - time use for computing 100 examples: 15.670748949050903
01/15/2024 00:59:07 - INFO - __main__ - start running soft prefix model
01/15/2024 00:59:07 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 00:59:07 - INFO - __main__ - Checking the first example...
Input:
sentence: with outtakes in which most of the characters forget their lines and just utter ` uhhh,'which is better than most of the writing in the movie negative
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 00:59:07 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 00:59:22 - INFO - __main__ - time use for computing 100 examples: 15.66852331161499
01/15/2024 00:59:22 - INFO - __main__ - start running soft prefix model
01/15/2024 00:59:22 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 00:59:23 - INFO - __main__ - Checking the first example...
Input:
sentence: with outtakes in which most of the characters forget their lines and just utter ` uhhh,'which is better than most of the writing in the movie negative
Output:
<glue-wnli-0><glue-wnli-1><glue-wnli-2><glue-wnli-3><glue-wnli-4><glue-wnli-5><glue-wnli-6><glue-wnli-7><glue-wnli-8><glue-wnli-9>
01/15/2024 00:59:23 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 00:59:38 - INFO - __main__ - time use for computing 100 examples: 15.667698621749878
01/15/2024 00:59:38 - INFO - __main__ - min difficulty: -inf
01/15/2024 00:59:38 - INFO - __main__ - max difficulty: -inf
01/15/2024 00:59:38 - INFO - __main__ - average difficulty: -inf
01/15/2024 00:59:38 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 00:59:39 - INFO - __main__ - Checking the first example...
Input:
sentence: with outtakes in which most of the characters forget their lines and just utter ` uhhh,'which is better than most of the writing in the movie negative sentence: gets very ugly, very fast negative sentence: called best bad film you thought was going to be really awful but negative sentence: delicate treatment positive
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 00:59:39 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 00:59:41 - INFO - __main__ - time use for computing 24 examples: 1.95396089553833
01/15/2024 00:59:41 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 00:59:41 - INFO - __main__ - Checking the first example...
Input:
sentence: with outtakes in which most of the characters forget their lines and just utter ` uhhh,'which is better than most of the writing in the movie negative sentence: gets very ugly, very fast negative sentence: called best bad film you thought was going to be really awful but negative sentence: delicate treatment positive
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 00:59:41 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 00:59:43 - INFO - __main__ - time use for computing 24 examples: 1.9623768329620361
01/15/2024 00:59:43 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 00:59:44 - INFO - __main__ - Checking the first example...
Input:
sentence: with outtakes in which most of the characters forget their lines and just utter ` uhhh,'which is better than most of the writing in the movie negative sentence: gets very ugly, very fast negative sentence: called best bad film you thought was going to be really awful but negative sentence: delicate treatment positive
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 00:59:44 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 00:59:46 - INFO - __main__ - time use for computing 24 examples: 1.9518013000488281
01/15/2024 00:59:46 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 00:59:47 - INFO - __main__ - Checking the first example...
Input:
sentence: with outtakes in which most of the characters forget their lines and just utter ` uhhh,'which is better than most of the writing in the movie negative sentence: gets very ugly, very fast negative sentence: called best bad film you thought was going to be really awful but negative sentence: delicate treatment positive
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 00:59:47 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 00:59:48 - INFO - __main__ - time use for computing 24 examples: 1.9465968608856201
01/15/2024 00:59:48 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 00:59:49 - INFO - __main__ - Checking the first example...
Input:
sentence: with outtakes in which most of the characters forget their lines and just utter ` uhhh,'which is better than most of the writing in the movie negative sentence: gets very ugly, very fast negative sentence: called best bad film you thought was going to be really awful but negative sentence: delicate treatment positive
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 00:59:49 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 00:59:51 - INFO - __main__ - time use for computing 24 examples: 1.947800636291504
01/15/2024 00:59:51 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 00:59:52 - INFO - __main__ - Checking the first example...
Input:
sentence: with outtakes in which most of the characters forget their lines and just utter ` uhhh,'which is better than most of the writing in the movie negative sentence: gets very ugly, very fast negative sentence: called best bad film you thought was going to be really awful but negative sentence: delicate treatment positive
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 00:59:52 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 00:59:54 - INFO - __main__ - time use for computing 24 examples: 1.942518711090088
01/15/2024 00:59:54 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 00:59:55 - INFO - __main__ - Checking the first example...
Input:
sentence: with outtakes in which most of the characters forget their lines and just utter ` uhhh,'which is better than most of the writing in the movie negative sentence: gets very ugly, very fast negative sentence: called best bad film you thought was going to be really awful but negative sentence: delicate treatment positive
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 00:59:55 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 00:59:56 - INFO - __main__ - time use for computing 24 examples: 1.9505527019500732
01/15/2024 00:59:56 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 00:59:57 - INFO - __main__ - Checking the first example...
Input:
sentence: with outtakes in which most of the characters forget their lines and just utter ` uhhh,'which is better than most of the writing in the movie negative sentence: gets very ugly, very fast negative sentence: called best bad film you thought was going to be really awful but negative sentence: delicate treatment positive
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 00:59:57 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 00:59:59 - INFO - __main__ - time use for computing 24 examples: 1.9597063064575195
01/15/2024 01:00:00 - INFO - __main__ - Checking the first example...
Input:
sentence: with outtakes in which most of the characters forget their lines and just utter ` uhhh,'which is better than most of the writing in the movie negative sentence: gets very ugly, very fast negative sentence: called best bad film you thought was going to be really awful but negative sentence: delicate treatment positive sentence: it's a charming and often affecting journey.
Output:
 negative
01/15/2024 01:00:00 - INFO - __main__ - torch.Size([1744, 1024])
01/15/2024 01:02:12 - INFO - __main__ - None task (seed=42): Macro-F1: 41.9, Accuracy: 52.9
01/15/2024 01:02:12 - INFO - __main__ - [Train] glue-sst2	67349
01/15/2024 01:02:12 - INFO - __main__ - [Dev] glue-sst2	872
01/15/2024 01:02:12 - INFO - __main__ - direct on None (1 train, 1 dev)
01/15/2024 01:02:12 - INFO - __main__ - start running soft prefix model
01/15/2024 01:02:12 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 01:02:13 - INFO - __main__ - Checking the first example...
Input:
sentence: titular negative
Output:
<glue-cola-0><glue-cola-1><glue-cola-2><glue-cola-3><glue-cola-4><glue-cola-5><glue-cola-6><glue-cola-7><glue-cola-8><glue-cola-9>
01/15/2024 01:02:13 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 01:02:28 - INFO - __main__ - time use for computing 100 examples: 15.650609254837036
01/15/2024 01:02:28 - INFO - __main__ - start running soft prefix model
01/15/2024 01:02:28 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 01:02:28 - INFO - __main__ - Checking the first example...
Input:
sentence: titular negative
Output:
<glue-mnli-0><glue-mnli-1><glue-mnli-2><glue-mnli-3><glue-mnli-4><glue-mnli-5><glue-mnli-6><glue-mnli-7><glue-mnli-8><glue-mnli-9>
01/15/2024 01:02:28 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 01:02:43 - INFO - __main__ - time use for computing 100 examples: 15.64602780342102
01/15/2024 01:02:43 - INFO - __main__ - start running soft prefix model
01/15/2024 01:02:43 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 01:02:44 - INFO - __main__ - Checking the first example...
Input:
sentence: titular negative
Output:
<glue-qqp-0><glue-qqp-1><glue-qqp-2><glue-qqp-3><glue-qqp-4><glue-qqp-5><glue-qqp-6><glue-qqp-7><glue-qqp-8><glue-qqp-9>
01/15/2024 01:02:44 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 01:02:59 - INFO - __main__ - time use for computing 100 examples: 15.695758819580078
01/15/2024 01:02:59 - INFO - __main__ - start running soft prefix model
01/15/2024 01:02:59 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 01:03:00 - INFO - __main__ - Checking the first example...
Input:
sentence: titular negative
Output:
<glue-mrpc-0><glue-mrpc-1><glue-mrpc-2><glue-mrpc-3><glue-mrpc-4><glue-mrpc-5><glue-mrpc-6><glue-mrpc-7><glue-mrpc-8><glue-mrpc-9>
01/15/2024 01:03:00 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 01:03:15 - INFO - __main__ - time use for computing 100 examples: 15.66416072845459
01/15/2024 01:03:15 - INFO - __main__ - start running soft prefix model
01/15/2024 01:03:15 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 01:03:15 - INFO - __main__ - Checking the first example...
Input:
sentence: titular negative
Output:
<glue-qnli-0><glue-qnli-1><glue-qnli-2><glue-qnli-3><glue-qnli-4><glue-qnli-5><glue-qnli-6><glue-qnli-7><glue-qnli-8><glue-qnli-9>
01/15/2024 01:03:15 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 01:03:30 - INFO - __main__ - time use for computing 100 examples: 15.657440185546875
01/15/2024 01:03:30 - INFO - __main__ - start running soft prefix model
01/15/2024 01:03:30 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 01:03:31 - INFO - __main__ - Checking the first example...
Input:
sentence: titular negative
Output:
<glue-rte-0><glue-rte-1><glue-rte-2><glue-rte-3><glue-rte-4><glue-rte-5><glue-rte-6><glue-rte-7><glue-rte-8><glue-rte-9>
01/15/2024 01:03:31 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 01:03:46 - INFO - __main__ - time use for computing 100 examples: 15.647621393203735
01/15/2024 01:03:46 - INFO - __main__ - start running soft prefix model
01/15/2024 01:03:46 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 01:03:47 - INFO - __main__ - Checking the first example...
Input:
sentence: titular negative
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 01:03:47 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 01:04:01 - INFO - __main__ - time use for computing 100 examples: 15.65594744682312
01/15/2024 01:04:01 - INFO - __main__ - start running soft prefix model
01/15/2024 01:04:01 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 01:04:02 - INFO - __main__ - Checking the first example...
Input:
sentence: titular negative
Output:
<glue-wnli-0><glue-wnli-1><glue-wnli-2><glue-wnli-3><glue-wnli-4><glue-wnli-5><glue-wnli-6><glue-wnli-7><glue-wnli-8><glue-wnli-9>
01/15/2024 01:04:02 - INFO - __main__ - torch.Size([200, 1024])
01/15/2024 01:04:17 - INFO - __main__ - time use for computing 100 examples: 15.67253589630127
01/15/2024 01:04:17 - INFO - __main__ - min difficulty: -inf
01/15/2024 01:04:17 - INFO - __main__ - max difficulty: -inf
01/15/2024 01:04:17 - INFO - __main__ - average difficulty: -inf
01/15/2024 01:04:17 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 01:04:18 - INFO - __main__ - Checking the first example...
Input:
sentence: titular positive sentence: various amusing sidekicks positive sentence: loses its sense of humor negative sentence: maintaining consciousness just long enough to achieve callow pretension negative
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 01:04:18 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 01:04:20 - INFO - __main__ - time use for computing 24 examples: 1.96128511428833
01/15/2024 01:04:20 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 01:04:21 - INFO - __main__ - Checking the first example...
Input:
sentence: titular positive sentence: various amusing sidekicks positive sentence: loses its sense of humor negative sentence: maintaining consciousness just long enough to achieve callow pretension negative
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 01:04:21 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 01:04:22 - INFO - __main__ - time use for computing 24 examples: 1.952789068222046
01/15/2024 01:04:22 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 01:04:23 - INFO - __main__ - Checking the first example...
Input:
sentence: titular positive sentence: various amusing sidekicks positive sentence: loses its sense of humor negative sentence: maintaining consciousness just long enough to achieve callow pretension negative
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 01:04:23 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 01:04:25 - INFO - __main__ - time use for computing 24 examples: 1.9642345905303955
01/15/2024 01:04:25 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 01:04:26 - INFO - __main__ - Checking the first example...
Input:
sentence: titular positive sentence: various amusing sidekicks positive sentence: loses its sense of humor negative sentence: maintaining consciousness just long enough to achieve callow pretension negative
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 01:04:26 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 01:04:28 - INFO - __main__ - time use for computing 24 examples: 1.9545912742614746
01/15/2024 01:04:28 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 01:04:29 - INFO - __main__ - Checking the first example...
Input:
sentence: titular positive sentence: various amusing sidekicks positive sentence: loses its sense of humor negative sentence: maintaining consciousness just long enough to achieve callow pretension negative
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 01:04:29 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 01:04:30 - INFO - __main__ - time use for computing 24 examples: 1.9627535343170166
01/15/2024 01:04:30 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 01:04:31 - INFO - __main__ - Checking the first example...
Input:
sentence: titular positive sentence: various amusing sidekicks positive sentence: loses its sense of humor negative sentence: maintaining consciousness just long enough to achieve callow pretension negative
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 01:04:31 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 01:04:33 - INFO - __main__ - time use for computing 24 examples: 1.954740285873413
01/15/2024 01:04:33 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 01:04:34 - INFO - __main__ - Checking the first example...
Input:
sentence: titular positive sentence: various amusing sidekicks positive sentence: loses its sense of humor negative sentence: maintaining consciousness just long enough to achieve callow pretension negative
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 01:04:34 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 01:04:36 - INFO - __main__ - time use for computing 24 examples: 1.946101427078247
01/15/2024 01:04:36 - INFO - __main__ - Setting up for local_rank=-1, world_size=1
01/15/2024 01:04:36 - INFO - __main__ - Checking the first example...
Input:
sentence: titular positive sentence: various amusing sidekicks positive sentence: loses its sense of humor negative sentence: maintaining consciousness just long enough to achieve callow pretension negative
Output:
<glue-sst2-0><glue-sst2-1><glue-sst2-2><glue-sst2-3><glue-sst2-4><glue-sst2-5><glue-sst2-6><glue-sst2-7><glue-sst2-8><glue-sst2-9>
01/15/2024 01:04:36 - INFO - __main__ - torch.Size([24, 1024])
01/15/2024 01:04:38 - INFO - __main__ - time use for computing 24 examples: 1.9477787017822266
01/15/2024 01:04:39 - INFO - __main__ - Checking the first example...
Input:
sentence: titular positive sentence: various amusing sidekicks positive sentence: loses its sense of humor negative sentence: maintaining consciousness just long enough to achieve callow pretension negative sentence: it's a charming and often affecting journey.
Output:
 negative
01/15/2024 01:04:39 - INFO - __main__ - torch.Size([1744, 1024])
01/15/2024 01:06:51 - INFO - __main__ - None task (seed=87): Macro-F1: 57.8, Accuracy: 61.9
01/15/2024 01:06:51 - INFO - __main__ - None over 1 target tasks with majority vote: Macro-F1: 58.0, Accuracy: 61.8
01/15/2024 01:06:51 - INFO - __main__ - None over 1 target tasks on average: Macro-F1: 41.4 +- 8.6, Accuracy: 53.6 +- 4.2
